2025-12-20 23:18:53,141 INFO __main__: Starting benchmark for dataset=20newsgroups
2025-12-20 23:18:54,373 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-20 23:18:54,858 INFO gensim.corpora.dictionary: adding document #10000 to Dictionary<92950 unique tokens: ['60s', '70s', 'addition', 'body', 'bricklin']...>
2025-12-20 23:18:54,909 INFO gensim.corpora.dictionary: built Dictionary<101322 unique tokens: ['60s', '70s', 'addition', 'body', 'bricklin']...> from 11014 documents (total 1223092 corpus positions)
2025-12-20 23:18:54,915 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<101322 unique tokens: ['60s', '70s', 'addition', 'body', 'bricklin']...> from 11014 documents (total 1223092 corpus positions)", 'datetime': '2025-12-20T23:18:54.910112', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.15.0-161-generic-x86_64-with-glibc2.35', 'event': 'created'}
2025-12-20 23:18:55,430 INFO sentence_transformers.SentenceTransformer: Use pytorch device_name: cuda:0
2025-12-20 23:18:55,430 INFO sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: all-roberta-large-v1
2025-12-20 23:19:01,855 INFO src.utils.bertopic_utils: Fitting BERTopic model HDBSCAN on 11014 docs
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/numba/np/ufunc/parallel.py:373: NumbaWarning:

The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.

2025-12-20 23:20:47,412 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:20:48,501 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (7232 virtual)
2025-12-20 23:20:48,505 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3127 virtual)
2025-12-20 23:20:48,509 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (1323 virtual)
2025-12-20 23:20:48,510 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (713 virtual)
2025-12-20 23:20:48,513 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (-5372 virtual)
2025-12-20 23:20:48,515 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-3523 virtual)
2025-12-20 23:20:48,519 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (12146 virtual)
2025-12-20 23:20:48,521 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (22148 virtual)
2025-12-20 23:20:48,522 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (19719 virtual)
2025-12-20 23:20:48,526 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (5184 virtual)
2025-12-20 23:20:48,528 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (6705 virtual)
2025-12-20 23:20:48,534 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (-5029 virtual)
2025-12-20 23:20:48,538 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (-3476 virtual)
2025-12-20 23:20:48,539 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (-2950 virtual)
2025-12-20 23:20:48,541 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (2109 virtual)
2025-12-20 23:20:48,551 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (2483 virtual)
2025-12-20 23:20:48,552 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (6024 virtual)
2025-12-20 23:20:48,553 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (8719 virtual)
2025-12-20 23:20:48,555 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (10782 virtual)
2025-12-20 23:20:48,603 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (12662 virtual)
2025-12-20 23:20:48,607 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (14417 virtual)
2025-12-20 23:20:48,608 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (16318 virtual)
2025-12-20 23:20:48,609 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (21460 virtual)
2025-12-20 23:20:48,638 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (36852 virtual)
2025-12-20 23:20:48,655 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (39766 virtual)
2025-12-20 23:20:48,656 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (41441 virtual)
2025-12-20 23:20:48,659 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (51322 virtual)
2025-12-20 23:20:48,660 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (52687 virtual)
2025-12-20 23:20:48,660 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (52913 virtual)
2025-12-20 23:20:48,662 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (55693 virtual)
2025-12-20 23:20:48,799 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (52992 virtual)
2025-12-20 23:20:48,816 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (50615 virtual)
2025-12-20 23:20:48,819 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (45525 virtual)
2025-12-20 23:20:48,822 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (45324 virtual)
2025-12-20 23:20:48,824 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (42113 virtual)
2025-12-20 23:20:48,835 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (43690 virtual)
2025-12-20 23:20:48,837 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (42608 virtual)
2025-12-20 23:20:48,840 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (39072 virtual)
2025-12-20 23:20:48,842 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (40044 virtual)
2025-12-20 23:20:48,843 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (41542 virtual)
2025-12-20 23:20:48,844 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (45793 virtual)
2025-12-20 23:20:48,845 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (47498 virtual)
2025-12-20 23:20:48,883 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (42550 virtual)
2025-12-20 23:20:48,914 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (37489 virtual)
2025-12-20 23:20:48,922 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (39918 virtual)
2025-12-20 23:20:48,939 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (31027 virtual)
2025-12-20 23:20:48,986 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (40008 virtual)
2025-12-20 23:20:49,030 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (41502 virtual)
2025-12-20 23:20:49,031 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (46622 virtual)
2025-12-20 23:20:49,043 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (48729 virtual)
2025-12-20 23:20:49,044 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (44346 virtual)
2025-12-20 23:20:49,075 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (48297 virtual)
2025-12-20 23:20:49,178 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (35558 virtual)
2025-12-20 23:20:49,218 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (37592 virtual)
2025-12-20 23:20:49,322 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (24474 virtual)
2025-12-20 23:20:49,330 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (24761 virtual)
2025-12-20 23:20:49,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,374 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,438 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,438 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,466 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,550 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,570 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:49,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:49,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:50,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:50,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:50,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:50,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:50,258 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:50,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:50,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:50,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:52,520 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:20:52,531 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 663359 virtual documents
2025-12-20 23:20:53,501 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:20:54,654 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5593 virtual)
2025-12-20 23:20:54,656 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10727 virtual)
2025-12-20 23:20:54,659 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (26432 virtual)
2025-12-20 23:20:54,660 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (30159 virtual)
2025-12-20 23:20:54,660 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (32725 virtual)
2025-12-20 23:20:54,661 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (36278 virtual)
2025-12-20 23:20:54,661 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (39220 virtual)
2025-12-20 23:20:54,663 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (54327 virtual)
2025-12-20 23:20:54,664 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (60577 virtual)
2025-12-20 23:20:54,665 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63971 virtual)
2025-12-20 23:20:54,665 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (68747 virtual)
2025-12-20 23:20:54,667 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (78123 virtual)
2025-12-20 23:20:54,667 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (82521 virtual)
2025-12-20 23:20:54,668 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (90313 virtual)
2025-12-20 23:20:54,669 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (95725 virtual)
2025-12-20 23:20:54,670 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (100032 virtual)
2025-12-20 23:20:54,670 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (103002 virtual)
2025-12-20 23:20:54,671 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (109828 virtual)
2025-12-20 23:20:54,672 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (115400 virtual)
2025-12-20 23:20:54,673 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (124477 virtual)
2025-12-20 23:20:54,674 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (128588 virtual)
2025-12-20 23:20:54,674 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (131939 virtual)
2025-12-20 23:20:54,678 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (159346 virtual)
2025-12-20 23:20:54,680 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (175748 virtual)
2025-12-20 23:20:54,680 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (179483 virtual)
2025-12-20 23:20:54,681 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (186119 virtual)
2025-12-20 23:20:54,681 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (189134 virtual)
2025-12-20 23:20:54,682 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (194011 virtual)
2025-12-20 23:20:54,683 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (198338 virtual)
2025-12-20 23:20:54,683 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (201418 virtual)
2025-12-20 23:20:54,684 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (205336 virtual)
2025-12-20 23:20:54,685 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (210865 virtual)
2025-12-20 23:20:54,685 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (215487 virtual)
2025-12-20 23:20:54,686 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (222784 virtual)
2025-12-20 23:20:54,687 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (227542 virtual)
2025-12-20 23:20:54,688 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (237105 virtual)
2025-12-20 23:20:54,689 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (242098 virtual)
2025-12-20 23:20:54,690 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (246462 virtual)
2025-12-20 23:20:54,690 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (250096 virtual)
2025-12-20 23:20:54,691 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (255323 virtual)
2025-12-20 23:20:54,691 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (258628 virtual)
2025-12-20 23:20:54,692 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (263349 virtual)
2025-12-20 23:20:54,693 INFO gensim.topic_coherence.text_analysis: 43 batches submitted to accumulate stats from 2752 documents (268233 virtual)
2025-12-20 23:20:54,693 INFO gensim.topic_coherence.text_analysis: 44 batches submitted to accumulate stats from 2816 documents (274132 virtual)
2025-12-20 23:20:54,695 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (282971 virtual)
2025-12-20 23:20:54,695 INFO gensim.topic_coherence.text_analysis: 46 batches submitted to accumulate stats from 2944 documents (286673 virtual)
2025-12-20 23:20:54,696 INFO gensim.topic_coherence.text_analysis: 47 batches submitted to accumulate stats from 3008 documents (290264 virtual)
2025-12-20 23:20:54,697 INFO gensim.topic_coherence.text_analysis: 48 batches submitted to accumulate stats from 3072 documents (296037 virtual)
2025-12-20 23:20:54,714 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (310124 virtual)
2025-12-20 23:20:54,715 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (317050 virtual)
2025-12-20 23:20:54,715 INFO gensim.topic_coherence.text_analysis: 51 batches submitted to accumulate stats from 3264 documents (320598 virtual)
2025-12-20 23:20:54,717 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (334909 virtual)
2025-12-20 23:20:54,722 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (341683 virtual)
2025-12-20 23:20:54,723 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (351624 virtual)
2025-12-20 23:20:54,742 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (360719 virtual)
2025-12-20 23:20:54,742 INFO gensim.topic_coherence.text_analysis: 56 batches submitted to accumulate stats from 3584 documents (365651 virtual)
2025-12-20 23:20:54,744 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (375582 virtual)
2025-12-20 23:20:54,744 INFO gensim.topic_coherence.text_analysis: 58 batches submitted to accumulate stats from 3712 documents (380043 virtual)
2025-12-20 23:20:54,750 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (390262 virtual)
2025-12-20 23:20:54,758 INFO gensim.topic_coherence.text_analysis: 60 batches submitted to accumulate stats from 3840 documents (394060 virtual)
2025-12-20 23:20:54,762 INFO gensim.topic_coherence.text_analysis: 61 batches submitted to accumulate stats from 3904 documents (398804 virtual)
2025-12-20 23:20:54,774 INFO gensim.topic_coherence.text_analysis: 62 batches submitted to accumulate stats from 3968 documents (402970 virtual)
2025-12-20 23:20:54,776 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (417617 virtual)
2025-12-20 23:20:54,782 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (425918 virtual)
2025-12-20 23:20:54,824 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (437460 virtual)
2025-12-20 23:20:54,825 INFO gensim.topic_coherence.text_analysis: 66 batches submitted to accumulate stats from 4224 documents (441365 virtual)
2025-12-20 23:20:54,825 INFO gensim.topic_coherence.text_analysis: 67 batches submitted to accumulate stats from 4288 documents (446589 virtual)
2025-12-20 23:20:54,826 INFO gensim.topic_coherence.text_analysis: 68 batches submitted to accumulate stats from 4352 documents (450244 virtual)
2025-12-20 23:20:54,830 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (478452 virtual)
2025-12-20 23:20:54,841 INFO gensim.topic_coherence.text_analysis: 70 batches submitted to accumulate stats from 4480 documents (482978 virtual)
2025-12-20 23:20:54,842 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (494166 virtual)
2025-12-20 23:20:54,843 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (502241 virtual)
2025-12-20 23:20:54,846 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (518522 virtual)
2025-12-20 23:20:54,847 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (526287 virtual)
2025-12-20 23:20:54,848 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (532913 virtual)
2025-12-20 23:20:54,848 INFO gensim.topic_coherence.text_analysis: 76 batches submitted to accumulate stats from 4864 documents (536619 virtual)
2025-12-20 23:20:54,858 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (548493 virtual)
2025-12-20 23:20:54,858 INFO gensim.topic_coherence.text_analysis: 78 batches submitted to accumulate stats from 4992 documents (551958 virtual)
2025-12-20 23:20:54,861 INFO gensim.topic_coherence.text_analysis: 79 batches submitted to accumulate stats from 5056 documents (555379 virtual)
2025-12-20 23:20:54,862 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (564992 virtual)
2025-12-20 23:20:54,866 INFO gensim.topic_coherence.text_analysis: 81 batches submitted to accumulate stats from 5184 documents (568990 virtual)
2025-12-20 23:20:54,869 INFO gensim.topic_coherence.text_analysis: 82 batches submitted to accumulate stats from 5248 documents (574796 virtual)
2025-12-20 23:20:54,870 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (581815 virtual)
2025-12-20 23:20:54,871 INFO gensim.topic_coherence.text_analysis: 84 batches submitted to accumulate stats from 5376 documents (585873 virtual)
2025-12-20 23:20:54,874 INFO gensim.topic_coherence.text_analysis: 85 batches submitted to accumulate stats from 5440 documents (591771 virtual)
2025-12-20 23:20:54,875 INFO gensim.topic_coherence.text_analysis: 86 batches submitted to accumulate stats from 5504 documents (597046 virtual)
2025-12-20 23:20:54,876 INFO gensim.topic_coherence.text_analysis: 87 batches submitted to accumulate stats from 5568 documents (601849 virtual)
2025-12-20 23:20:54,882 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (608725 virtual)
2025-12-20 23:20:54,890 INFO gensim.topic_coherence.text_analysis: 89 batches submitted to accumulate stats from 5696 documents (615021 virtual)
2025-12-20 23:20:54,894 INFO gensim.topic_coherence.text_analysis: 90 batches submitted to accumulate stats from 5760 documents (621265 virtual)
2025-12-20 23:20:54,898 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (627724 virtual)
2025-12-20 23:20:54,902 INFO gensim.topic_coherence.text_analysis: 92 batches submitted to accumulate stats from 5888 documents (631679 virtual)
2025-12-20 23:20:54,902 INFO gensim.topic_coherence.text_analysis: 93 batches submitted to accumulate stats from 5952 documents (635736 virtual)
2025-12-20 23:20:54,919 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (643713 virtual)
2025-12-20 23:20:54,920 INFO gensim.topic_coherence.text_analysis: 95 batches submitted to accumulate stats from 6080 documents (649874 virtual)
2025-12-20 23:20:54,921 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (658090 virtual)
2025-12-20 23:20:54,922 INFO gensim.topic_coherence.text_analysis: 97 batches submitted to accumulate stats from 6208 documents (661695 virtual)
2025-12-20 23:20:54,947 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (669808 virtual)
2025-12-20 23:20:54,958 INFO gensim.topic_coherence.text_analysis: 99 batches submitted to accumulate stats from 6336 documents (673686 virtual)
2025-12-20 23:20:54,959 INFO gensim.topic_coherence.text_analysis: 100 batches submitted to accumulate stats from 6400 documents (678673 virtual)
2025-12-20 23:20:54,960 INFO gensim.topic_coherence.text_analysis: 101 batches submitted to accumulate stats from 6464 documents (683677 virtual)
2025-12-20 23:20:54,960 INFO gensim.topic_coherence.text_analysis: 102 batches submitted to accumulate stats from 6528 documents (687618 virtual)
2025-12-20 23:20:54,967 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (698272 virtual)
2025-12-20 23:20:54,986 INFO gensim.topic_coherence.text_analysis: 104 batches submitted to accumulate stats from 6656 documents (703739 virtual)
2025-12-20 23:20:54,988 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (712044 virtual)
2025-12-20 23:20:54,989 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (719942 virtual)
2025-12-20 23:20:55,075 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (730593 virtual)
2025-12-20 23:20:55,123 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (738698 virtual)
2025-12-20 23:20:55,124 INFO gensim.topic_coherence.text_analysis: 109 batches submitted to accumulate stats from 6976 documents (744918 virtual)
2025-12-20 23:20:55,134 INFO gensim.topic_coherence.text_analysis: 110 batches submitted to accumulate stats from 7040 documents (748587 virtual)
2025-12-20 23:20:55,139 INFO gensim.topic_coherence.text_analysis: 111 batches submitted to accumulate stats from 7104 documents (754283 virtual)
2025-12-20 23:20:55,154 INFO gensim.topic_coherence.text_analysis: 112 batches submitted to accumulate stats from 7168 documents (759411 virtual)
2025-12-20 23:20:55,166 INFO gensim.topic_coherence.text_analysis: 113 batches submitted to accumulate stats from 7232 documents (763074 virtual)
2025-12-20 23:20:55,167 INFO gensim.topic_coherence.text_analysis: 114 batches submitted to accumulate stats from 7296 documents (769146 virtual)
2025-12-20 23:20:55,175 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (778550 virtual)
2025-12-20 23:20:55,190 INFO gensim.topic_coherence.text_analysis: 116 batches submitted to accumulate stats from 7424 documents (782687 virtual)
2025-12-20 23:20:55,210 INFO gensim.topic_coherence.text_analysis: 117 batches submitted to accumulate stats from 7488 documents (787370 virtual)
2025-12-20 23:20:55,214 INFO gensim.topic_coherence.text_analysis: 118 batches submitted to accumulate stats from 7552 documents (792747 virtual)
2025-12-20 23:20:55,215 INFO gensim.topic_coherence.text_analysis: 119 batches submitted to accumulate stats from 7616 documents (795834 virtual)
2025-12-20 23:20:55,216 INFO gensim.topic_coherence.text_analysis: 120 batches submitted to accumulate stats from 7680 documents (799472 virtual)
2025-12-20 23:20:55,221 INFO gensim.topic_coherence.text_analysis: 121 batches submitted to accumulate stats from 7744 documents (804251 virtual)
2025-12-20 23:20:55,231 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (818289 virtual)
2025-12-20 23:20:55,270 INFO gensim.topic_coherence.text_analysis: 123 batches submitted to accumulate stats from 7872 documents (823742 virtual)
2025-12-20 23:20:55,274 INFO gensim.topic_coherence.text_analysis: 124 batches submitted to accumulate stats from 7936 documents (829121 virtual)
2025-12-20 23:20:55,283 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (839918 virtual)
2025-12-20 23:20:55,287 INFO gensim.topic_coherence.text_analysis: 126 batches submitted to accumulate stats from 8064 documents (843357 virtual)
2025-12-20 23:20:55,310 INFO gensim.topic_coherence.text_analysis: 127 batches submitted to accumulate stats from 8128 documents (847194 virtual)
2025-12-20 23:20:55,315 INFO gensim.topic_coherence.text_analysis: 128 batches submitted to accumulate stats from 8192 documents (850480 virtual)
2025-12-20 23:20:55,316 INFO gensim.topic_coherence.text_analysis: 129 batches submitted to accumulate stats from 8256 documents (854672 virtual)
2025-12-20 23:20:55,323 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (863027 virtual)
2025-12-20 23:20:55,334 INFO gensim.topic_coherence.text_analysis: 131 batches submitted to accumulate stats from 8384 documents (865772 virtual)
2025-12-20 23:20:55,337 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (884808 virtual)
2025-12-20 23:20:55,366 INFO gensim.topic_coherence.text_analysis: 133 batches submitted to accumulate stats from 8512 documents (889004 virtual)
2025-12-20 23:20:55,382 INFO gensim.topic_coherence.text_analysis: 134 batches submitted to accumulate stats from 8576 documents (894985 virtual)
2025-12-20 23:20:55,394 INFO gensim.topic_coherence.text_analysis: 135 batches submitted to accumulate stats from 8640 documents (898703 virtual)
2025-12-20 23:20:55,395 INFO gensim.topic_coherence.text_analysis: 136 batches submitted to accumulate stats from 8704 documents (901982 virtual)
2025-12-20 23:20:55,406 INFO gensim.topic_coherence.text_analysis: 137 batches submitted to accumulate stats from 8768 documents (906587 virtual)
2025-12-20 23:20:55,420 INFO gensim.topic_coherence.text_analysis: 138 batches submitted to accumulate stats from 8832 documents (910463 virtual)
2025-12-20 23:20:55,427 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (931102 virtual)
2025-12-20 23:20:55,455 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (942622 virtual)
2025-12-20 23:20:55,483 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (951129 virtual)
2025-12-20 23:20:55,483 INFO gensim.topic_coherence.text_analysis: 142 batches submitted to accumulate stats from 9088 documents (955276 virtual)
2025-12-20 23:20:55,487 INFO gensim.topic_coherence.text_analysis: 143 batches submitted to accumulate stats from 9152 documents (959539 virtual)
2025-12-20 23:20:55,488 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (965946 virtual)
2025-12-20 23:20:55,499 INFO gensim.topic_coherence.text_analysis: 145 batches submitted to accumulate stats from 9280 documents (970853 virtual)
2025-12-20 23:20:55,500 INFO gensim.topic_coherence.text_analysis: 146 batches submitted to accumulate stats from 9344 documents (973829 virtual)
2025-12-20 23:20:55,502 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (989097 virtual)
2025-12-20 23:20:55,510 INFO gensim.topic_coherence.text_analysis: 148 batches submitted to accumulate stats from 9472 documents (994234 virtual)
2025-12-20 23:20:55,511 INFO gensim.topic_coherence.text_analysis: 149 batches submitted to accumulate stats from 9536 documents (997762 virtual)
2025-12-20 23:20:55,513 INFO gensim.topic_coherence.text_analysis: 150 batches submitted to accumulate stats from 9600 documents (1000793 virtual)
2025-12-20 23:20:55,529 INFO gensim.topic_coherence.text_analysis: 151 batches submitted to accumulate stats from 9664 documents (1006413 virtual)
2025-12-20 23:20:55,535 INFO gensim.topic_coherence.text_analysis: 152 batches submitted to accumulate stats from 9728 documents (1011923 virtual)
2025-12-20 23:20:55,536 INFO gensim.topic_coherence.text_analysis: 153 batches submitted to accumulate stats from 9792 documents (1014946 virtual)
2025-12-20 23:20:55,537 INFO gensim.topic_coherence.text_analysis: 154 batches submitted to accumulate stats from 9856 documents (1018740 virtual)
2025-12-20 23:20:55,552 INFO gensim.topic_coherence.text_analysis: 155 batches submitted to accumulate stats from 9920 documents (1022376 virtual)
2025-12-20 23:20:55,553 INFO gensim.topic_coherence.text_analysis: 156 batches submitted to accumulate stats from 9984 documents (1026825 virtual)
2025-12-20 23:20:55,563 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (1040358 virtual)
2025-12-20 23:20:55,565 INFO gensim.topic_coherence.text_analysis: 158 batches submitted to accumulate stats from 10112 documents (1044737 virtual)
2025-12-20 23:20:55,581 INFO gensim.topic_coherence.text_analysis: 159 batches submitted to accumulate stats from 10176 documents (1050861 virtual)
2025-12-20 23:20:55,582 INFO gensim.topic_coherence.text_analysis: 160 batches submitted to accumulate stats from 10240 documents (1056370 virtual)
2025-12-20 23:20:55,583 INFO gensim.topic_coherence.text_analysis: 161 batches submitted to accumulate stats from 10304 documents (1062228 virtual)
2025-12-20 23:20:55,584 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (1074392 virtual)
2025-12-20 23:20:55,585 INFO gensim.topic_coherence.text_analysis: 163 batches submitted to accumulate stats from 10432 documents (1078963 virtual)
2025-12-20 23:20:55,586 INFO gensim.topic_coherence.text_analysis: 164 batches submitted to accumulate stats from 10496 documents (1082443 virtual)
2025-12-20 23:20:55,602 INFO gensim.topic_coherence.text_analysis: 165 batches submitted to accumulate stats from 10560 documents (1088508 virtual)
2025-12-20 23:20:55,608 INFO gensim.topic_coherence.text_analysis: 166 batches submitted to accumulate stats from 10624 documents (1093083 virtual)
2025-12-20 23:20:55,609 INFO gensim.topic_coherence.text_analysis: 167 batches submitted to accumulate stats from 10688 documents (1096984 virtual)
2025-12-20 23:20:55,610 INFO gensim.topic_coherence.text_analysis: 168 batches submitted to accumulate stats from 10752 documents (1101614 virtual)
2025-12-20 23:20:55,610 INFO gensim.topic_coherence.text_analysis: 169 batches submitted to accumulate stats from 10816 documents (1105041 virtual)
2025-12-20 23:20:55,611 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (1112474 virtual)
2025-12-20 23:20:55,612 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (1119161 virtual)
2025-12-20 23:20:55,613 INFO gensim.topic_coherence.text_analysis: 172 batches submitted to accumulate stats from 11008 documents (1123702 virtual)
2025-12-20 23:20:55,623 INFO gensim.topic_coherence.text_analysis: 173 batches submitted to accumulate stats from 11072 documents (1123966 virtual)
2025-12-20 23:20:55,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,670 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,688 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,690 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,692 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,700 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,710 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,712 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,724 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:55,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:55,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:56,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:56,104 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:56,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:20:56,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:20:59,479 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:20:59,491 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1127780 virtual documents
2025-12-20 23:20:59,991 INFO src.utils.bertopic_utils: Fitting BERTopic model KMeans on 11014 docs
2025-12-20 23:22:31,031 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:22:32,291 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (7232 virtual)
2025-12-20 23:22:32,296 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3127 virtual)
2025-12-20 23:22:32,300 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (1323 virtual)
2025-12-20 23:22:32,302 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (713 virtual)
2025-12-20 23:22:32,306 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (-5372 virtual)
2025-12-20 23:22:32,308 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-3523 virtual)
2025-12-20 23:22:32,313 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (12146 virtual)
2025-12-20 23:22:32,315 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (22148 virtual)
2025-12-20 23:22:32,317 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (19719 virtual)
2025-12-20 23:22:32,325 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (5184 virtual)
2025-12-20 23:22:32,327 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (6705 virtual)
2025-12-20 23:22:32,334 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (-5029 virtual)
2025-12-20 23:22:32,351 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (-3476 virtual)
2025-12-20 23:22:32,354 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (-2950 virtual)
2025-12-20 23:22:32,357 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (2109 virtual)
2025-12-20 23:22:32,358 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (2483 virtual)
2025-12-20 23:22:32,359 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (6024 virtual)
2025-12-20 23:22:32,394 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (8719 virtual)
2025-12-20 23:22:32,396 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (10782 virtual)
2025-12-20 23:22:32,398 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (12662 virtual)
2025-12-20 23:22:32,441 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (14417 virtual)
2025-12-20 23:22:32,475 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (16318 virtual)
2025-12-20 23:22:32,477 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (21460 virtual)
2025-12-20 23:22:32,505 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (36852 virtual)
2025-12-20 23:22:32,528 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (39766 virtual)
2025-12-20 23:22:32,555 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (41441 virtual)
2025-12-20 23:22:32,572 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (51322 virtual)
2025-12-20 23:22:32,603 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (52687 virtual)
2025-12-20 23:22:32,631 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (52913 virtual)
2025-12-20 23:22:32,633 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (55693 virtual)
2025-12-20 23:22:32,664 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (52992 virtual)
2025-12-20 23:22:32,676 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (50615 virtual)
2025-12-20 23:22:32,718 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (45525 virtual)
2025-12-20 23:22:32,765 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (45324 virtual)
2025-12-20 23:22:32,796 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (42113 virtual)
2025-12-20 23:22:32,820 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (43690 virtual)
2025-12-20 23:22:32,844 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (42608 virtual)
2025-12-20 23:22:32,854 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (39072 virtual)
2025-12-20 23:22:32,901 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (40044 virtual)
2025-12-20 23:22:32,934 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (41542 virtual)
2025-12-20 23:22:32,936 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (45793 virtual)
2025-12-20 23:22:32,963 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (47498 virtual)
2025-12-20 23:22:32,969 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (42550 virtual)
2025-12-20 23:22:33,064 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (37489 virtual)
2025-12-20 23:22:33,089 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (39918 virtual)
2025-12-20 23:22:33,117 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (31027 virtual)
2025-12-20 23:22:33,161 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (40008 virtual)
2025-12-20 23:22:33,245 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (41502 virtual)
2025-12-20 23:22:33,287 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (46622 virtual)
2025-12-20 23:22:33,311 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (48729 virtual)
2025-12-20 23:22:33,328 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (44346 virtual)
2025-12-20 23:22:33,353 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (48297 virtual)
2025-12-20 23:22:33,446 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (35558 virtual)
2025-12-20 23:22:33,531 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (37592 virtual)
2025-12-20 23:22:33,575 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (24474 virtual)
2025-12-20 23:22:33,576 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (24761 virtual)
2025-12-20 23:22:33,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:33,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,974 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:33,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,981 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:33,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:33,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:33,994 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,006 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,040 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,042 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,045 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,062 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,082 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,104 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,114 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,121 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,197 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,206 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,253 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,330 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,412 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,448 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,469 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,570 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:34,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:34,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:35,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:35,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:35,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:35,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:35,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:35,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:35,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:35,570 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:35,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:35,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:37,742 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:22:38,344 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 663359 virtual documents
2025-12-20 23:22:39,125 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:22:40,409 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5593 virtual)
2025-12-20 23:22:40,414 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10727 virtual)
2025-12-20 23:22:40,416 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (26432 virtual)
2025-12-20 23:22:40,417 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (30159 virtual)
2025-12-20 23:22:40,418 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (32725 virtual)
2025-12-20 23:22:40,419 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (36278 virtual)
2025-12-20 23:22:40,419 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (39220 virtual)
2025-12-20 23:22:40,421 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (54327 virtual)
2025-12-20 23:22:40,422 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (60577 virtual)
2025-12-20 23:22:40,423 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63971 virtual)
2025-12-20 23:22:40,424 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (68747 virtual)
2025-12-20 23:22:40,425 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (78123 virtual)
2025-12-20 23:22:40,426 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (82521 virtual)
2025-12-20 23:22:40,427 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (90313 virtual)
2025-12-20 23:22:40,428 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (95725 virtual)
2025-12-20 23:22:40,429 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (100032 virtual)
2025-12-20 23:22:40,430 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (103002 virtual)
2025-12-20 23:22:40,431 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (109828 virtual)
2025-12-20 23:22:40,432 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (115400 virtual)
2025-12-20 23:22:40,433 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (124477 virtual)
2025-12-20 23:22:40,434 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (128588 virtual)
2025-12-20 23:22:40,434 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (131939 virtual)
2025-12-20 23:22:40,438 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (159346 virtual)
2025-12-20 23:22:40,441 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (175748 virtual)
2025-12-20 23:22:40,441 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (179483 virtual)
2025-12-20 23:22:40,442 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (186119 virtual)
2025-12-20 23:22:40,443 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (189134 virtual)
2025-12-20 23:22:40,444 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (194011 virtual)
2025-12-20 23:22:40,445 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (198338 virtual)
2025-12-20 23:22:40,445 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (201418 virtual)
2025-12-20 23:22:40,446 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (205336 virtual)
2025-12-20 23:22:40,447 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (210865 virtual)
2025-12-20 23:22:40,448 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (215487 virtual)
2025-12-20 23:22:40,449 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (222784 virtual)
2025-12-20 23:22:40,450 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (227542 virtual)
2025-12-20 23:22:40,451 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (237105 virtual)
2025-12-20 23:22:40,452 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (242098 virtual)
2025-12-20 23:22:40,453 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (246462 virtual)
2025-12-20 23:22:40,453 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (250096 virtual)
2025-12-20 23:22:40,454 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (255323 virtual)
2025-12-20 23:22:40,459 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (258628 virtual)
2025-12-20 23:22:40,460 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (263349 virtual)
2025-12-20 23:22:40,461 INFO gensim.topic_coherence.text_analysis: 43 batches submitted to accumulate stats from 2752 documents (268233 virtual)
2025-12-20 23:22:40,462 INFO gensim.topic_coherence.text_analysis: 44 batches submitted to accumulate stats from 2816 documents (274132 virtual)
2025-12-20 23:22:40,463 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (282971 virtual)
2025-12-20 23:22:40,464 INFO gensim.topic_coherence.text_analysis: 46 batches submitted to accumulate stats from 2944 documents (286673 virtual)
2025-12-20 23:22:40,464 INFO gensim.topic_coherence.text_analysis: 47 batches submitted to accumulate stats from 3008 documents (290264 virtual)
2025-12-20 23:22:40,465 INFO gensim.topic_coherence.text_analysis: 48 batches submitted to accumulate stats from 3072 documents (296037 virtual)
2025-12-20 23:22:40,467 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (310124 virtual)
2025-12-20 23:22:40,468 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (317050 virtual)
2025-12-20 23:22:40,469 INFO gensim.topic_coherence.text_analysis: 51 batches submitted to accumulate stats from 3264 documents (320598 virtual)
2025-12-20 23:22:40,471 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (334909 virtual)
2025-12-20 23:22:40,472 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (341683 virtual)
2025-12-20 23:22:40,474 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (351624 virtual)
2025-12-20 23:22:40,476 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (360719 virtual)
2025-12-20 23:22:40,494 INFO gensim.topic_coherence.text_analysis: 56 batches submitted to accumulate stats from 3584 documents (365651 virtual)
2025-12-20 23:22:40,495 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (375582 virtual)
2025-12-20 23:22:40,506 INFO gensim.topic_coherence.text_analysis: 58 batches submitted to accumulate stats from 3712 documents (380043 virtual)
2025-12-20 23:22:40,508 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (390262 virtual)
2025-12-20 23:22:40,509 INFO gensim.topic_coherence.text_analysis: 60 batches submitted to accumulate stats from 3840 documents (394060 virtual)
2025-12-20 23:22:40,509 INFO gensim.topic_coherence.text_analysis: 61 batches submitted to accumulate stats from 3904 documents (398804 virtual)
2025-12-20 23:22:40,510 INFO gensim.topic_coherence.text_analysis: 62 batches submitted to accumulate stats from 3968 documents (402970 virtual)
2025-12-20 23:22:40,512 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (417617 virtual)
2025-12-20 23:22:40,523 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (425918 virtual)
2025-12-20 23:22:40,525 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (437460 virtual)
2025-12-20 23:22:40,534 INFO gensim.topic_coherence.text_analysis: 66 batches submitted to accumulate stats from 4224 documents (441365 virtual)
2025-12-20 23:22:40,535 INFO gensim.topic_coherence.text_analysis: 67 batches submitted to accumulate stats from 4288 documents (446589 virtual)
2025-12-20 23:22:40,536 INFO gensim.topic_coherence.text_analysis: 68 batches submitted to accumulate stats from 4352 documents (450244 virtual)
2025-12-20 23:22:40,540 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (478452 virtual)
2025-12-20 23:22:40,550 INFO gensim.topic_coherence.text_analysis: 70 batches submitted to accumulate stats from 4480 documents (482978 virtual)
2025-12-20 23:22:40,552 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (494166 virtual)
2025-12-20 23:22:40,553 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (502241 virtual)
2025-12-20 23:22:40,564 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (518522 virtual)
2025-12-20 23:22:40,565 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (526287 virtual)
2025-12-20 23:22:40,567 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (532913 virtual)
2025-12-20 23:22:40,567 INFO gensim.topic_coherence.text_analysis: 76 batches submitted to accumulate stats from 4864 documents (536619 virtual)
2025-12-20 23:22:40,571 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (548493 virtual)
2025-12-20 23:22:40,606 INFO gensim.topic_coherence.text_analysis: 78 batches submitted to accumulate stats from 4992 documents (551958 virtual)
2025-12-20 23:22:40,634 INFO gensim.topic_coherence.text_analysis: 79 batches submitted to accumulate stats from 5056 documents (555379 virtual)
2025-12-20 23:22:40,643 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (564992 virtual)
2025-12-20 23:22:40,644 INFO gensim.topic_coherence.text_analysis: 81 batches submitted to accumulate stats from 5184 documents (568990 virtual)
2025-12-20 23:22:40,645 INFO gensim.topic_coherence.text_analysis: 82 batches submitted to accumulate stats from 5248 documents (574796 virtual)
2025-12-20 23:22:40,646 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (581815 virtual)
2025-12-20 23:22:40,654 INFO gensim.topic_coherence.text_analysis: 84 batches submitted to accumulate stats from 5376 documents (585873 virtual)
2025-12-20 23:22:40,655 INFO gensim.topic_coherence.text_analysis: 85 batches submitted to accumulate stats from 5440 documents (591771 virtual)
2025-12-20 23:22:40,663 INFO gensim.topic_coherence.text_analysis: 86 batches submitted to accumulate stats from 5504 documents (597046 virtual)
2025-12-20 23:22:40,679 INFO gensim.topic_coherence.text_analysis: 87 batches submitted to accumulate stats from 5568 documents (601849 virtual)
2025-12-20 23:22:40,680 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (608725 virtual)
2025-12-20 23:22:40,681 INFO gensim.topic_coherence.text_analysis: 89 batches submitted to accumulate stats from 5696 documents (615021 virtual)
2025-12-20 23:22:40,687 INFO gensim.topic_coherence.text_analysis: 90 batches submitted to accumulate stats from 5760 documents (621265 virtual)
2025-12-20 23:22:40,688 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (627724 virtual)
2025-12-20 23:22:40,690 INFO gensim.topic_coherence.text_analysis: 92 batches submitted to accumulate stats from 5888 documents (631679 virtual)
2025-12-20 23:22:40,802 INFO gensim.topic_coherence.text_analysis: 93 batches submitted to accumulate stats from 5952 documents (635736 virtual)
2025-12-20 23:22:40,804 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (643713 virtual)
2025-12-20 23:22:40,805 INFO gensim.topic_coherence.text_analysis: 95 batches submitted to accumulate stats from 6080 documents (649874 virtual)
2025-12-20 23:22:40,811 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (658090 virtual)
2025-12-20 23:22:40,826 INFO gensim.topic_coherence.text_analysis: 97 batches submitted to accumulate stats from 6208 documents (661695 virtual)
2025-12-20 23:22:40,843 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (669808 virtual)
2025-12-20 23:22:40,844 INFO gensim.topic_coherence.text_analysis: 99 batches submitted to accumulate stats from 6336 documents (673686 virtual)
2025-12-20 23:22:40,844 INFO gensim.topic_coherence.text_analysis: 100 batches submitted to accumulate stats from 6400 documents (678673 virtual)
2025-12-20 23:22:40,845 INFO gensim.topic_coherence.text_analysis: 101 batches submitted to accumulate stats from 6464 documents (683677 virtual)
2025-12-20 23:22:40,862 INFO gensim.topic_coherence.text_analysis: 102 batches submitted to accumulate stats from 6528 documents (687618 virtual)
2025-12-20 23:22:40,867 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (698272 virtual)
2025-12-20 23:22:40,868 INFO gensim.topic_coherence.text_analysis: 104 batches submitted to accumulate stats from 6656 documents (703739 virtual)
2025-12-20 23:22:40,875 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (712044 virtual)
2025-12-20 23:22:40,911 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (719942 virtual)
2025-12-20 23:22:40,912 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (730593 virtual)
2025-12-20 23:22:40,914 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (738698 virtual)
2025-12-20 23:22:40,943 INFO gensim.topic_coherence.text_analysis: 109 batches submitted to accumulate stats from 6976 documents (744918 virtual)
2025-12-20 23:22:40,943 INFO gensim.topic_coherence.text_analysis: 110 batches submitted to accumulate stats from 7040 documents (748587 virtual)
2025-12-20 23:22:40,955 INFO gensim.topic_coherence.text_analysis: 111 batches submitted to accumulate stats from 7104 documents (754283 virtual)
2025-12-20 23:22:40,955 INFO gensim.topic_coherence.text_analysis: 112 batches submitted to accumulate stats from 7168 documents (759411 virtual)
2025-12-20 23:22:40,968 INFO gensim.topic_coherence.text_analysis: 113 batches submitted to accumulate stats from 7232 documents (763074 virtual)
2025-12-20 23:22:40,983 INFO gensim.topic_coherence.text_analysis: 114 batches submitted to accumulate stats from 7296 documents (769146 virtual)
2025-12-20 23:22:40,991 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (778550 virtual)
2025-12-20 23:22:40,998 INFO gensim.topic_coherence.text_analysis: 116 batches submitted to accumulate stats from 7424 documents (782687 virtual)
2025-12-20 23:22:40,999 INFO gensim.topic_coherence.text_analysis: 117 batches submitted to accumulate stats from 7488 documents (787370 virtual)
2025-12-20 23:22:41,006 INFO gensim.topic_coherence.text_analysis: 118 batches submitted to accumulate stats from 7552 documents (792747 virtual)
2025-12-20 23:22:41,010 INFO gensim.topic_coherence.text_analysis: 119 batches submitted to accumulate stats from 7616 documents (795834 virtual)
2025-12-20 23:22:41,022 INFO gensim.topic_coherence.text_analysis: 120 batches submitted to accumulate stats from 7680 documents (799472 virtual)
2025-12-20 23:22:41,023 INFO gensim.topic_coherence.text_analysis: 121 batches submitted to accumulate stats from 7744 documents (804251 virtual)
2025-12-20 23:22:41,025 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (818289 virtual)
2025-12-20 23:22:41,047 INFO gensim.topic_coherence.text_analysis: 123 batches submitted to accumulate stats from 7872 documents (823742 virtual)
2025-12-20 23:22:41,058 INFO gensim.topic_coherence.text_analysis: 124 batches submitted to accumulate stats from 7936 documents (829121 virtual)
2025-12-20 23:22:41,063 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (839918 virtual)
2025-12-20 23:22:41,078 INFO gensim.topic_coherence.text_analysis: 126 batches submitted to accumulate stats from 8064 documents (843357 virtual)
2025-12-20 23:22:41,090 INFO gensim.topic_coherence.text_analysis: 127 batches submitted to accumulate stats from 8128 documents (847194 virtual)
2025-12-20 23:22:41,091 INFO gensim.topic_coherence.text_analysis: 128 batches submitted to accumulate stats from 8192 documents (850480 virtual)
2025-12-20 23:22:41,098 INFO gensim.topic_coherence.text_analysis: 129 batches submitted to accumulate stats from 8256 documents (854672 virtual)
2025-12-20 23:22:41,100 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (863027 virtual)
2025-12-20 23:22:41,106 INFO gensim.topic_coherence.text_analysis: 131 batches submitted to accumulate stats from 8384 documents (865772 virtual)
2025-12-20 23:22:41,120 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (884808 virtual)
2025-12-20 23:22:41,138 INFO gensim.topic_coherence.text_analysis: 133 batches submitted to accumulate stats from 8512 documents (889004 virtual)
2025-12-20 23:22:41,143 INFO gensim.topic_coherence.text_analysis: 134 batches submitted to accumulate stats from 8576 documents (894985 virtual)
2025-12-20 23:22:41,158 INFO gensim.topic_coherence.text_analysis: 135 batches submitted to accumulate stats from 8640 documents (898703 virtual)
2025-12-20 23:22:41,162 INFO gensim.topic_coherence.text_analysis: 136 batches submitted to accumulate stats from 8704 documents (901982 virtual)
2025-12-20 23:22:41,170 INFO gensim.topic_coherence.text_analysis: 137 batches submitted to accumulate stats from 8768 documents (906587 virtual)
2025-12-20 23:22:41,178 INFO gensim.topic_coherence.text_analysis: 138 batches submitted to accumulate stats from 8832 documents (910463 virtual)
2025-12-20 23:22:41,189 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (931102 virtual)
2025-12-20 23:22:41,211 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (942622 virtual)
2025-12-20 23:22:41,219 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (951129 virtual)
2025-12-20 23:22:41,242 INFO gensim.topic_coherence.text_analysis: 142 batches submitted to accumulate stats from 9088 documents (955276 virtual)
2025-12-20 23:22:41,246 INFO gensim.topic_coherence.text_analysis: 143 batches submitted to accumulate stats from 9152 documents (959539 virtual)
2025-12-20 23:22:41,255 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (965946 virtual)
2025-12-20 23:22:41,256 INFO gensim.topic_coherence.text_analysis: 145 batches submitted to accumulate stats from 9280 documents (970853 virtual)
2025-12-20 23:22:41,262 INFO gensim.topic_coherence.text_analysis: 146 batches submitted to accumulate stats from 9344 documents (973829 virtual)
2025-12-20 23:22:41,284 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (989097 virtual)
2025-12-20 23:22:41,294 INFO gensim.topic_coherence.text_analysis: 148 batches submitted to accumulate stats from 9472 documents (994234 virtual)
2025-12-20 23:22:41,298 INFO gensim.topic_coherence.text_analysis: 149 batches submitted to accumulate stats from 9536 documents (997762 virtual)
2025-12-20 23:22:41,299 INFO gensim.topic_coherence.text_analysis: 150 batches submitted to accumulate stats from 9600 documents (1000793 virtual)
2025-12-20 23:22:41,311 INFO gensim.topic_coherence.text_analysis: 151 batches submitted to accumulate stats from 9664 documents (1006413 virtual)
2025-12-20 23:22:41,315 INFO gensim.topic_coherence.text_analysis: 152 batches submitted to accumulate stats from 9728 documents (1011923 virtual)
2025-12-20 23:22:41,318 INFO gensim.topic_coherence.text_analysis: 153 batches submitted to accumulate stats from 9792 documents (1014946 virtual)
2025-12-20 23:22:41,326 INFO gensim.topic_coherence.text_analysis: 154 batches submitted to accumulate stats from 9856 documents (1018740 virtual)
2025-12-20 23:22:41,330 INFO gensim.topic_coherence.text_analysis: 155 batches submitted to accumulate stats from 9920 documents (1022376 virtual)
2025-12-20 23:22:41,338 INFO gensim.topic_coherence.text_analysis: 156 batches submitted to accumulate stats from 9984 documents (1026825 virtual)
2025-12-20 23:22:41,351 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (1040358 virtual)
2025-12-20 23:22:41,366 INFO gensim.topic_coherence.text_analysis: 158 batches submitted to accumulate stats from 10112 documents (1044737 virtual)
2025-12-20 23:22:41,375 INFO gensim.topic_coherence.text_analysis: 159 batches submitted to accumulate stats from 10176 documents (1050861 virtual)
2025-12-20 23:22:41,383 INFO gensim.topic_coherence.text_analysis: 160 batches submitted to accumulate stats from 10240 documents (1056370 virtual)
2025-12-20 23:22:41,395 INFO gensim.topic_coherence.text_analysis: 161 batches submitted to accumulate stats from 10304 documents (1062228 virtual)
2025-12-20 23:22:41,407 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (1074392 virtual)
2025-12-20 23:22:41,426 INFO gensim.topic_coherence.text_analysis: 163 batches submitted to accumulate stats from 10432 documents (1078963 virtual)
2025-12-20 23:22:41,430 INFO gensim.topic_coherence.text_analysis: 164 batches submitted to accumulate stats from 10496 documents (1082443 virtual)
2025-12-20 23:22:41,435 INFO gensim.topic_coherence.text_analysis: 165 batches submitted to accumulate stats from 10560 documents (1088508 virtual)
2025-12-20 23:22:41,435 INFO gensim.topic_coherence.text_analysis: 166 batches submitted to accumulate stats from 10624 documents (1093083 virtual)
2025-12-20 23:22:41,442 INFO gensim.topic_coherence.text_analysis: 167 batches submitted to accumulate stats from 10688 documents (1096984 virtual)
2025-12-20 23:22:41,454 INFO gensim.topic_coherence.text_analysis: 168 batches submitted to accumulate stats from 10752 documents (1101614 virtual)
2025-12-20 23:22:41,466 INFO gensim.topic_coherence.text_analysis: 169 batches submitted to accumulate stats from 10816 documents (1105041 virtual)
2025-12-20 23:22:41,471 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (1112474 virtual)
2025-12-20 23:22:41,472 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (1119161 virtual)
2025-12-20 23:22:41,490 INFO gensim.topic_coherence.text_analysis: 172 batches submitted to accumulate stats from 11008 documents (1123702 virtual)
2025-12-20 23:22:41,498 INFO gensim.topic_coherence.text_analysis: 173 batches submitted to accumulate stats from 11072 documents (1123966 virtual)
2025-12-20 23:22:41,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,926 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,954 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,954 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,978 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:41,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,993 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,994 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,010 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,022 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,025 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:41,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,030 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,074 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,074 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,082 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,098 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,128 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,152 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,164 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,254 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,262 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,278 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,289 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,394 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,410 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:42,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:42,757 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:43,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:43,094 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:43,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:43,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:22:43,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:22:45,599 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:22:45,664 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1127780 virtual documents
2025-12-20 23:22:47,203 INFO src.utils.bertopic_utils: Fitting BERTopic model BERTopicCobwebWrapper on 11014 docs

Training CobwebTree:   0%|          | 0/11014 [00:00<?, ?it/s]
Training CobwebTree:   0%|          | 23/11014 [00:00<00:48, 224.45it/s]
Training CobwebTree:   0%|          | 46/11014 [00:00<01:07, 163.15it/s]
Training CobwebTree:   1%|          | 64/11014 [00:00<01:20, 136.11it/s]
Training CobwebTree:   1%|          | 79/11014 [00:00<01:22, 131.79it/s]
Training CobwebTree:   1%|          | 93/11014 [00:00<01:30, 121.14it/s]
Training CobwebTree:   1%|          | 106/11014 [00:00<01:33, 117.02it/s]
Training CobwebTree:   1%|          | 118/11014 [00:00<01:33, 116.10it/s]
Training CobwebTree:   1%|          | 130/11014 [00:01<01:37, 111.65it/s]
Training CobwebTree:   1%|         | 142/11014 [00:01<01:40, 107.97it/s]
Training CobwebTree:   1%|         | 153/11014 [00:01<01:44, 104.01it/s]
Training CobwebTree:   1%|         | 164/11014 [00:01<01:46, 101.64it/s]
Training CobwebTree:   2%|         | 175/11014 [00:01<01:49, 98.66it/s] 
Training CobwebTree:   2%|         | 185/11014 [00:01<01:49, 98.83it/s]
Training CobwebTree:   2%|         | 195/11014 [00:01<01:52, 96.26it/s]
Training CobwebTree:   2%|         | 205/11014 [00:01<01:51, 96.85it/s]
Training CobwebTree:   2%|         | 215/11014 [00:01<01:53, 95.50it/s]
Training CobwebTree:   2%|         | 225/11014 [00:02<01:58, 90.82it/s]
Training CobwebTree:   2%|         | 235/11014 [00:02<01:58, 91.05it/s]
Training CobwebTree:   2%|         | 245/11014 [00:02<01:59, 90.33it/s]
Training CobwebTree:   2%|         | 255/11014 [00:02<02:00, 89.32it/s]
Training CobwebTree:   2%|         | 264/11014 [00:02<02:04, 86.37it/s]
Training CobwebTree:   2%|         | 274/11014 [00:02<02:02, 87.70it/s]
Training CobwebTree:   3%|         | 283/11014 [00:02<02:04, 86.20it/s]
Training CobwebTree:   3%|         | 292/11014 [00:02<02:07, 84.06it/s]
Training CobwebTree:   3%|         | 301/11014 [00:02<02:08, 83.15it/s]
Training CobwebTree:   3%|         | 311/11014 [00:03<02:03, 86.61it/s]
Training CobwebTree:   3%|         | 320/11014 [00:03<02:02, 87.32it/s]
Training CobwebTree:   3%|         | 329/11014 [00:03<02:03, 86.82it/s]
Training CobwebTree:   3%|         | 338/11014 [00:03<02:03, 86.45it/s]
Training CobwebTree:   3%|         | 347/11014 [00:03<02:02, 87.07it/s]
Training CobwebTree:   3%|         | 357/11014 [00:03<02:00, 88.39it/s]
Training CobwebTree:   3%|         | 366/11014 [00:03<02:00, 88.54it/s]
Training CobwebTree:   3%|         | 375/11014 [00:03<02:04, 85.28it/s]
Training CobwebTree:   3%|         | 384/11014 [00:03<02:03, 86.06it/s]
Training CobwebTree:   4%|         | 393/11014 [00:04<02:05, 84.37it/s]
Training CobwebTree:   4%|         | 402/11014 [00:04<02:10, 81.20it/s]
Training CobwebTree:   4%|         | 411/11014 [00:04<02:12, 80.11it/s]
Training CobwebTree:   4%|         | 420/11014 [00:04<02:08, 82.55it/s]
Training CobwebTree:   4%|         | 429/11014 [00:04<02:05, 84.01it/s]
Training CobwebTree:   4%|         | 438/11014 [00:04<02:05, 84.28it/s]
Training CobwebTree:   4%|         | 447/11014 [00:04<02:07, 83.14it/s]
Training CobwebTree:   4%|         | 456/11014 [00:04<02:14, 78.52it/s]
Training CobwebTree:   4%|         | 465/11014 [00:04<02:11, 80.12it/s]
Training CobwebTree:   4%|         | 474/11014 [00:05<02:09, 81.53it/s]
Training CobwebTree:   4%|         | 483/11014 [00:05<02:10, 80.80it/s]
Training CobwebTree:   4%|         | 492/11014 [00:05<02:07, 82.24it/s]
Training CobwebTree:   5%|         | 501/11014 [00:05<02:13, 78.52it/s]
Training CobwebTree:   5%|         | 511/11014 [00:05<02:07, 82.70it/s]
Training CobwebTree:   5%|         | 520/11014 [00:05<02:06, 83.23it/s]
Training CobwebTree:   5%|         | 529/11014 [00:05<02:10, 80.32it/s]
Training CobwebTree:   5%|         | 538/11014 [00:05<02:08, 81.69it/s]
Training CobwebTree:   5%|         | 547/11014 [00:05<02:06, 82.96it/s]
Training CobwebTree:   5%|         | 556/11014 [00:06<02:11, 79.57it/s]
Training CobwebTree:   5%|         | 565/11014 [00:06<02:08, 81.01it/s]
Training CobwebTree:   5%|         | 574/11014 [00:06<02:08, 81.41it/s]
Training CobwebTree:   5%|         | 583/11014 [00:06<02:09, 80.84it/s]
Training CobwebTree:   5%|         | 592/11014 [00:06<02:17, 75.74it/s]
Training CobwebTree:   5%|         | 601/11014 [00:06<02:12, 78.85it/s]
Training CobwebTree:   6%|         | 609/11014 [00:06<02:19, 74.65it/s]
Training CobwebTree:   6%|         | 618/11014 [00:06<02:16, 76.24it/s]
Training CobwebTree:   6%|         | 626/11014 [00:06<02:17, 75.53it/s]
Training CobwebTree:   6%|         | 635/11014 [00:07<02:12, 78.09it/s]
Training CobwebTree:   6%|         | 643/11014 [00:07<02:15, 76.44it/s]
Training CobwebTree:   6%|         | 651/11014 [00:07<02:15, 76.23it/s]
Training CobwebTree:   6%|         | 660/11014 [00:07<02:14, 77.13it/s]
Training CobwebTree:   6%|         | 669/11014 [00:07<02:13, 77.70it/s]
Training CobwebTree:   6%|         | 678/11014 [00:07<02:08, 80.35it/s]
Training CobwebTree:   6%|         | 687/11014 [00:07<02:13, 77.16it/s]
Training CobwebTree:   6%|         | 695/11014 [00:07<02:13, 77.04it/s]
Training CobwebTree:   6%|         | 703/11014 [00:07<02:18, 74.57it/s]
Training CobwebTree:   6%|         | 711/11014 [00:08<02:19, 73.59it/s]
Training CobwebTree:   7%|         | 719/11014 [00:08<02:22, 72.32it/s]
Training CobwebTree:   7%|         | 727/11014 [00:08<02:20, 73.01it/s]
Training CobwebTree:   7%|         | 736/11014 [00:08<02:15, 75.88it/s]
Training CobwebTree:   7%|         | 745/11014 [00:08<02:08, 79.62it/s]
Training CobwebTree:   7%|         | 753/11014 [00:08<02:13, 76.95it/s]
Training CobwebTree:   7%|         | 761/11014 [00:08<02:12, 77.22it/s]
Training CobwebTree:   7%|         | 769/11014 [00:08<02:11, 77.95it/s]
Training CobwebTree:   7%|         | 777/11014 [00:08<02:14, 76.31it/s]
Training CobwebTree:   7%|         | 785/11014 [00:09<02:12, 77.26it/s]
Training CobwebTree:   7%|         | 793/11014 [00:09<02:10, 78.03it/s]
Training CobwebTree:   7%|         | 801/11014 [00:09<02:11, 77.83it/s]
Training CobwebTree:   7%|         | 809/11014 [00:09<02:10, 78.42it/s]
Training CobwebTree:   7%|         | 817/11014 [00:09<02:09, 78.59it/s]
Training CobwebTree:   7%|         | 826/11014 [00:09<02:07, 80.07it/s]
Training CobwebTree:   8%|         | 835/11014 [00:09<02:09, 78.84it/s]
Training CobwebTree:   8%|         | 843/11014 [00:09<02:08, 79.11it/s]
Training CobwebTree:   8%|         | 851/11014 [00:09<02:10, 77.82it/s]
Training CobwebTree:   8%|         | 859/11014 [00:09<02:17, 73.85it/s]
Training CobwebTree:   8%|         | 867/11014 [00:10<02:16, 74.33it/s]
Training CobwebTree:   8%|         | 876/11014 [00:10<02:12, 76.71it/s]
Training CobwebTree:   8%|         | 884/11014 [00:10<02:13, 75.90it/s]
Training CobwebTree:   8%|         | 892/11014 [00:10<02:12, 76.31it/s]
Training CobwebTree:   8%|         | 900/11014 [00:10<02:11, 77.09it/s]
Training CobwebTree:   8%|         | 909/11014 [00:10<02:07, 79.09it/s]
Training CobwebTree:   8%|         | 917/11014 [00:10<02:11, 77.03it/s]
Training CobwebTree:   8%|         | 926/11014 [00:10<02:06, 80.06it/s]
Training CobwebTree:   8%|         | 935/11014 [00:10<02:12, 76.12it/s]
Training CobwebTree:   9%|         | 943/11014 [00:11<02:17, 73.40it/s]
Training CobwebTree:   9%|         | 952/11014 [00:11<02:12, 75.85it/s]
Training CobwebTree:   9%|         | 960/11014 [00:11<02:14, 75.02it/s]
Training CobwebTree:   9%|         | 968/11014 [00:11<02:14, 74.84it/s]
Training CobwebTree:   9%|         | 976/11014 [00:11<02:18, 72.31it/s]
Training CobwebTree:   9%|         | 984/11014 [00:11<02:16, 73.61it/s]
Training CobwebTree:   9%|         | 992/11014 [00:11<02:15, 73.73it/s]
Training CobwebTree:   9%|         | 1000/11014 [00:11<02:15, 73.92it/s]
Training CobwebTree:   9%|         | 1008/11014 [00:11<02:14, 74.45it/s]
Training CobwebTree:   9%|         | 1017/11014 [00:12<02:10, 76.47it/s]
Training CobwebTree:   9%|         | 1025/11014 [00:12<02:14, 74.27it/s]
Training CobwebTree:   9%|         | 1033/11014 [00:12<02:16, 73.32it/s]
Training CobwebTree:   9%|         | 1041/11014 [00:12<02:19, 71.55it/s]
Training CobwebTree:  10%|         | 1049/11014 [00:12<02:18, 72.20it/s]
Training CobwebTree:  10%|         | 1057/11014 [00:12<02:17, 72.57it/s]
Training CobwebTree:  10%|         | 1066/11014 [00:12<02:13, 74.66it/s]
Training CobwebTree:  10%|         | 1074/11014 [00:12<02:14, 73.64it/s]
Training CobwebTree:  10%|         | 1082/11014 [00:12<02:20, 70.47it/s]
Training CobwebTree:  10%|         | 1090/11014 [00:13<02:20, 70.53it/s]
Training CobwebTree:  10%|         | 1098/11014 [00:13<02:19, 71.06it/s]
Training CobwebTree:  10%|         | 1106/11014 [00:13<02:25, 68.30it/s]
Training CobwebTree:  10%|         | 1114/11014 [00:13<02:20, 70.57it/s]
Training CobwebTree:  10%|         | 1122/11014 [00:13<02:16, 72.26it/s]
Training CobwebTree:  10%|         | 1130/11014 [00:13<02:16, 72.19it/s]
Training CobwebTree:  10%|         | 1138/11014 [00:13<02:13, 74.07it/s]
Training CobwebTree:  10%|         | 1146/11014 [00:13<02:12, 74.65it/s]
Training CobwebTree:  10%|         | 1154/11014 [00:13<02:16, 72.35it/s]
Training CobwebTree:  11%|         | 1162/11014 [00:14<02:19, 70.49it/s]
Training CobwebTree:  11%|         | 1170/11014 [00:14<02:20, 70.26it/s]
Training CobwebTree:  11%|         | 1178/11014 [00:14<02:17, 71.39it/s]
Training CobwebTree:  11%|         | 1186/11014 [00:14<02:16, 71.75it/s]
Training CobwebTree:  11%|         | 1194/11014 [00:14<02:18, 70.90it/s]
Training CobwebTree:  11%|         | 1202/11014 [00:14<02:24, 67.91it/s]
Training CobwebTree:  11%|         | 1209/11014 [00:14<02:24, 68.04it/s]
Training CobwebTree:  11%|         | 1217/11014 [00:14<02:18, 70.63it/s]
Training CobwebTree:  11%|         | 1225/11014 [00:14<02:18, 70.85it/s]
Training CobwebTree:  11%|         | 1233/11014 [00:15<02:19, 69.98it/s]
Training CobwebTree:  11%|        | 1241/11014 [00:15<02:21, 69.29it/s]
Training CobwebTree:  11%|        | 1248/11014 [00:15<02:20, 69.28it/s]
Training CobwebTree:  11%|        | 1256/11014 [00:15<02:19, 69.79it/s]
Training CobwebTree:  11%|        | 1264/11014 [00:15<02:15, 72.09it/s]
Training CobwebTree:  12%|        | 1272/11014 [00:15<02:13, 72.77it/s]
Training CobwebTree:  12%|        | 1280/11014 [00:15<02:19, 69.90it/s]
Training CobwebTree:  12%|        | 1288/11014 [00:15<02:21, 68.52it/s]
Training CobwebTree:  12%|        | 1296/11014 [00:15<02:21, 68.75it/s]
Training CobwebTree:  12%|        | 1304/11014 [00:16<02:18, 69.94it/s]
Training CobwebTree:  12%|        | 1312/11014 [00:16<02:17, 70.53it/s]
Training CobwebTree:  12%|        | 1320/11014 [00:16<02:20, 69.12it/s]
Training CobwebTree:  12%|        | 1327/11014 [00:16<02:22, 68.15it/s]
Training CobwebTree:  12%|        | 1335/11014 [00:16<02:19, 69.52it/s]
Training CobwebTree:  12%|        | 1342/11014 [00:16<02:20, 69.05it/s]
Training CobwebTree:  12%|        | 1349/11014 [00:16<02:23, 67.42it/s]
Training CobwebTree:  12%|        | 1356/11014 [00:16<02:25, 66.59it/s]
Training CobwebTree:  12%|        | 1364/11014 [00:16<02:20, 68.45it/s]
Training CobwebTree:  12%|        | 1372/11014 [00:17<02:20, 68.82it/s]
Training CobwebTree:  13%|        | 1381/11014 [00:17<02:10, 73.58it/s]
Training CobwebTree:  13%|        | 1389/11014 [00:17<02:10, 73.62it/s]
Training CobwebTree:  13%|        | 1397/11014 [00:17<02:11, 73.33it/s]
Training CobwebTree:  13%|        | 1405/11014 [00:17<02:11, 73.12it/s]
Training CobwebTree:  13%|        | 1413/11014 [00:17<02:10, 73.29it/s]
Training CobwebTree:  13%|        | 1421/11014 [00:17<02:16, 70.33it/s]
Training CobwebTree:  13%|        | 1429/11014 [00:17<02:16, 70.00it/s]
Training CobwebTree:  13%|        | 1437/11014 [00:18<02:19, 68.49it/s]
Training CobwebTree:  13%|        | 1445/11014 [00:18<02:15, 70.40it/s]
Training CobwebTree:  13%|        | 1453/11014 [00:18<02:16, 69.89it/s]
Training CobwebTree:  13%|        | 1461/11014 [00:18<02:21, 67.68it/s]
Training CobwebTree:  13%|        | 1468/11014 [00:18<02:21, 67.62it/s]
Training CobwebTree:  13%|        | 1475/11014 [00:18<02:20, 67.97it/s]
Training CobwebTree:  13%|        | 1482/11014 [00:18<02:20, 67.72it/s]
Training CobwebTree:  14%|        | 1490/11014 [00:18<02:15, 70.19it/s]
Training CobwebTree:  14%|        | 1498/11014 [00:18<02:10, 72.69it/s]
Training CobwebTree:  14%|        | 1506/11014 [00:18<02:13, 71.39it/s]
Training CobwebTree:  14%|        | 1514/11014 [00:19<02:15, 70.04it/s]
Training CobwebTree:  14%|        | 1522/11014 [00:19<02:14, 70.64it/s]
Training CobwebTree:  14%|        | 1530/11014 [00:19<02:17, 69.16it/s]
Training CobwebTree:  14%|        | 1537/11014 [00:19<02:17, 69.07it/s]
Training CobwebTree:  14%|        | 1545/11014 [00:19<02:14, 70.16it/s]
Training CobwebTree:  14%|        | 1553/11014 [00:19<02:11, 71.68it/s]
Training CobwebTree:  14%|        | 1561/11014 [00:19<02:15, 69.88it/s]
Training CobwebTree:  14%|        | 1569/11014 [00:19<02:15, 69.67it/s]
Training CobwebTree:  14%|        | 1576/11014 [00:19<02:17, 68.76it/s]
Training CobwebTree:  14%|        | 1584/11014 [00:20<02:12, 70.97it/s]
Training CobwebTree:  14%|        | 1592/11014 [00:20<02:13, 70.40it/s]
Training CobwebTree:  15%|        | 1600/11014 [00:20<02:14, 69.87it/s]
Training CobwebTree:  15%|        | 1607/11014 [00:20<02:18, 68.15it/s]
Training CobwebTree:  15%|        | 1615/11014 [00:20<02:17, 68.52it/s]
Training CobwebTree:  15%|        | 1623/11014 [00:20<02:16, 69.05it/s]
Training CobwebTree:  15%|        | 1630/11014 [00:20<02:15, 69.13it/s]
Training CobwebTree:  15%|        | 1638/11014 [00:20<02:11, 71.37it/s]
Training CobwebTree:  15%|        | 1646/11014 [00:20<02:13, 70.04it/s]
Training CobwebTree:  15%|        | 1654/11014 [00:21<02:12, 70.73it/s]
Training CobwebTree:  15%|        | 1662/11014 [00:21<02:12, 70.71it/s]
Training CobwebTree:  15%|        | 1670/11014 [00:21<02:13, 69.84it/s]
Training CobwebTree:  15%|        | 1678/11014 [00:21<02:12, 70.56it/s]
Training CobwebTree:  15%|        | 1686/11014 [00:21<02:14, 69.16it/s]
Training CobwebTree:  15%|        | 1693/11014 [00:21<02:15, 68.89it/s]
Training CobwebTree:  15%|        | 1700/11014 [00:21<02:16, 68.37it/s]
Training CobwebTree:  15%|        | 1707/11014 [00:21<02:17, 67.88it/s]
Training CobwebTree:  16%|        | 1714/11014 [00:21<02:16, 67.90it/s]
Training CobwebTree:  16%|        | 1721/11014 [00:22<02:16, 68.33it/s]
Training CobwebTree:  16%|        | 1728/11014 [00:22<02:16, 68.20it/s]
Training CobwebTree:  16%|        | 1736/11014 [00:22<02:14, 69.03it/s]
Training CobwebTree:  16%|        | 1744/11014 [00:22<02:09, 71.37it/s]
Training CobwebTree:  16%|        | 1752/11014 [00:22<02:13, 69.53it/s]
Training CobwebTree:  16%|        | 1759/11014 [00:22<02:17, 67.41it/s]
Training CobwebTree:  16%|        | 1766/11014 [00:22<02:17, 67.22it/s]
Training CobwebTree:  16%|        | 1774/11014 [00:22<02:14, 68.65it/s]
Training CobwebTree:  16%|        | 1782/11014 [00:22<02:10, 70.62it/s]
Training CobwebTree:  16%|        | 1790/11014 [00:23<02:12, 69.57it/s]
Training CobwebTree:  16%|        | 1798/11014 [00:23<02:11, 69.84it/s]
Training CobwebTree:  16%|        | 1805/11014 [00:23<02:11, 69.85it/s]
Training CobwebTree:  16%|        | 1812/11014 [00:23<02:14, 68.43it/s]
Training CobwebTree:  17%|        | 1820/11014 [00:23<02:12, 69.58it/s]
Training CobwebTree:  17%|        | 1828/11014 [00:23<02:11, 69.70it/s]
Training CobwebTree:  17%|        | 1836/11014 [00:23<02:09, 70.69it/s]
Training CobwebTree:  17%|        | 1844/11014 [00:23<02:09, 70.79it/s]
Training CobwebTree:  17%|        | 1852/11014 [00:23<02:11, 69.72it/s]
Training CobwebTree:  17%|        | 1860/11014 [00:24<02:09, 70.90it/s]
Training CobwebTree:  17%|        | 1868/11014 [00:24<02:10, 69.93it/s]
Training CobwebTree:  17%|        | 1876/11014 [00:24<02:17, 66.26it/s]
Training CobwebTree:  17%|        | 1883/11014 [00:24<02:19, 65.58it/s]
Training CobwebTree:  17%|        | 1890/11014 [00:24<02:20, 64.75it/s]
Training CobwebTree:  17%|        | 1897/11014 [00:24<02:21, 64.39it/s]
Training CobwebTree:  17%|        | 1904/11014 [00:24<02:18, 65.60it/s]
Training CobwebTree:  17%|        | 1911/11014 [00:24<02:19, 65.13it/s]
Training CobwebTree:  17%|        | 1918/11014 [00:24<02:20, 64.55it/s]
Training CobwebTree:  17%|        | 1925/11014 [00:25<02:20, 64.85it/s]
Training CobwebTree:  18%|        | 1933/11014 [00:25<02:15, 67.02it/s]
Training CobwebTree:  18%|        | 1940/11014 [00:25<02:20, 64.41it/s]
Training CobwebTree:  18%|        | 1947/11014 [00:25<02:17, 65.70it/s]
Training CobwebTree:  18%|        | 1954/11014 [00:25<02:17, 65.92it/s]
Training CobwebTree:  18%|        | 1961/11014 [00:25<02:18, 65.51it/s]
Training CobwebTree:  18%|        | 1968/11014 [00:25<02:18, 65.36it/s]
Training CobwebTree:  18%|        | 1975/11014 [00:25<02:17, 65.70it/s]
Training CobwebTree:  18%|        | 1982/11014 [00:25<02:17, 65.91it/s]
Training CobwebTree:  18%|        | 1989/11014 [00:26<02:17, 65.72it/s]
Training CobwebTree:  18%|        | 1996/11014 [00:26<02:15, 66.58it/s]
Training CobwebTree:  18%|        | 2003/11014 [00:26<02:15, 66.65it/s]
Training CobwebTree:  18%|        | 2010/11014 [00:26<02:19, 64.63it/s]
Training CobwebTree:  18%|        | 2018/11014 [00:26<02:10, 68.93it/s]
Training CobwebTree:  18%|        | 2026/11014 [00:26<02:07, 70.58it/s]
Training CobwebTree:  18%|        | 2034/11014 [00:26<02:12, 67.86it/s]
Training CobwebTree:  19%|        | 2041/11014 [00:26<02:17, 65.31it/s]
Training CobwebTree:  19%|        | 2048/11014 [00:26<02:15, 66.12it/s]
Training CobwebTree:  19%|        | 2056/11014 [00:27<02:12, 67.75it/s]
Training CobwebTree:  19%|        | 2064/11014 [00:27<02:08, 69.65it/s]
Training CobwebTree:  19%|        | 2071/11014 [00:27<02:15, 66.11it/s]
Training CobwebTree:  19%|        | 2078/11014 [00:27<02:17, 65.03it/s]
Training CobwebTree:  19%|        | 2086/11014 [00:27<02:12, 67.14it/s]
Training CobwebTree:  19%|        | 2093/11014 [00:27<02:11, 67.79it/s]
Training CobwebTree:  19%|        | 2100/11014 [00:27<02:19, 64.09it/s]
Training CobwebTree:  19%|        | 2107/11014 [00:27<02:19, 63.65it/s]
Training CobwebTree:  19%|        | 2114/11014 [00:27<02:17, 64.56it/s]
Training CobwebTree:  19%|        | 2121/11014 [00:28<02:17, 64.88it/s]
Training CobwebTree:  19%|        | 2128/11014 [00:28<02:18, 64.15it/s]
Training CobwebTree:  19%|        | 2136/11014 [00:28<02:13, 66.53it/s]
Training CobwebTree:  19%|        | 2143/11014 [00:28<02:16, 65.22it/s]
Training CobwebTree:  20%|        | 2150/11014 [00:28<02:14, 65.67it/s]
Training CobwebTree:  20%|        | 2157/11014 [00:28<02:14, 65.93it/s]
Training CobwebTree:  20%|        | 2164/11014 [00:28<02:16, 65.00it/s]
Training CobwebTree:  20%|        | 2171/11014 [00:28<02:16, 64.55it/s]
Training CobwebTree:  20%|        | 2178/11014 [00:28<02:17, 64.38it/s]
Training CobwebTree:  20%|        | 2185/11014 [00:29<02:17, 64.10it/s]
Training CobwebTree:  20%|        | 2192/11014 [00:29<02:15, 65.22it/s]
Training CobwebTree:  20%|        | 2199/11014 [00:29<02:12, 66.53it/s]
Training CobwebTree:  20%|        | 2207/11014 [00:29<02:10, 67.53it/s]
Training CobwebTree:  20%|        | 2214/11014 [00:29<02:10, 67.24it/s]
Training CobwebTree:  20%|        | 2221/11014 [00:29<02:12, 66.45it/s]
Training CobwebTree:  20%|        | 2228/11014 [00:29<02:14, 65.41it/s]
Training CobwebTree:  20%|        | 2235/11014 [00:29<02:11, 66.51it/s]
Training CobwebTree:  20%|        | 2242/11014 [00:29<02:11, 66.50it/s]
Training CobwebTree:  20%|        | 2249/11014 [00:30<02:16, 64.29it/s]
Training CobwebTree:  20%|        | 2256/11014 [00:30<02:15, 64.68it/s]
Training CobwebTree:  21%|        | 2263/11014 [00:30<02:13, 65.37it/s]
Training CobwebTree:  21%|        | 2270/11014 [00:30<02:14, 64.80it/s]
Training CobwebTree:  21%|        | 2277/11014 [00:30<02:17, 63.38it/s]
Training CobwebTree:  21%|        | 2285/11014 [00:30<02:11, 66.38it/s]
Training CobwebTree:  21%|        | 2292/11014 [00:30<02:15, 64.30it/s]
Training CobwebTree:  21%|        | 2299/11014 [00:30<02:19, 62.30it/s]
Training CobwebTree:  21%|        | 2306/11014 [00:30<02:22, 61.23it/s]
Training CobwebTree:  21%|        | 2313/11014 [00:31<02:16, 63.54it/s]
Training CobwebTree:  21%|        | 2321/11014 [00:31<02:11, 65.96it/s]
Training CobwebTree:  21%|        | 2328/11014 [00:31<02:13, 65.26it/s]
Training CobwebTree:  21%|        | 2335/11014 [00:31<02:12, 65.50it/s]
Training CobwebTree:  21%|       | 2342/11014 [00:31<02:16, 63.49it/s]
Training CobwebTree:  21%|       | 2349/11014 [00:31<02:16, 63.29it/s]
Training CobwebTree:  21%|       | 2357/11014 [00:31<02:11, 65.65it/s]
Training CobwebTree:  21%|       | 2364/11014 [00:31<02:13, 65.03it/s]
Training CobwebTree:  22%|       | 2371/11014 [00:31<02:13, 64.95it/s]
Training CobwebTree:  22%|       | 2378/11014 [00:32<02:17, 62.91it/s]
Training CobwebTree:  22%|       | 2385/11014 [00:32<02:15, 63.76it/s]
Training CobwebTree:  22%|       | 2392/11014 [00:32<02:18, 62.06it/s]
Training CobwebTree:  22%|       | 2399/11014 [00:32<02:19, 61.60it/s]
Training CobwebTree:  22%|       | 2406/11014 [00:32<02:20, 61.35it/s]
Training CobwebTree:  22%|       | 2413/11014 [00:32<02:19, 61.86it/s]
Training CobwebTree:  22%|       | 2421/11014 [00:32<02:13, 64.37it/s]
Training CobwebTree:  22%|       | 2428/11014 [00:32<02:12, 64.64it/s]
Training CobwebTree:  22%|       | 2435/11014 [00:32<02:14, 63.62it/s]
Training CobwebTree:  22%|       | 2442/11014 [00:33<02:13, 64.10it/s]
Training CobwebTree:  22%|       | 2449/11014 [00:33<02:15, 63.07it/s]
Training CobwebTree:  22%|       | 2456/11014 [00:33<02:16, 62.88it/s]
Training CobwebTree:  22%|       | 2463/11014 [00:33<02:12, 64.53it/s]
Training CobwebTree:  22%|       | 2471/11014 [00:33<02:08, 66.57it/s]
Training CobwebTree:  22%|       | 2478/11014 [00:33<02:12, 64.18it/s]
Training CobwebTree:  23%|       | 2485/11014 [00:33<02:10, 65.45it/s]
Training CobwebTree:  23%|       | 2492/11014 [00:33<02:11, 64.56it/s]
Training CobwebTree:  23%|       | 2499/11014 [00:33<02:11, 64.79it/s]
Training CobwebTree:  23%|       | 2507/11014 [00:34<02:08, 66.42it/s]
Training CobwebTree:  23%|       | 2514/11014 [00:34<02:09, 65.42it/s]
Training CobwebTree:  23%|       | 2521/11014 [00:34<02:10, 64.95it/s]
Training CobwebTree:  23%|       | 2528/11014 [00:34<02:20, 60.51it/s]
Training CobwebTree:  23%|       | 2535/11014 [00:34<02:18, 61.33it/s]
Training CobwebTree:  23%|       | 2542/11014 [00:34<02:16, 61.96it/s]
Training CobwebTree:  23%|       | 2549/11014 [00:34<02:12, 63.72it/s]
Training CobwebTree:  23%|       | 2556/11014 [00:34<02:13, 63.17it/s]
Training CobwebTree:  23%|       | 2563/11014 [00:34<02:11, 64.34it/s]
Training CobwebTree:  23%|       | 2570/11014 [00:35<02:11, 64.09it/s]
Training CobwebTree:  23%|       | 2577/11014 [00:35<02:10, 64.75it/s]
Training CobwebTree:  23%|       | 2584/11014 [00:35<02:13, 63.12it/s]
Training CobwebTree:  24%|       | 2591/11014 [00:35<02:11, 63.93it/s]
Training CobwebTree:  24%|       | 2599/11014 [00:35<02:05, 66.95it/s]
Training CobwebTree:  24%|       | 2606/11014 [00:35<02:10, 64.32it/s]
Training CobwebTree:  24%|       | 2613/11014 [00:35<02:10, 64.41it/s]
Training CobwebTree:  24%|       | 2620/11014 [00:35<02:10, 64.24it/s]
Training CobwebTree:  24%|       | 2627/11014 [00:35<02:12, 63.17it/s]
Training CobwebTree:  24%|       | 2634/11014 [00:36<02:13, 62.82it/s]
Training CobwebTree:  24%|       | 2641/11014 [00:36<02:11, 63.89it/s]
Training CobwebTree:  24%|       | 2648/11014 [00:36<02:11, 63.78it/s]
Training CobwebTree:  24%|       | 2655/11014 [00:36<02:10, 64.09it/s]
Training CobwebTree:  24%|       | 2662/11014 [00:36<02:10, 63.97it/s]
Training CobwebTree:  24%|       | 2669/11014 [00:36<02:12, 63.08it/s]
Training CobwebTree:  24%|       | 2676/11014 [00:36<02:12, 62.86it/s]
Training CobwebTree:  24%|       | 2683/11014 [00:36<02:09, 64.55it/s]
Training CobwebTree:  24%|       | 2690/11014 [00:36<02:06, 66.00it/s]
Training CobwebTree:  24%|       | 2697/11014 [00:36<02:04, 66.67it/s]
Training CobwebTree:  25%|       | 2704/11014 [00:37<02:07, 65.41it/s]
Training CobwebTree:  25%|       | 2711/11014 [00:37<02:09, 64.05it/s]
Training CobwebTree:  25%|       | 2718/11014 [00:37<02:12, 62.59it/s]
Training CobwebTree:  25%|       | 2725/11014 [00:37<02:10, 63.28it/s]
Training CobwebTree:  25%|       | 2732/11014 [00:37<02:07, 64.98it/s]
Training CobwebTree:  25%|       | 2739/11014 [00:37<02:09, 64.00it/s]
Training CobwebTree:  25%|       | 2746/11014 [00:37<02:08, 64.25it/s]
Training CobwebTree:  25%|       | 2753/11014 [00:37<02:06, 65.52it/s]
Training CobwebTree:  25%|       | 2760/11014 [00:37<02:08, 64.30it/s]
Training CobwebTree:  25%|       | 2767/11014 [00:38<02:11, 62.86it/s]
Training CobwebTree:  25%|       | 2774/11014 [00:38<02:13, 61.63it/s]
Training CobwebTree:  25%|       | 2782/11014 [00:38<02:06, 64.93it/s]
Training CobwebTree:  25%|       | 2789/11014 [00:38<02:05, 65.37it/s]
Training CobwebTree:  25%|       | 2796/11014 [00:38<02:05, 65.25it/s]
Training CobwebTree:  25%|       | 2803/11014 [00:38<02:06, 64.76it/s]
Training CobwebTree:  26%|       | 2810/11014 [00:38<02:11, 62.57it/s]
Training CobwebTree:  26%|       | 2817/11014 [00:38<02:11, 62.14it/s]
Training CobwebTree:  26%|       | 2824/11014 [00:39<02:12, 61.84it/s]
Training CobwebTree:  26%|       | 2831/11014 [00:39<02:11, 62.43it/s]
Training CobwebTree:  26%|       | 2838/11014 [00:39<02:09, 63.06it/s]
Training CobwebTree:  26%|       | 2845/11014 [00:39<02:11, 62.03it/s]
Training CobwebTree:  26%|       | 2852/11014 [00:39<02:15, 60.32it/s]
Training CobwebTree:  26%|       | 2859/11014 [00:39<02:10, 62.47it/s]
Training CobwebTree:  26%|       | 2866/11014 [00:39<02:12, 61.53it/s]
Training CobwebTree:  26%|       | 2873/11014 [00:39<02:11, 62.01it/s]
Training CobwebTree:  26%|       | 2880/11014 [00:39<02:11, 61.65it/s]
Training CobwebTree:  26%|       | 2887/11014 [00:40<02:14, 60.33it/s]
Training CobwebTree:  26%|       | 2894/11014 [00:40<02:14, 60.18it/s]
Training CobwebTree:  26%|       | 2901/11014 [00:40<02:11, 61.77it/s]
Training CobwebTree:  26%|       | 2908/11014 [00:40<02:12, 61.32it/s]
Training CobwebTree:  26%|       | 2915/11014 [00:40<02:10, 62.05it/s]
Training CobwebTree:  27%|       | 2922/11014 [00:40<02:08, 62.97it/s]
Training CobwebTree:  27%|       | 2929/11014 [00:40<02:08, 62.88it/s]
Training CobwebTree:  27%|       | 2936/11014 [00:40<02:05, 64.13it/s]
Training CobwebTree:  27%|       | 2943/11014 [00:40<02:08, 62.71it/s]
Training CobwebTree:  27%|       | 2950/11014 [00:41<02:08, 62.83it/s]
Training CobwebTree:  27%|       | 2957/11014 [00:41<02:06, 63.70it/s]
Training CobwebTree:  27%|       | 2964/11014 [00:41<02:05, 64.01it/s]
Training CobwebTree:  27%|       | 2971/11014 [00:41<02:05, 64.12it/s]
Training CobwebTree:  27%|       | 2978/11014 [00:41<02:04, 64.51it/s]
Training CobwebTree:  27%|       | 2985/11014 [00:41<02:02, 65.67it/s]
Training CobwebTree:  27%|       | 2992/11014 [00:41<02:01, 65.94it/s]
Training CobwebTree:  27%|       | 2999/11014 [00:41<02:02, 65.31it/s]
Training CobwebTree:  27%|       | 3006/11014 [00:41<02:06, 63.30it/s]
Training CobwebTree:  27%|       | 3013/11014 [00:42<02:07, 62.89it/s]
Training CobwebTree:  27%|       | 3020/11014 [00:42<02:07, 62.89it/s]
Training CobwebTree:  27%|       | 3027/11014 [00:42<02:11, 60.87it/s]
Training CobwebTree:  28%|       | 3034/11014 [00:42<02:11, 60.59it/s]
Training CobwebTree:  28%|       | 3041/11014 [00:42<02:14, 59.11it/s]
Training CobwebTree:  28%|       | 3048/11014 [00:42<02:14, 59.30it/s]
Training CobwebTree:  28%|       | 3054/11014 [00:42<02:16, 58.47it/s]
Training CobwebTree:  28%|       | 3061/11014 [00:42<02:09, 61.32it/s]
Training CobwebTree:  28%|       | 3069/11014 [00:42<02:01, 65.33it/s]
Training CobwebTree:  28%|       | 3076/11014 [00:43<02:05, 63.32it/s]
Training CobwebTree:  28%|       | 3083/11014 [00:43<02:04, 63.45it/s]
Training CobwebTree:  28%|       | 3090/11014 [00:43<02:04, 63.58it/s]
Training CobwebTree:  28%|       | 3097/11014 [00:43<02:01, 65.17it/s]
Training CobwebTree:  28%|       | 3104/11014 [00:43<02:00, 65.62it/s]
Training CobwebTree:  28%|       | 3111/11014 [00:43<01:58, 66.77it/s]
Training CobwebTree:  28%|       | 3118/11014 [00:43<01:59, 65.97it/s]
Training CobwebTree:  28%|       | 3125/11014 [00:43<02:01, 64.67it/s]
Training CobwebTree:  28%|       | 3132/11014 [00:43<02:07, 61.90it/s]
Training CobwebTree:  29%|       | 3139/11014 [00:44<02:09, 60.77it/s]
Training CobwebTree:  29%|       | 3146/11014 [00:44<02:04, 63.25it/s]
Training CobwebTree:  29%|       | 3153/11014 [00:44<02:02, 64.32it/s]
Training CobwebTree:  29%|       | 3160/11014 [00:44<02:03, 63.51it/s]
Training CobwebTree:  29%|       | 3167/11014 [00:44<02:05, 62.44it/s]
Training CobwebTree:  29%|       | 3175/11014 [00:44<02:02, 63.99it/s]
Training CobwebTree:  29%|       | 3182/11014 [00:44<02:04, 62.80it/s]
Training CobwebTree:  29%|       | 3189/11014 [00:44<02:02, 63.90it/s]
Training CobwebTree:  29%|       | 3196/11014 [00:44<02:01, 64.15it/s]
Training CobwebTree:  29%|       | 3203/11014 [00:45<02:02, 63.88it/s]
Training CobwebTree:  29%|       | 3210/11014 [00:45<01:59, 65.11it/s]
Training CobwebTree:  29%|       | 3217/11014 [00:45<02:00, 64.56it/s]
Training CobwebTree:  29%|       | 3224/11014 [00:45<02:01, 64.02it/s]
Training CobwebTree:  29%|       | 3231/11014 [00:45<02:04, 62.31it/s]
Training CobwebTree:  29%|       | 3238/11014 [00:45<02:04, 62.45it/s]
Training CobwebTree:  29%|       | 3245/11014 [00:45<02:08, 60.44it/s]
Training CobwebTree:  30%|       | 3252/11014 [00:45<02:06, 61.42it/s]
Training CobwebTree:  30%|       | 3259/11014 [00:45<02:08, 60.20it/s]
Training CobwebTree:  30%|       | 3266/11014 [00:46<02:05, 61.58it/s]
Training CobwebTree:  30%|       | 3273/11014 [00:46<02:04, 62.03it/s]
Training CobwebTree:  30%|       | 3280/11014 [00:46<02:02, 63.18it/s]
Training CobwebTree:  30%|       | 3288/11014 [00:46<01:57, 65.50it/s]
Training CobwebTree:  30%|       | 3295/11014 [00:46<02:01, 63.31it/s]
Training CobwebTree:  30%|       | 3302/11014 [00:46<02:01, 63.38it/s]
Training CobwebTree:  30%|       | 3309/11014 [00:46<01:59, 64.60it/s]
Training CobwebTree:  30%|       | 3316/11014 [00:46<02:01, 63.36it/s]
Training CobwebTree:  30%|       | 3323/11014 [00:46<02:00, 63.61it/s]
Training CobwebTree:  30%|       | 3330/11014 [00:47<02:02, 62.55it/s]
Training CobwebTree:  30%|       | 3337/11014 [00:47<02:02, 62.90it/s]
Training CobwebTree:  30%|       | 3344/11014 [00:47<02:00, 63.76it/s]
Training CobwebTree:  30%|       | 3351/11014 [00:47<02:00, 63.47it/s]
Training CobwebTree:  30%|       | 3358/11014 [00:47<01:59, 63.91it/s]
Training CobwebTree:  31%|       | 3365/11014 [00:47<01:58, 64.82it/s]
Training CobwebTree:  31%|       | 3372/11014 [00:47<01:57, 65.05it/s]
Training CobwebTree:  31%|       | 3379/11014 [00:47<02:00, 63.57it/s]
Training CobwebTree:  31%|       | 3386/11014 [00:47<02:00, 63.50it/s]
Training CobwebTree:  31%|       | 3393/11014 [00:48<02:05, 60.75it/s]
Training CobwebTree:  31%|       | 3400/11014 [00:48<02:05, 60.50it/s]
Training CobwebTree:  31%|       | 3407/11014 [00:48<02:03, 61.55it/s]
Training CobwebTree:  31%|       | 3414/11014 [00:48<02:04, 60.99it/s]
Training CobwebTree:  31%|       | 3421/11014 [00:48<02:03, 61.24it/s]
Training CobwebTree:  31%|       | 3428/11014 [00:48<02:02, 61.74it/s]
Training CobwebTree:  31%|       | 3435/11014 [00:48<02:02, 61.78it/s]
Training CobwebTree:  31%|      | 3442/11014 [00:48<02:00, 62.88it/s]
Training CobwebTree:  31%|      | 3450/11014 [00:48<01:57, 64.50it/s]
Training CobwebTree:  31%|      | 3457/11014 [00:49<01:57, 64.37it/s]
Training CobwebTree:  31%|      | 3464/11014 [00:49<02:02, 61.79it/s]
Training CobwebTree:  32%|      | 3471/11014 [00:49<02:05, 60.27it/s]
Training CobwebTree:  32%|      | 3478/11014 [00:49<02:04, 60.44it/s]
Training CobwebTree:  32%|      | 3485/11014 [00:49<02:03, 61.19it/s]
Training CobwebTree:  32%|      | 3492/11014 [00:49<02:00, 62.64it/s]
Training CobwebTree:  32%|      | 3499/11014 [00:49<01:58, 63.32it/s]
Training CobwebTree:  32%|      | 3506/11014 [00:49<02:01, 61.60it/s]
Training CobwebTree:  32%|      | 3513/11014 [00:49<01:59, 62.69it/s]
Training CobwebTree:  32%|      | 3520/11014 [00:50<02:00, 62.18it/s]
Training CobwebTree:  32%|      | 3528/11014 [00:50<01:56, 64.28it/s]
Training CobwebTree:  32%|      | 3535/11014 [00:50<01:54, 65.26it/s]
Training CobwebTree:  32%|      | 3542/11014 [00:50<01:57, 63.78it/s]
Training CobwebTree:  32%|      | 3549/11014 [00:50<01:59, 62.24it/s]
Training CobwebTree:  32%|      | 3556/11014 [00:50<02:02, 61.06it/s]
Training CobwebTree:  32%|      | 3563/11014 [00:50<02:01, 61.39it/s]
Training CobwebTree:  32%|      | 3570/11014 [00:50<02:01, 61.02it/s]
Training CobwebTree:  32%|      | 3577/11014 [00:51<02:06, 58.87it/s]
Training CobwebTree:  33%|      | 3584/11014 [00:51<02:04, 59.79it/s]
Training CobwebTree:  33%|      | 3591/11014 [00:51<02:02, 60.35it/s]
Training CobwebTree:  33%|      | 3598/11014 [00:51<02:00, 61.76it/s]
Training CobwebTree:  33%|      | 3605/11014 [00:51<01:57, 63.15it/s]
Training CobwebTree:  33%|      | 3612/11014 [00:51<01:58, 62.47it/s]
Training CobwebTree:  33%|      | 3619/11014 [00:51<01:58, 62.45it/s]
Training CobwebTree:  33%|      | 3626/11014 [00:51<02:04, 59.11it/s]
Training CobwebTree:  33%|      | 3633/11014 [00:51<02:02, 60.06it/s]
Training CobwebTree:  33%|      | 3640/11014 [00:52<02:03, 59.78it/s]
Training CobwebTree:  33%|      | 3647/11014 [00:52<01:59, 61.44it/s]
Training CobwebTree:  33%|      | 3654/11014 [00:52<02:03, 59.39it/s]
Training CobwebTree:  33%|      | 3661/11014 [00:52<02:05, 58.63it/s]
Training CobwebTree:  33%|      | 3668/11014 [00:52<02:02, 59.76it/s]
Training CobwebTree:  33%|      | 3675/11014 [00:52<02:01, 60.38it/s]
Training CobwebTree:  33%|      | 3682/11014 [00:52<02:02, 60.09it/s]
Training CobwebTree:  33%|      | 3689/11014 [00:52<02:02, 59.88it/s]
Training CobwebTree:  34%|      | 3696/11014 [00:52<02:01, 60.25it/s]
Training CobwebTree:  34%|      | 3703/11014 [00:53<01:58, 61.90it/s]
Training CobwebTree:  34%|      | 3710/11014 [00:53<01:57, 62.05it/s]
Training CobwebTree:  34%|      | 3717/11014 [00:53<01:57, 61.98it/s]
Training CobwebTree:  34%|      | 3724/11014 [00:53<01:53, 64.01it/s]
Training CobwebTree:  34%|      | 3731/11014 [00:53<01:53, 63.94it/s]
Training CobwebTree:  34%|      | 3738/11014 [00:53<01:51, 65.41it/s]
Training CobwebTree:  34%|      | 3745/11014 [00:53<01:51, 65.36it/s]
Training CobwebTree:  34%|      | 3752/11014 [00:53<01:53, 64.11it/s]
Training CobwebTree:  34%|      | 3759/11014 [00:53<01:53, 63.66it/s]
Training CobwebTree:  34%|      | 3766/11014 [00:54<01:55, 62.65it/s]
Training CobwebTree:  34%|      | 3773/11014 [00:54<01:55, 62.88it/s]
Training CobwebTree:  34%|      | 3780/11014 [00:54<01:55, 62.70it/s]
Training CobwebTree:  34%|      | 3787/11014 [00:54<01:54, 62.90it/s]
Training CobwebTree:  34%|      | 3794/11014 [00:54<02:00, 60.16it/s]
Training CobwebTree:  35%|      | 3801/11014 [00:54<01:59, 60.41it/s]
Training CobwebTree:  35%|      | 3808/11014 [00:54<02:00, 59.66it/s]
Training CobwebTree:  35%|      | 3815/11014 [00:54<01:55, 62.27it/s]
Training CobwebTree:  35%|      | 3822/11014 [00:54<01:59, 60.21it/s]
Training CobwebTree:  35%|      | 3829/11014 [00:55<01:59, 59.98it/s]
Training CobwebTree:  35%|      | 3836/11014 [00:55<01:57, 60.93it/s]
Training CobwebTree:  35%|      | 3843/11014 [00:55<01:58, 60.28it/s]
Training CobwebTree:  35%|      | 3850/11014 [00:55<02:03, 58.00it/s]
Training CobwebTree:  35%|      | 3857/11014 [00:55<02:00, 59.26it/s]
Training CobwebTree:  35%|      | 3864/11014 [00:55<01:57, 61.10it/s]
Training CobwebTree:  35%|      | 3871/11014 [00:55<01:53, 62.69it/s]
Training CobwebTree:  35%|      | 3878/11014 [00:55<01:57, 60.60it/s]
Training CobwebTree:  35%|      | 3885/11014 [00:56<01:58, 60.07it/s]
Training CobwebTree:  35%|      | 3892/11014 [00:56<01:58, 59.89it/s]
Training CobwebTree:  35%|      | 3899/11014 [00:56<01:56, 61.15it/s]
Training CobwebTree:  35%|      | 3906/11014 [00:56<01:57, 60.36it/s]
Training CobwebTree:  36%|      | 3913/11014 [00:56<01:57, 60.26it/s]
Training CobwebTree:  36%|      | 3920/11014 [00:56<01:56, 60.80it/s]
Training CobwebTree:  36%|      | 3927/11014 [00:56<01:59, 59.54it/s]
Training CobwebTree:  36%|      | 3934/11014 [00:56<01:57, 60.43it/s]
Training CobwebTree:  36%|      | 3941/11014 [00:56<01:54, 61.62it/s]
Training CobwebTree:  36%|      | 3948/11014 [00:57<01:53, 62.37it/s]
Training CobwebTree:  36%|      | 3955/11014 [00:57<01:54, 61.60it/s]
Training CobwebTree:  36%|      | 3962/11014 [00:57<01:57, 60.17it/s]
Training CobwebTree:  36%|      | 3969/11014 [00:57<01:54, 61.38it/s]
Training CobwebTree:  36%|      | 3976/11014 [00:57<01:54, 61.73it/s]
Training CobwebTree:  36%|      | 3983/11014 [00:57<01:52, 62.52it/s]
Training CobwebTree:  36%|      | 3990/11014 [00:57<01:51, 62.77it/s]
Training CobwebTree:  36%|      | 3997/11014 [00:57<01:54, 61.51it/s]
Training CobwebTree:  36%|      | 4004/11014 [00:57<01:54, 61.35it/s]
Training CobwebTree:  36%|      | 4011/11014 [00:58<01:54, 61.40it/s]
Training CobwebTree:  36%|      | 4018/11014 [00:58<01:52, 61.98it/s]
Training CobwebTree:  37%|      | 4025/11014 [00:58<01:53, 61.75it/s]
Training CobwebTree:  37%|      | 4032/11014 [00:58<01:55, 60.67it/s]
Training CobwebTree:  37%|      | 4039/11014 [00:58<01:54, 60.78it/s]
Training CobwebTree:  37%|      | 4046/11014 [00:58<01:52, 62.13it/s]
Training CobwebTree:  37%|      | 4053/11014 [00:58<01:52, 62.06it/s]
Training CobwebTree:  37%|      | 4060/11014 [00:58<01:54, 60.94it/s]
Training CobwebTree:  37%|      | 4067/11014 [00:59<01:55, 60.05it/s]
Training CobwebTree:  37%|      | 4074/11014 [00:59<01:58, 58.55it/s]
Training CobwebTree:  37%|      | 4081/11014 [00:59<01:57, 58.87it/s]
Training CobwebTree:  37%|      | 4088/11014 [00:59<01:55, 59.90it/s]
Training CobwebTree:  37%|      | 4095/11014 [00:59<01:56, 59.27it/s]
Training CobwebTree:  37%|      | 4102/11014 [00:59<01:55, 59.73it/s]
Training CobwebTree:  37%|      | 4108/11014 [00:59<01:59, 57.85it/s]
Training CobwebTree:  37%|      | 4114/11014 [00:59<01:58, 58.29it/s]
Training CobwebTree:  37%|      | 4120/11014 [00:59<02:00, 57.21it/s]
Training CobwebTree:  37%|      | 4127/11014 [01:00<01:57, 58.48it/s]
Training CobwebTree:  38%|      | 4133/11014 [01:00<02:04, 55.44it/s]
Training CobwebTree:  38%|      | 4140/11014 [01:00<02:01, 56.73it/s]
Training CobwebTree:  38%|      | 4147/11014 [01:00<01:59, 57.52it/s]
Training CobwebTree:  38%|      | 4154/11014 [01:00<01:57, 58.30it/s]
Training CobwebTree:  38%|      | 4160/11014 [01:00<01:57, 58.34it/s]
Training CobwebTree:  38%|      | 4167/11014 [01:00<01:56, 58.69it/s]
Training CobwebTree:  38%|      | 4173/11014 [01:00<01:58, 57.90it/s]
Training CobwebTree:  38%|      | 4180/11014 [01:00<01:54, 59.47it/s]
Training CobwebTree:  38%|      | 4187/11014 [01:01<01:52, 60.61it/s]
Training CobwebTree:  38%|      | 4194/11014 [01:01<01:54, 59.77it/s]
Training CobwebTree:  38%|      | 4201/11014 [01:01<01:52, 60.78it/s]
Training CobwebTree:  38%|      | 4208/11014 [01:01<01:48, 62.57it/s]
Training CobwebTree:  38%|      | 4215/11014 [01:01<01:46, 63.98it/s]
Training CobwebTree:  38%|      | 4222/11014 [01:01<01:47, 63.46it/s]
Training CobwebTree:  38%|      | 4229/11014 [01:01<01:53, 59.95it/s]
Training CobwebTree:  38%|      | 4236/11014 [01:01<01:57, 57.49it/s]
Training CobwebTree:  39%|      | 4242/11014 [01:01<01:57, 57.75it/s]
Training CobwebTree:  39%|      | 4249/11014 [01:02<01:53, 59.53it/s]
Training CobwebTree:  39%|      | 4256/11014 [01:02<01:52, 60.21it/s]
Training CobwebTree:  39%|      | 4263/11014 [01:02<01:52, 60.23it/s]
Training CobwebTree:  39%|      | 4270/11014 [01:02<01:48, 61.98it/s]
Training CobwebTree:  39%|      | 4277/11014 [01:02<01:54, 58.76it/s]
Training CobwebTree:  39%|      | 4283/11014 [01:02<01:59, 56.53it/s]
Training CobwebTree:  39%|      | 4289/11014 [01:02<01:58, 56.79it/s]
Training CobwebTree:  39%|      | 4295/11014 [01:02<01:56, 57.61it/s]
Training CobwebTree:  39%|      | 4301/11014 [01:02<01:57, 57.18it/s]
Training CobwebTree:  39%|      | 4308/11014 [01:03<01:54, 58.70it/s]
Training CobwebTree:  39%|      | 4315/11014 [01:03<01:51, 59.92it/s]
Training CobwebTree:  39%|      | 4322/11014 [01:03<01:49, 61.30it/s]
Training CobwebTree:  39%|      | 4329/11014 [01:03<01:45, 63.12it/s]
Training CobwebTree:  39%|      | 4336/11014 [01:03<01:47, 62.36it/s]
Training CobwebTree:  39%|      | 4343/11014 [01:03<01:47, 62.16it/s]
Training CobwebTree:  39%|      | 4350/11014 [01:03<01:51, 59.73it/s]
Training CobwebTree:  40%|      | 4357/11014 [01:03<01:49, 60.59it/s]
Training CobwebTree:  40%|      | 4364/11014 [01:04<01:51, 59.68it/s]
Training CobwebTree:  40%|      | 4372/11014 [01:04<01:47, 62.03it/s]
Training CobwebTree:  40%|      | 4379/11014 [01:04<01:46, 62.13it/s]
Training CobwebTree:  40%|      | 4386/11014 [01:04<01:47, 61.44it/s]
Training CobwebTree:  40%|      | 4393/11014 [01:04<01:47, 61.83it/s]
Training CobwebTree:  40%|      | 4400/11014 [01:04<01:47, 61.37it/s]
Training CobwebTree:  40%|      | 4407/11014 [01:04<01:47, 61.66it/s]
Training CobwebTree:  40%|      | 4414/11014 [01:04<01:49, 60.15it/s]
Training CobwebTree:  40%|      | 4421/11014 [01:04<01:50, 59.43it/s]
Training CobwebTree:  40%|      | 4428/11014 [01:05<01:50, 59.83it/s]
Training CobwebTree:  40%|      | 4434/11014 [01:05<01:53, 58.21it/s]
Training CobwebTree:  40%|      | 4441/11014 [01:05<01:50, 59.67it/s]
Training CobwebTree:  40%|      | 4448/11014 [01:05<01:46, 61.43it/s]
Training CobwebTree:  40%|      | 4455/11014 [01:05<01:44, 62.81it/s]
Training CobwebTree:  41%|      | 4462/11014 [01:05<01:44, 62.55it/s]
Training CobwebTree:  41%|      | 4469/11014 [01:05<01:44, 62.34it/s]
Training CobwebTree:  41%|      | 4476/11014 [01:05<01:47, 60.64it/s]
Training CobwebTree:  41%|      | 4483/11014 [01:05<01:46, 61.19it/s]
Training CobwebTree:  41%|      | 4490/11014 [01:06<01:46, 61.47it/s]
Training CobwebTree:  41%|      | 4497/11014 [01:06<01:48, 60.05it/s]
Training CobwebTree:  41%|      | 4504/11014 [01:06<01:50, 59.12it/s]
Training CobwebTree:  41%|      | 4511/11014 [01:06<01:47, 60.66it/s]
Training CobwebTree:  41%|      | 4518/11014 [01:06<01:52, 57.86it/s]
Training CobwebTree:  41%|      | 4525/11014 [01:06<01:49, 59.50it/s]
Training CobwebTree:  41%|      | 4531/11014 [01:06<01:48, 59.58it/s]
Training CobwebTree:  41%|      | 4537/11014 [01:06<01:48, 59.46it/s]
Training CobwebTree:  41%|      | 4543/11014 [01:06<01:48, 59.54it/s]
Training CobwebTree:  41%|     | 4550/11014 [01:07<01:46, 60.67it/s]
Training CobwebTree:  41%|     | 4557/11014 [01:07<01:50, 58.50it/s]
Training CobwebTree:  41%|     | 4564/11014 [01:07<01:48, 59.56it/s]
Training CobwebTree:  42%|     | 4571/11014 [01:07<01:45, 60.97it/s]
Training CobwebTree:  42%|     | 4578/11014 [01:07<01:42, 62.57it/s]
Training CobwebTree:  42%|     | 4585/11014 [01:07<01:43, 61.92it/s]
Training CobwebTree:  42%|     | 4592/11014 [01:07<01:41, 63.52it/s]
Training CobwebTree:  42%|     | 4599/11014 [01:07<01:41, 63.19it/s]
Training CobwebTree:  42%|     | 4606/11014 [01:08<01:47, 59.36it/s]
Training CobwebTree:  42%|     | 4613/11014 [01:08<01:45, 60.88it/s]
Training CobwebTree:  42%|     | 4620/11014 [01:08<01:43, 61.85it/s]
Training CobwebTree:  42%|     | 4627/11014 [01:08<01:41, 62.73it/s]
Training CobwebTree:  42%|     | 4634/11014 [01:08<01:45, 60.70it/s]
Training CobwebTree:  42%|     | 4641/11014 [01:08<01:42, 62.35it/s]
Training CobwebTree:  42%|     | 4648/11014 [01:08<01:40, 63.05it/s]
Training CobwebTree:  42%|     | 4655/11014 [01:08<01:43, 61.58it/s]
Training CobwebTree:  42%|     | 4662/11014 [01:08<01:46, 59.74it/s]
Training CobwebTree:  42%|     | 4669/11014 [01:09<01:45, 60.10it/s]
Training CobwebTree:  42%|     | 4676/11014 [01:09<01:44, 60.47it/s]
Training CobwebTree:  43%|     | 4683/11014 [01:09<01:46, 59.20it/s]
Training CobwebTree:  43%|     | 4690/11014 [01:09<01:45, 59.99it/s]
Training CobwebTree:  43%|     | 4697/11014 [01:09<01:47, 58.93it/s]
Training CobwebTree:  43%|     | 4704/11014 [01:09<01:44, 60.36it/s]
Training CobwebTree:  43%|     | 4711/11014 [01:09<01:47, 58.65it/s]
Training CobwebTree:  43%|     | 4717/11014 [01:09<01:46, 58.99it/s]
Training CobwebTree:  43%|     | 4724/11014 [01:09<01:45, 59.59it/s]
Training CobwebTree:  43%|     | 4731/11014 [01:10<01:41, 61.78it/s]
Training CobwebTree:  43%|     | 4738/11014 [01:10<01:42, 60.99it/s]
Training CobwebTree:  43%|     | 4745/11014 [01:10<01:42, 60.91it/s]
Training CobwebTree:  43%|     | 4752/11014 [01:10<01:44, 60.08it/s]
Training CobwebTree:  43%|     | 4759/11014 [01:10<01:44, 59.60it/s]
Training CobwebTree:  43%|     | 4765/11014 [01:10<01:47, 57.94it/s]
Training CobwebTree:  43%|     | 4771/11014 [01:10<01:46, 58.49it/s]
Training CobwebTree:  43%|     | 4778/11014 [01:10<01:45, 59.35it/s]
Training CobwebTree:  43%|     | 4786/11014 [01:10<01:39, 62.71it/s]
Training CobwebTree:  44%|     | 4793/11014 [01:11<01:42, 60.91it/s]
Training CobwebTree:  44%|     | 4800/11014 [01:11<01:44, 59.66it/s]
Training CobwebTree:  44%|     | 4807/11014 [01:11<01:41, 61.22it/s]
Training CobwebTree:  44%|     | 4814/11014 [01:11<01:44, 59.53it/s]
Training CobwebTree:  44%|     | 4820/11014 [01:11<01:44, 59.49it/s]
Training CobwebTree:  44%|     | 4826/11014 [01:11<01:44, 59.42it/s]
Training CobwebTree:  44%|     | 4832/11014 [01:11<01:45, 58.43it/s]
Training CobwebTree:  44%|     | 4838/11014 [01:11<01:45, 58.29it/s]
Training CobwebTree:  44%|     | 4845/11014 [01:11<01:46, 57.67it/s]
Training CobwebTree:  44%|     | 4851/11014 [01:12<01:48, 56.97it/s]
Training CobwebTree:  44%|     | 4858/11014 [01:12<01:46, 57.70it/s]
Training CobwebTree:  44%|     | 4864/11014 [01:12<01:48, 56.92it/s]
Training CobwebTree:  44%|     | 4870/11014 [01:12<01:50, 55.76it/s]
Training CobwebTree:  44%|     | 4877/11014 [01:12<01:46, 57.51it/s]
Training CobwebTree:  44%|     | 4883/11014 [01:12<01:49, 55.89it/s]
Training CobwebTree:  44%|     | 4890/11014 [01:12<01:47, 57.02it/s]
Training CobwebTree:  44%|     | 4897/11014 [01:12<01:43, 59.11it/s]
Training CobwebTree:  45%|     | 4904/11014 [01:13<01:43, 58.85it/s]
Training CobwebTree:  45%|     | 4910/11014 [01:13<01:45, 57.75it/s]
Training CobwebTree:  45%|     | 4916/11014 [01:13<01:47, 56.90it/s]
Training CobwebTree:  45%|     | 4922/11014 [01:13<01:47, 56.65it/s]
Training CobwebTree:  45%|     | 4928/11014 [01:13<01:46, 57.25it/s]
Training CobwebTree:  45%|     | 4934/11014 [01:13<01:47, 56.73it/s]
Training CobwebTree:  45%|     | 4941/11014 [01:13<01:43, 58.41it/s]
Training CobwebTree:  45%|     | 4947/11014 [01:13<01:45, 57.35it/s]
Training CobwebTree:  45%|     | 4954/11014 [01:13<01:43, 58.44it/s]
Training CobwebTree:  45%|     | 4961/11014 [01:13<01:42, 59.33it/s]
Training CobwebTree:  45%|     | 4967/11014 [01:14<01:43, 58.56it/s]
Training CobwebTree:  45%|     | 4973/11014 [01:14<01:47, 56.26it/s]
Training CobwebTree:  45%|     | 4980/11014 [01:14<01:44, 57.81it/s]
Training CobwebTree:  45%|     | 4986/11014 [01:14<01:45, 57.02it/s]
Training CobwebTree:  45%|     | 4992/11014 [01:14<01:46, 56.43it/s]
Training CobwebTree:  45%|     | 4999/11014 [01:14<01:43, 58.34it/s]
Training CobwebTree:  45%|     | 5005/11014 [01:14<01:44, 57.41it/s]
Training CobwebTree:  45%|     | 5011/11014 [01:14<01:46, 56.56it/s]
Training CobwebTree:  46%|     | 5018/11014 [01:14<01:42, 58.40it/s]
Training CobwebTree:  46%|     | 5025/11014 [01:15<01:41, 58.85it/s]
Training CobwebTree:  46%|     | 5032/11014 [01:15<01:40, 59.28it/s]
Training CobwebTree:  46%|     | 5039/11014 [01:15<01:36, 61.77it/s]
Training CobwebTree:  46%|     | 5046/11014 [01:15<01:36, 61.78it/s]
Training CobwebTree:  46%|     | 5053/11014 [01:15<01:36, 61.69it/s]
Training CobwebTree:  46%|     | 5060/11014 [01:15<01:36, 61.71it/s]
Training CobwebTree:  46%|     | 5067/11014 [01:15<01:37, 60.93it/s]
Training CobwebTree:  46%|     | 5074/11014 [01:15<01:38, 60.02it/s]
Training CobwebTree:  46%|     | 5081/11014 [01:16<01:40, 59.27it/s]
Training CobwebTree:  46%|     | 5088/11014 [01:16<01:38, 60.29it/s]
Training CobwebTree:  46%|     | 5095/11014 [01:16<01:39, 59.57it/s]
Training CobwebTree:  46%|     | 5101/11014 [01:16<01:42, 57.55it/s]
Training CobwebTree:  46%|     | 5107/11014 [01:16<01:43, 56.85it/s]
Training CobwebTree:  46%|     | 5113/11014 [01:16<01:43, 57.21it/s]
Training CobwebTree:  46%|     | 5119/11014 [01:17<03:47, 25.87it/s]
Training CobwebTree:  47%|     | 5125/11014 [01:17<03:09, 31.01it/s]
Training CobwebTree:  47%|     | 5131/11014 [01:17<02:44, 35.84it/s]
Training CobwebTree:  47%|     | 5138/11014 [01:17<02:20, 41.70it/s]
Training CobwebTree:  47%|     | 5145/11014 [01:17<02:05, 46.80it/s]
Training CobwebTree:  47%|     | 5152/11014 [01:17<01:55, 50.86it/s]
Training CobwebTree:  47%|     | 5159/11014 [01:17<01:50, 52.87it/s]
Training CobwebTree:  47%|     | 5165/11014 [01:17<01:47, 54.59it/s]
Training CobwebTree:  47%|     | 5171/11014 [01:18<01:48, 54.02it/s]
Training CobwebTree:  47%|     | 5179/11014 [01:18<01:39, 58.77it/s]
Training CobwebTree:  47%|     | 5186/11014 [01:18<01:38, 59.27it/s]
Training CobwebTree:  47%|     | 5193/11014 [01:18<01:39, 58.37it/s]
Training CobwebTree:  47%|     | 5200/11014 [01:18<01:37, 59.90it/s]
Training CobwebTree:  47%|     | 5207/11014 [01:18<01:37, 59.60it/s]
Training CobwebTree:  47%|     | 5214/11014 [01:18<01:38, 59.05it/s]
Training CobwebTree:  47%|     | 5221/11014 [01:18<01:37, 59.70it/s]
Training CobwebTree:  47%|     | 5228/11014 [01:18<01:35, 60.82it/s]
Training CobwebTree:  48%|     | 5235/11014 [01:19<01:38, 58.89it/s]
Training CobwebTree:  48%|     | 5241/11014 [01:19<01:41, 57.16it/s]
Training CobwebTree:  48%|     | 5247/11014 [01:19<01:42, 56.36it/s]
Training CobwebTree:  48%|     | 5253/11014 [01:19<01:42, 56.32it/s]
Training CobwebTree:  48%|     | 5259/11014 [01:19<01:41, 56.45it/s]
Training CobwebTree:  48%|     | 5266/11014 [01:19<01:40, 57.48it/s]
Training CobwebTree:  48%|     | 5273/11014 [01:19<01:37, 58.67it/s]
Training CobwebTree:  48%|     | 5280/11014 [01:19<01:37, 59.00it/s]
Training CobwebTree:  48%|     | 5287/11014 [01:19<01:36, 59.46it/s]
Training CobwebTree:  48%|     | 5293/11014 [01:20<01:37, 58.63it/s]
Training CobwebTree:  48%|     | 5300/11014 [01:20<01:36, 59.52it/s]
Training CobwebTree:  48%|     | 5306/11014 [01:20<01:35, 59.57it/s]
Training CobwebTree:  48%|     | 5312/11014 [01:20<01:38, 58.13it/s]
Training CobwebTree:  48%|     | 5319/11014 [01:20<01:37, 58.32it/s]
Training CobwebTree:  48%|     | 5326/11014 [01:20<01:34, 59.97it/s]
Training CobwebTree:  48%|     | 5333/11014 [01:20<01:36, 59.16it/s]
Training CobwebTree:  48%|     | 5340/11014 [01:20<01:34, 59.94it/s]
Training CobwebTree:  49%|     | 5347/11014 [01:20<01:32, 61.29it/s]
Training CobwebTree:  49%|     | 5354/11014 [01:21<01:33, 60.66it/s]
Training CobwebTree:  49%|     | 5361/11014 [01:21<01:32, 61.10it/s]
Training CobwebTree:  49%|     | 5368/11014 [01:21<01:31, 61.51it/s]
Training CobwebTree:  49%|     | 5375/11014 [01:21<01:32, 60.71it/s]
Training CobwebTree:  49%|     | 5382/11014 [01:21<01:34, 59.40it/s]
Training CobwebTree:  49%|     | 5388/11014 [01:21<01:36, 58.18it/s]
Training CobwebTree:  49%|     | 5395/11014 [01:21<01:33, 60.37it/s]
Training CobwebTree:  49%|     | 5402/11014 [01:21<01:32, 60.65it/s]
Training CobwebTree:  49%|     | 5409/11014 [01:21<01:32, 60.39it/s]
Training CobwebTree:  49%|     | 5416/11014 [01:22<01:32, 60.24it/s]
Training CobwebTree:  49%|     | 5423/11014 [01:22<01:34, 59.19it/s]
Training CobwebTree:  49%|     | 5430/11014 [01:22<01:34, 59.16it/s]
Training CobwebTree:  49%|     | 5437/11014 [01:22<01:35, 58.35it/s]
Training CobwebTree:  49%|     | 5443/11014 [01:22<01:36, 57.88it/s]
Training CobwebTree:  49%|     | 5449/11014 [01:22<01:39, 55.72it/s]
Training CobwebTree:  50%|     | 5456/11014 [01:22<01:36, 57.54it/s]
Training CobwebTree:  50%|     | 5462/11014 [01:22<01:35, 58.06it/s]
Training CobwebTree:  50%|     | 5468/11014 [01:23<01:35, 58.07it/s]
Training CobwebTree:  50%|     | 5475/11014 [01:23<01:32, 59.82it/s]
Training CobwebTree:  50%|     | 5481/11014 [01:23<01:35, 58.00it/s]
Training CobwebTree:  50%|     | 5488/11014 [01:23<01:32, 59.53it/s]
Training CobwebTree:  50%|     | 5494/11014 [01:23<01:34, 58.35it/s]
Training CobwebTree:  50%|     | 5500/11014 [01:23<01:34, 58.49it/s]
Training CobwebTree:  50%|     | 5506/11014 [01:23<01:35, 57.75it/s]
Training CobwebTree:  50%|     | 5513/11014 [01:23<01:33, 58.98it/s]
Training CobwebTree:  50%|     | 5520/11014 [01:23<01:31, 60.10it/s]
Training CobwebTree:  50%|     | 5527/11014 [01:24<01:33, 58.87it/s]
Training CobwebTree:  50%|     | 5533/11014 [01:24<01:32, 58.97it/s]
Training CobwebTree:  50%|     | 5540/11014 [01:24<01:31, 59.96it/s]
Training CobwebTree:  50%|     | 5547/11014 [01:24<01:31, 60.06it/s]
Training CobwebTree:  50%|     | 5554/11014 [01:24<01:32, 59.27it/s]
Training CobwebTree:  50%|     | 5560/11014 [01:24<01:34, 57.83it/s]
Training CobwebTree:  51%|     | 5566/11014 [01:24<01:34, 57.59it/s]
Training CobwebTree:  51%|     | 5572/11014 [01:24<01:34, 57.59it/s]
Training CobwebTree:  51%|     | 5579/11014 [01:24<01:30, 59.95it/s]
Training CobwebTree:  51%|     | 5585/11014 [01:25<01:31, 59.15it/s]
Training CobwebTree:  51%|     | 5591/11014 [01:25<01:32, 58.45it/s]
Training CobwebTree:  51%|     | 5597/11014 [01:25<01:32, 58.78it/s]
Training CobwebTree:  51%|     | 5603/11014 [01:25<01:33, 58.04it/s]
Training CobwebTree:  51%|     | 5609/11014 [01:25<01:32, 58.17it/s]
Training CobwebTree:  51%|     | 5615/11014 [01:25<01:33, 57.46it/s]
Training CobwebTree:  51%|     | 5622/11014 [01:25<01:32, 58.37it/s]
Training CobwebTree:  51%|     | 5628/11014 [01:25<01:32, 58.11it/s]
Training CobwebTree:  51%|     | 5634/11014 [01:25<01:33, 57.82it/s]
Training CobwebTree:  51%|     | 5641/11014 [01:25<01:30, 59.27it/s]
Training CobwebTree:  51%|    | 5647/11014 [01:26<01:33, 57.58it/s]
Training CobwebTree:  51%|    | 5653/11014 [01:26<01:32, 58.22it/s]
Training CobwebTree:  51%|    | 5659/11014 [01:26<01:32, 57.96it/s]
Training CobwebTree:  51%|    | 5665/11014 [01:26<01:34, 56.89it/s]
Training CobwebTree:  51%|    | 5671/11014 [01:26<01:33, 56.84it/s]
Training CobwebTree:  52%|    | 5678/11014 [01:26<01:33, 56.87it/s]
Training CobwebTree:  52%|    | 5684/11014 [01:26<01:33, 57.12it/s]
Training CobwebTree:  52%|    | 5690/11014 [01:26<01:33, 57.00it/s]
Training CobwebTree:  52%|    | 5696/11014 [01:26<01:35, 55.47it/s]
Training CobwebTree:  52%|    | 5703/11014 [01:27<01:33, 57.10it/s]
Training CobwebTree:  52%|    | 5709/11014 [01:27<01:34, 56.27it/s]
Training CobwebTree:  52%|    | 5715/11014 [01:27<01:33, 56.76it/s]
Training CobwebTree:  52%|    | 5722/11014 [01:27<01:29, 58.83it/s]
Training CobwebTree:  52%|    | 5729/11014 [01:27<01:29, 59.13it/s]
Training CobwebTree:  52%|    | 5735/11014 [01:27<01:31, 57.52it/s]
Training CobwebTree:  52%|    | 5741/11014 [01:27<01:32, 57.10it/s]
Training CobwebTree:  52%|    | 5748/11014 [01:27<01:30, 58.17it/s]
Training CobwebTree:  52%|    | 5755/11014 [01:27<01:30, 57.99it/s]
Training CobwebTree:  52%|    | 5761/11014 [01:28<01:31, 57.61it/s]
Training CobwebTree:  52%|    | 5768/11014 [01:28<01:26, 60.50it/s]
Training CobwebTree:  52%|    | 5775/11014 [01:28<01:26, 60.57it/s]
Training CobwebTree:  52%|    | 5782/11014 [01:28<01:28, 59.04it/s]
Training CobwebTree:  53%|    | 5788/11014 [01:28<01:30, 57.80it/s]
Training CobwebTree:  53%|    | 5794/11014 [01:28<01:30, 57.61it/s]
Training CobwebTree:  53%|    | 5800/11014 [01:28<01:32, 56.34it/s]
Training CobwebTree:  53%|    | 5807/11014 [01:28<01:28, 58.66it/s]
Training CobwebTree:  53%|    | 5813/11014 [01:28<01:32, 56.53it/s]
Training CobwebTree:  53%|    | 5819/11014 [01:29<01:31, 57.06it/s]
Training CobwebTree:  53%|    | 5826/11014 [01:29<01:30, 57.58it/s]
Training CobwebTree:  53%|    | 5832/11014 [01:29<01:30, 56.99it/s]
Training CobwebTree:  53%|    | 5838/11014 [01:29<01:30, 57.09it/s]
Training CobwebTree:  53%|    | 5845/11014 [01:29<01:28, 58.43it/s]
Training CobwebTree:  53%|    | 5851/11014 [01:29<01:28, 58.47it/s]
Training CobwebTree:  53%|    | 5858/11014 [01:29<01:25, 60.27it/s]
Training CobwebTree:  53%|    | 5865/11014 [01:29<01:27, 58.78it/s]
Training CobwebTree:  53%|    | 5872/11014 [01:29<01:26, 59.65it/s]
Training CobwebTree:  53%|    | 5878/11014 [01:30<01:32, 55.46it/s]
Training CobwebTree:  53%|    | 5884/11014 [01:30<01:31, 56.03it/s]
Training CobwebTree:  53%|    | 5890/11014 [01:30<01:32, 55.48it/s]
Training CobwebTree:  54%|    | 5897/11014 [01:30<01:27, 58.27it/s]
Training CobwebTree:  54%|    | 5903/11014 [01:30<01:27, 58.65it/s]
Training CobwebTree:  54%|    | 5909/11014 [01:30<01:27, 58.55it/s]
Training CobwebTree:  54%|    | 5915/11014 [01:30<01:28, 57.90it/s]
Training CobwebTree:  54%|    | 5922/11014 [01:30<01:25, 59.22it/s]
Training CobwebTree:  54%|    | 5928/11014 [01:30<01:27, 57.90it/s]
Training CobwebTree:  54%|    | 5935/11014 [01:31<01:26, 58.82it/s]
Training CobwebTree:  54%|    | 5941/11014 [01:31<01:26, 58.35it/s]
Training CobwebTree:  54%|    | 5947/11014 [01:31<01:26, 58.80it/s]
Training CobwebTree:  54%|    | 5953/11014 [01:31<01:28, 56.97it/s]
Training CobwebTree:  54%|    | 5959/11014 [01:31<01:30, 55.73it/s]
Training CobwebTree:  54%|    | 5965/11014 [01:31<01:31, 55.42it/s]
Training CobwebTree:  54%|    | 5971/11014 [01:31<01:31, 55.00it/s]
Training CobwebTree:  54%|    | 5977/11014 [01:31<01:30, 55.69it/s]
Training CobwebTree:  54%|    | 5983/11014 [01:31<01:31, 54.98it/s]
Training CobwebTree:  54%|    | 5989/11014 [01:32<01:30, 55.78it/s]
Training CobwebTree:  54%|    | 5995/11014 [01:32<01:28, 56.48it/s]
Training CobwebTree:  54%|    | 6001/11014 [01:32<01:27, 57.41it/s]
Training CobwebTree:  55%|    | 6007/11014 [01:32<01:27, 56.92it/s]
Training CobwebTree:  55%|    | 6013/11014 [01:32<01:29, 56.17it/s]
Training CobwebTree:  55%|    | 6019/11014 [01:32<01:28, 56.30it/s]
Training CobwebTree:  55%|    | 6026/11014 [01:32<01:25, 58.61it/s]
Training CobwebTree:  55%|    | 6032/11014 [01:32<01:26, 57.68it/s]
Training CobwebTree:  55%|    | 6038/11014 [01:32<01:27, 56.80it/s]
Training CobwebTree:  55%|    | 6044/11014 [01:32<01:29, 55.59it/s]
Training CobwebTree:  55%|    | 6050/11014 [01:33<01:28, 56.12it/s]
Training CobwebTree:  55%|    | 6056/11014 [01:33<01:27, 56.76it/s]
Training CobwebTree:  55%|    | 6063/11014 [01:33<01:25, 57.81it/s]
Training CobwebTree:  55%|    | 6069/11014 [01:33<01:29, 54.97it/s]
Training CobwebTree:  55%|    | 6075/11014 [01:33<01:30, 54.61it/s]
Training CobwebTree:  55%|    | 6082/11014 [01:33<01:26, 56.99it/s]
Training CobwebTree:  55%|    | 6088/11014 [01:33<01:26, 56.65it/s]
Training CobwebTree:  55%|    | 6094/11014 [01:33<01:26, 56.57it/s]
Training CobwebTree:  55%|    | 6100/11014 [01:33<01:26, 56.71it/s]
Training CobwebTree:  55%|    | 6107/11014 [01:34<01:24, 57.74it/s]
Training CobwebTree:  56%|    | 6113/11014 [01:34<01:26, 56.34it/s]
Training CobwebTree:  56%|    | 6120/11014 [01:34<01:25, 57.19it/s]
Training CobwebTree:  56%|    | 6126/11014 [01:34<01:26, 56.27it/s]
Training CobwebTree:  56%|    | 6132/11014 [01:34<01:28, 55.01it/s]
Training CobwebTree:  56%|    | 6138/11014 [01:34<01:26, 56.28it/s]
Training CobwebTree:  56%|    | 6144/11014 [01:34<01:27, 55.66it/s]
Training CobwebTree:  56%|    | 6151/11014 [01:34<01:22, 58.68it/s]
Training CobwebTree:  56%|    | 6157/11014 [01:34<01:24, 57.81it/s]
Training CobwebTree:  56%|    | 6164/11014 [01:35<01:22, 59.13it/s]
Training CobwebTree:  56%|    | 6170/11014 [01:35<01:26, 56.00it/s]
Training CobwebTree:  56%|    | 6176/11014 [01:35<01:25, 56.62it/s]
Training CobwebTree:  56%|    | 6182/11014 [01:35<01:26, 55.54it/s]
Training CobwebTree:  56%|    | 6189/11014 [01:35<01:24, 57.09it/s]
Training CobwebTree:  56%|    | 6196/11014 [01:35<01:20, 59.92it/s]
Training CobwebTree:  56%|    | 6203/11014 [01:35<01:20, 60.12it/s]
Training CobwebTree:  56%|    | 6210/11014 [01:35<01:19, 60.43it/s]
Training CobwebTree:  56%|    | 6217/11014 [01:36<01:21, 59.09it/s]
Training CobwebTree:  57%|    | 6223/11014 [01:36<01:25, 55.83it/s]
Training CobwebTree:  57%|    | 6230/11014 [01:36<01:22, 58.18it/s]
Training CobwebTree:  57%|    | 6237/11014 [01:36<01:19, 60.32it/s]
Training CobwebTree:  57%|    | 6244/11014 [01:36<01:19, 59.65it/s]
Training CobwebTree:  57%|    | 6251/11014 [01:36<01:19, 60.16it/s]
Training CobwebTree:  57%|    | 6258/11014 [01:36<01:20, 58.84it/s]
Training CobwebTree:  57%|    | 6264/11014 [01:36<01:20, 58.95it/s]
Training CobwebTree:  57%|    | 6271/11014 [01:36<01:19, 59.34it/s]
Training CobwebTree:  57%|    | 6277/11014 [01:37<01:21, 57.98it/s]
Training CobwebTree:  57%|    | 6283/11014 [01:37<01:21, 58.25it/s]
Training CobwebTree:  57%|    | 6290/11014 [01:37<01:19, 59.21it/s]
Training CobwebTree:  57%|    | 6297/11014 [01:37<01:18, 59.84it/s]
Training CobwebTree:  57%|    | 6303/11014 [01:37<01:18, 59.79it/s]
Training CobwebTree:  57%|    | 6309/11014 [01:37<01:20, 58.14it/s]
Training CobwebTree:  57%|    | 6315/11014 [01:37<01:22, 57.23it/s]
Training CobwebTree:  57%|    | 6321/11014 [01:37<01:21, 57.50it/s]
Training CobwebTree:  57%|    | 6327/11014 [01:37<01:21, 57.70it/s]
Training CobwebTree:  57%|    | 6333/11014 [01:38<01:23, 56.29it/s]
Training CobwebTree:  58%|    | 6339/11014 [01:38<01:23, 55.69it/s]
Training CobwebTree:  58%|    | 6345/11014 [01:38<01:23, 56.03it/s]
Training CobwebTree:  58%|    | 6351/11014 [01:38<01:22, 56.71it/s]
Training CobwebTree:  58%|    | 6358/11014 [01:38<01:20, 57.55it/s]
Training CobwebTree:  58%|    | 6364/11014 [01:38<01:22, 56.64it/s]
Training CobwebTree:  58%|    | 6370/11014 [01:38<01:22, 56.50it/s]
Training CobwebTree:  58%|    | 6376/11014 [01:38<01:24, 54.63it/s]
Training CobwebTree:  58%|    | 6382/11014 [01:38<01:24, 54.61it/s]
Training CobwebTree:  58%|    | 6388/11014 [01:38<01:23, 55.57it/s]
Training CobwebTree:  58%|    | 6395/11014 [01:39<01:21, 56.67it/s]
Training CobwebTree:  58%|    | 6401/11014 [01:39<01:20, 57.06it/s]
Training CobwebTree:  58%|    | 6408/11014 [01:39<01:19, 58.29it/s]
Training CobwebTree:  58%|    | 6414/11014 [01:39<01:18, 58.24it/s]
Training CobwebTree:  58%|    | 6420/11014 [01:39<01:20, 57.34it/s]
Training CobwebTree:  58%|    | 6426/11014 [01:39<01:20, 56.83it/s]
Training CobwebTree:  58%|    | 6432/11014 [01:39<01:21, 56.37it/s]
Training CobwebTree:  58%|    | 6438/11014 [01:39<01:23, 55.07it/s]
Training CobwebTree:  59%|    | 6444/11014 [01:39<01:24, 54.23it/s]
Training CobwebTree:  59%|    | 6451/11014 [01:40<01:19, 57.07it/s]
Training CobwebTree:  59%|    | 6457/11014 [01:40<01:20, 56.71it/s]
Training CobwebTree:  59%|    | 6463/11014 [01:40<01:19, 56.97it/s]
Training CobwebTree:  59%|    | 6469/11014 [01:40<01:18, 57.60it/s]
Training CobwebTree:  59%|    | 6475/11014 [01:40<01:18, 57.76it/s]
Training CobwebTree:  59%|    | 6482/11014 [01:40<01:17, 58.25it/s]
Training CobwebTree:  59%|    | 6488/11014 [01:40<01:19, 57.00it/s]
Training CobwebTree:  59%|    | 6494/11014 [01:40<01:18, 57.36it/s]
Training CobwebTree:  59%|    | 6501/11014 [01:40<01:16, 58.74it/s]
Training CobwebTree:  59%|    | 6508/11014 [01:41<01:15, 59.79it/s]
Training CobwebTree:  59%|    | 6514/11014 [01:41<01:17, 58.11it/s]
Training CobwebTree:  59%|    | 6520/11014 [01:41<01:16, 58.61it/s]
Training CobwebTree:  59%|    | 6527/11014 [01:41<01:14, 60.58it/s]
Training CobwebTree:  59%|    | 6534/11014 [01:41<01:15, 59.57it/s]
Training CobwebTree:  59%|    | 6540/11014 [01:41<01:17, 57.86it/s]
Training CobwebTree:  59%|    | 6546/11014 [01:41<01:17, 57.47it/s]
Training CobwebTree:  59%|    | 6552/11014 [01:41<01:17, 57.48it/s]
Training CobwebTree:  60%|    | 6558/11014 [01:41<01:20, 55.43it/s]
Training CobwebTree:  60%|    | 6564/11014 [01:42<01:19, 55.71it/s]
Training CobwebTree:  60%|    | 6570/11014 [01:42<01:18, 56.67it/s]
Training CobwebTree:  60%|    | 6576/11014 [01:42<01:18, 56.37it/s]
Training CobwebTree:  60%|    | 6582/11014 [01:42<01:18, 56.12it/s]
Training CobwebTree:  60%|    | 6588/11014 [01:42<01:18, 56.49it/s]
Training CobwebTree:  60%|    | 6594/11014 [01:42<01:18, 56.37it/s]
Training CobwebTree:  60%|    | 6601/11014 [01:42<01:17, 56.73it/s]
Training CobwebTree:  60%|    | 6607/11014 [01:42<01:17, 57.13it/s]
Training CobwebTree:  60%|    | 6613/11014 [01:42<01:19, 55.20it/s]
Training CobwebTree:  60%|    | 6619/11014 [01:43<01:20, 54.82it/s]
Training CobwebTree:  60%|    | 6625/11014 [01:43<01:18, 56.18it/s]
Training CobwebTree:  60%|    | 6631/11014 [01:43<01:20, 54.28it/s]
Training CobwebTree:  60%|    | 6637/11014 [01:43<01:21, 54.01it/s]
Training CobwebTree:  60%|    | 6644/11014 [01:43<01:16, 56.90it/s]
Training CobwebTree:  60%|    | 6650/11014 [01:43<01:17, 55.98it/s]
Training CobwebTree:  60%|    | 6656/11014 [01:43<01:17, 56.05it/s]
Training CobwebTree:  60%|    | 6662/11014 [01:43<01:17, 55.91it/s]
Training CobwebTree:  61%|    | 6668/11014 [01:43<01:19, 54.58it/s]
Training CobwebTree:  61%|    | 6674/11014 [01:44<01:18, 55.56it/s]
Training CobwebTree:  61%|    | 6681/11014 [01:44<01:14, 57.82it/s]
Training CobwebTree:  61%|    | 6687/11014 [01:44<01:14, 58.09it/s]
Training CobwebTree:  61%|    | 6693/11014 [01:44<01:15, 57.32it/s]
Training CobwebTree:  61%|    | 6699/11014 [01:44<01:14, 57.63it/s]
Training CobwebTree:  61%|    | 6705/11014 [01:44<01:17, 55.92it/s]
Training CobwebTree:  61%|    | 6711/11014 [01:44<01:16, 56.49it/s]
Training CobwebTree:  61%|    | 6717/11014 [01:44<01:17, 55.67it/s]
Training CobwebTree:  61%|    | 6723/11014 [01:44<01:16, 56.29it/s]
Training CobwebTree:  61%|    | 6730/11014 [01:44<01:14, 57.73it/s]
Training CobwebTree:  61%|    | 6736/11014 [01:45<01:14, 57.37it/s]
Training CobwebTree:  61%|    | 6742/11014 [01:45<01:14, 57.27it/s]
Training CobwebTree:  61%|   | 6748/11014 [01:45<01:15, 56.38it/s]
Training CobwebTree:  61%|   | 6754/11014 [01:45<01:14, 57.10it/s]
Training CobwebTree:  61%|   | 6760/11014 [01:45<01:13, 57.89it/s]
Training CobwebTree:  61%|   | 6766/11014 [01:45<01:15, 56.28it/s]
Training CobwebTree:  61%|   | 6772/11014 [01:45<01:15, 56.04it/s]
Training CobwebTree:  62%|   | 6778/11014 [01:45<01:17, 54.90it/s]
Training CobwebTree:  62%|   | 6785/11014 [01:45<01:13, 57.53it/s]
Training CobwebTree:  62%|   | 6792/11014 [01:46<01:11, 58.82it/s]
Training CobwebTree:  62%|   | 6799/11014 [01:46<01:10, 59.79it/s]
Training CobwebTree:  62%|   | 6806/11014 [01:46<01:09, 60.97it/s]
Training CobwebTree:  62%|   | 6813/11014 [01:46<01:10, 59.18it/s]
Training CobwebTree:  62%|   | 6819/11014 [01:46<01:11, 58.51it/s]
Training CobwebTree:  62%|   | 6826/11014 [01:46<01:10, 59.21it/s]
Training CobwebTree:  62%|   | 6832/11014 [01:46<01:14, 56.35it/s]
Training CobwebTree:  62%|   | 6839/11014 [01:46<01:13, 56.85it/s]
Training CobwebTree:  62%|   | 6846/11014 [01:47<01:12, 57.70it/s]
Training CobwebTree:  62%|   | 6852/11014 [01:47<01:12, 57.20it/s]
Training CobwebTree:  62%|   | 6858/11014 [01:47<01:12, 57.03it/s]
Training CobwebTree:  62%|   | 6864/11014 [01:47<01:15, 55.05it/s]
Training CobwebTree:  62%|   | 6870/11014 [01:47<01:15, 55.14it/s]
Training CobwebTree:  62%|   | 6876/11014 [01:47<01:15, 54.98it/s]
Training CobwebTree:  62%|   | 6882/11014 [01:47<01:13, 55.94it/s]
Training CobwebTree:  63%|   | 6888/11014 [01:47<01:14, 55.59it/s]
Training CobwebTree:  63%|   | 6894/11014 [01:47<01:13, 56.19it/s]
Training CobwebTree:  63%|   | 6901/11014 [01:47<01:12, 56.85it/s]
Training CobwebTree:  63%|   | 6907/11014 [01:48<01:13, 56.25it/s]
Training CobwebTree:  63%|   | 6913/11014 [01:48<01:11, 57.03it/s]
Training CobwebTree:  63%|   | 6919/11014 [01:48<01:11, 57.38it/s]
Training CobwebTree:  63%|   | 6925/11014 [01:48<01:12, 56.53it/s]
Training CobwebTree:  63%|   | 6931/11014 [01:48<01:13, 55.77it/s]
Training CobwebTree:  63%|   | 6937/11014 [01:48<01:14, 54.68it/s]
Training CobwebTree:  63%|   | 6943/11014 [01:48<01:15, 53.72it/s]
Training CobwebTree:  63%|   | 6949/11014 [01:48<01:14, 54.81it/s]
Training CobwebTree:  63%|   | 6955/11014 [01:48<01:14, 54.75it/s]
Training CobwebTree:  63%|   | 6962/11014 [01:49<01:10, 57.08it/s]
Training CobwebTree:  63%|   | 6968/11014 [01:49<01:11, 56.33it/s]
Training CobwebTree:  63%|   | 6974/11014 [01:49<01:11, 56.79it/s]
Training CobwebTree:  63%|   | 6981/11014 [01:49<01:08, 59.24it/s]
Training CobwebTree:  63%|   | 6987/11014 [01:49<01:08, 58.56it/s]
Training CobwebTree:  63%|   | 6993/11014 [01:49<01:09, 57.98it/s]
Training CobwebTree:  64%|   | 6999/11014 [01:49<01:08, 58.21it/s]
Training CobwebTree:  64%|   | 7005/11014 [01:49<01:10, 57.27it/s]
Training CobwebTree:  64%|   | 7011/11014 [01:49<01:11, 56.21it/s]
Training CobwebTree:  64%|   | 7018/11014 [01:50<01:09, 57.17it/s]
Training CobwebTree:  64%|   | 7024/11014 [01:50<01:09, 57.52it/s]
Training CobwebTree:  64%|   | 7030/11014 [01:50<01:12, 54.66it/s]
Training CobwebTree:  64%|   | 7036/11014 [01:50<01:11, 55.40it/s]
Training CobwebTree:  64%|   | 7042/11014 [01:50<01:10, 56.05it/s]
Training CobwebTree:  64%|   | 7049/11014 [01:50<01:08, 57.86it/s]
Training CobwebTree:  64%|   | 7055/11014 [01:50<01:08, 58.15it/s]
Training CobwebTree:  64%|   | 7062/11014 [01:50<01:05, 60.40it/s]
Training CobwebTree:  64%|   | 7069/11014 [01:50<01:07, 58.80it/s]
Training CobwebTree:  64%|   | 7076/11014 [01:51<01:06, 59.23it/s]
Training CobwebTree:  64%|   | 7082/11014 [01:51<01:10, 55.87it/s]
Training CobwebTree:  64%|   | 7088/11014 [01:51<01:09, 56.87it/s]
Training CobwebTree:  64%|   | 7095/11014 [01:51<01:07, 57.74it/s]
Training CobwebTree:  64%|   | 7101/11014 [01:51<01:10, 55.41it/s]
Training CobwebTree:  65%|   | 7108/11014 [01:51<01:09, 56.22it/s]
Training CobwebTree:  65%|   | 7114/11014 [01:51<01:08, 57.04it/s]
Training CobwebTree:  65%|   | 7120/11014 [01:51<01:07, 57.43it/s]
Training CobwebTree:  65%|   | 7127/11014 [01:51<01:06, 58.37it/s]
Training CobwebTree:  65%|   | 7133/11014 [01:52<01:09, 56.02it/s]
Training CobwebTree:  65%|   | 7139/11014 [01:52<01:07, 57.00it/s]
Training CobwebTree:  65%|   | 7145/11014 [01:52<01:07, 56.91it/s]
Training CobwebTree:  65%|   | 7151/11014 [01:52<01:08, 56.81it/s]
Training CobwebTree:  65%|   | 7157/11014 [01:52<01:08, 56.66it/s]
Training CobwebTree:  65%|   | 7164/11014 [01:52<01:06, 58.23it/s]
Training CobwebTree:  65%|   | 7170/11014 [01:52<01:07, 56.92it/s]
Training CobwebTree:  65%|   | 7177/11014 [01:52<01:05, 58.68it/s]
Training CobwebTree:  65%|   | 7183/11014 [01:52<01:06, 57.37it/s]
Training CobwebTree:  65%|   | 7190/11014 [01:53<01:04, 59.16it/s]
Training CobwebTree:  65%|   | 7196/11014 [01:53<01:05, 58.59it/s]
Training CobwebTree:  65%|   | 7202/11014 [01:53<01:05, 58.17it/s]
Training CobwebTree:  65%|   | 7208/11014 [01:53<01:06, 57.53it/s]
Training CobwebTree:  65%|   | 7214/11014 [01:53<01:06, 56.98it/s]
Training CobwebTree:  66%|   | 7222/11014 [01:53<01:03, 60.07it/s]
Training CobwebTree:  66%|   | 7228/11014 [01:53<01:04, 58.56it/s]
Training CobwebTree:  66%|   | 7234/11014 [01:53<01:06, 57.26it/s]
Training CobwebTree:  66%|   | 7240/11014 [01:53<01:06, 56.51it/s]
Training CobwebTree:  66%|   | 7246/11014 [01:54<01:06, 56.75it/s]
Training CobwebTree:  66%|   | 7252/11014 [01:54<01:08, 54.94it/s]
Training CobwebTree:  66%|   | 7259/11014 [01:54<01:06, 56.86it/s]
Training CobwebTree:  66%|   | 7265/11014 [01:54<01:06, 56.52it/s]
Training CobwebTree:  66%|   | 7271/11014 [01:54<01:06, 56.67it/s]
Training CobwebTree:  66%|   | 7278/11014 [01:54<01:03, 59.19it/s]
Training CobwebTree:  66%|   | 7284/11014 [01:54<01:04, 57.98it/s]
Training CobwebTree:  66%|   | 7291/11014 [01:54<01:02, 59.58it/s]
Training CobwebTree:  66%|   | 7297/11014 [01:54<01:02, 59.45it/s]
Training CobwebTree:  66%|   | 7304/11014 [01:55<01:00, 61.75it/s]
Training CobwebTree:  66%|   | 7311/11014 [01:55<01:02, 59.66it/s]
Training CobwebTree:  66%|   | 7317/11014 [01:55<01:01, 59.65it/s]
Training CobwebTree:  66%|   | 7323/11014 [01:55<01:03, 57.83it/s]
Training CobwebTree:  67%|   | 7329/11014 [01:55<01:04, 56.86it/s]
Training CobwebTree:  67%|   | 7335/11014 [01:55<01:06, 55.55it/s]
Training CobwebTree:  67%|   | 7342/11014 [01:55<01:01, 59.36it/s]
Training CobwebTree:  67%|   | 7348/11014 [01:55<01:03, 58.08it/s]
Training CobwebTree:  67%|   | 7354/11014 [01:55<01:03, 57.23it/s]
Training CobwebTree:  67%|   | 7361/11014 [01:56<01:01, 59.02it/s]
Training CobwebTree:  67%|   | 7367/11014 [01:56<01:03, 57.78it/s]
Training CobwebTree:  67%|   | 7374/11014 [01:56<01:01, 59.50it/s]
Training CobwebTree:  67%|   | 7380/11014 [01:56<01:04, 56.31it/s]
Training CobwebTree:  67%|   | 7387/11014 [01:56<01:02, 58.46it/s]
Training CobwebTree:  67%|   | 7393/11014 [01:56<01:02, 57.82it/s]
Training CobwebTree:  67%|   | 7399/11014 [01:56<01:03, 56.50it/s]
Training CobwebTree:  67%|   | 7405/11014 [01:56<01:03, 56.84it/s]
Training CobwebTree:  67%|   | 7411/11014 [01:56<01:04, 56.22it/s]
Training CobwebTree:  67%|   | 7417/11014 [01:56<01:04, 56.13it/s]
Training CobwebTree:  67%|   | 7424/11014 [01:57<01:02, 57.51it/s]
Training CobwebTree:  67%|   | 7430/11014 [01:57<01:04, 55.75it/s]
Training CobwebTree:  68%|   | 7436/11014 [01:57<01:03, 56.05it/s]
Training CobwebTree:  68%|   | 7442/11014 [01:57<01:06, 53.78it/s]
Training CobwebTree:  68%|   | 7449/11014 [01:57<01:02, 56.67it/s]
Training CobwebTree:  68%|   | 7455/11014 [01:57<01:02, 57.23it/s]
Training CobwebTree:  68%|   | 7461/11014 [01:57<01:03, 56.11it/s]
Training CobwebTree:  68%|   | 7467/11014 [01:57<01:04, 54.87it/s]
Training CobwebTree:  68%|   | 7473/11014 [01:57<01:03, 55.59it/s]
Training CobwebTree:  68%|   | 7479/11014 [01:58<01:03, 55.63it/s]
Training CobwebTree:  68%|   | 7485/11014 [01:58<01:04, 54.63it/s]
Training CobwebTree:  68%|   | 7491/11014 [01:58<01:04, 54.93it/s]
Training CobwebTree:  68%|   | 7497/11014 [01:58<01:04, 54.61it/s]
Training CobwebTree:  68%|   | 7503/11014 [01:58<01:03, 55.27it/s]
Training CobwebTree:  68%|   | 7509/11014 [01:58<01:04, 54.62it/s]
Training CobwebTree:  68%|   | 7515/11014 [01:58<01:06, 52.75it/s]
Training CobwebTree:  68%|   | 7521/11014 [01:58<01:04, 53.95it/s]
Training CobwebTree:  68%|   | 7527/11014 [01:58<01:04, 54.48it/s]
Training CobwebTree:  68%|   | 7533/11014 [01:59<01:04, 53.92it/s]
Training CobwebTree:  68%|   | 7539/11014 [01:59<01:03, 54.95it/s]
Training CobwebTree:  69%|   | 7546/11014 [01:59<01:00, 57.18it/s]
Training CobwebTree:  69%|   | 7552/11014 [01:59<01:00, 57.67it/s]
Training CobwebTree:  69%|   | 7559/11014 [01:59<00:58, 58.62it/s]
Training CobwebTree:  69%|   | 7565/11014 [01:59<00:58, 58.92it/s]
Training CobwebTree:  69%|   | 7571/11014 [01:59<01:00, 57.25it/s]
Training CobwebTree:  69%|   | 7577/11014 [01:59<00:59, 57.47it/s]
Training CobwebTree:  69%|   | 7583/11014 [01:59<01:01, 55.46it/s]
Training CobwebTree:  69%|   | 7590/11014 [02:00<00:59, 57.98it/s]
Training CobwebTree:  69%|   | 7597/11014 [02:00<00:57, 59.11it/s]
Training CobwebTree:  69%|   | 7604/11014 [02:00<00:57, 59.13it/s]
Training CobwebTree:  69%|   | 7610/11014 [02:00<00:58, 57.99it/s]
Training CobwebTree:  69%|   | 7616/11014 [02:00<00:59, 57.16it/s]
Training CobwebTree:  69%|   | 7623/11014 [02:00<00:58, 57.74it/s]
Training CobwebTree:  69%|   | 7629/11014 [02:00<01:00, 56.32it/s]
Training CobwebTree:  69%|   | 7635/11014 [02:00<01:00, 56.14it/s]
Training CobwebTree:  69%|   | 7642/11014 [02:00<00:58, 57.36it/s]
Training CobwebTree:  69%|   | 7648/11014 [02:01<00:59, 56.45it/s]
Training CobwebTree:  69%|   | 7654/11014 [02:01<00:59, 56.49it/s]
Training CobwebTree:  70%|   | 7660/11014 [02:01<00:59, 55.97it/s]
Training CobwebTree:  70%|   | 7667/11014 [02:01<00:57, 57.81it/s]
Training CobwebTree:  70%|   | 7674/11014 [02:01<00:57, 58.58it/s]
Training CobwebTree:  70%|   | 7680/11014 [02:01<00:56, 58.85it/s]
Training CobwebTree:  70%|   | 7687/11014 [02:01<00:54, 60.82it/s]
Training CobwebTree:  70%|   | 7694/11014 [02:01<00:56, 59.06it/s]
Training CobwebTree:  70%|   | 7700/11014 [02:01<00:57, 57.62it/s]
Training CobwebTree:  70%|   | 7706/11014 [02:02<00:57, 57.64it/s]
Training CobwebTree:  70%|   | 7712/11014 [02:02<00:57, 57.85it/s]
Training CobwebTree:  70%|   | 7719/11014 [02:02<00:56, 58.49it/s]
Training CobwebTree:  70%|   | 7725/11014 [02:02<00:58, 56.61it/s]
Training CobwebTree:  70%|   | 7731/11014 [02:02<00:58, 56.40it/s]
Training CobwebTree:  70%|   | 7737/11014 [02:02<00:58, 55.63it/s]
Training CobwebTree:  70%|   | 7743/11014 [02:02<00:59, 54.97it/s]
Training CobwebTree:  70%|   | 7749/11014 [02:02<00:58, 55.48it/s]
Training CobwebTree:  70%|   | 7755/11014 [02:02<00:57, 56.37it/s]
Training CobwebTree:  70%|   | 7761/11014 [02:03<00:57, 56.64it/s]
Training CobwebTree:  71%|   | 7767/11014 [02:03<00:56, 57.04it/s]
Training CobwebTree:  71%|   | 7773/11014 [02:03<00:58, 55.34it/s]
Training CobwebTree:  71%|   | 7779/11014 [02:03<00:58, 55.34it/s]
Training CobwebTree:  71%|   | 7785/11014 [02:03<00:59, 54.47it/s]
Training CobwebTree:  71%|   | 7791/11014 [02:03<00:57, 55.63it/s]
Training CobwebTree:  71%|   | 7798/11014 [02:03<00:56, 57.04it/s]
Training CobwebTree:  71%|   | 7804/11014 [02:03<00:55, 57.72it/s]
Training CobwebTree:  71%|   | 7810/11014 [02:03<00:55, 58.07it/s]
Training CobwebTree:  71%|   | 7816/11014 [02:04<00:54, 58.30it/s]
Training CobwebTree:  71%|   | 7822/11014 [02:04<00:54, 58.15it/s]
Training CobwebTree:  71%|   | 7828/11014 [02:04<00:55, 57.92it/s]
Training CobwebTree:  71%|   | 7834/11014 [02:04<00:55, 57.47it/s]
Training CobwebTree:  71%|   | 7840/11014 [02:04<00:56, 55.73it/s]
Training CobwebTree:  71%|   | 7846/11014 [02:04<00:55, 56.77it/s]
Training CobwebTree:  71%|  | 7852/11014 [02:04<00:55, 57.15it/s]
Training CobwebTree:  71%|  | 7859/11014 [02:04<00:52, 60.16it/s]
Training CobwebTree:  71%|  | 7866/11014 [02:04<00:51, 61.04it/s]
Training CobwebTree:  71%|  | 7873/11014 [02:04<00:50, 61.68it/s]
Training CobwebTree:  72%|  | 7880/11014 [02:05<00:52, 59.96it/s]
Training CobwebTree:  72%|  | 7887/11014 [02:05<00:54, 57.20it/s]
Training CobwebTree:  72%|  | 7893/11014 [02:05<00:55, 56.40it/s]
Training CobwebTree:  72%|  | 7899/11014 [02:05<00:54, 57.16it/s]
Training CobwebTree:  72%|  | 7906/11014 [02:05<00:52, 59.43it/s]
Training CobwebTree:  72%|  | 7912/11014 [02:05<00:54, 56.63it/s]
Training CobwebTree:  72%|  | 7919/11014 [02:05<00:54, 57.22it/s]
Training CobwebTree:  72%|  | 7925/11014 [02:05<00:54, 57.11it/s]
Training CobwebTree:  72%|  | 7931/11014 [02:06<00:54, 57.06it/s]
Training CobwebTree:  72%|  | 7937/11014 [02:06<00:54, 56.80it/s]
Training CobwebTree:  72%|  | 7943/11014 [02:06<00:54, 56.44it/s]
Training CobwebTree:  72%|  | 7949/11014 [02:06<00:54, 56.60it/s]
Training CobwebTree:  72%|  | 7956/11014 [02:06<00:52, 57.85it/s]
Training CobwebTree:  72%|  | 7962/11014 [02:06<00:55, 54.57it/s]
Training CobwebTree:  72%|  | 7969/11014 [02:06<00:53, 56.85it/s]
Training CobwebTree:  72%|  | 7975/11014 [02:06<00:54, 55.57it/s]
Training CobwebTree:  72%|  | 7981/11014 [02:06<00:57, 52.72it/s]
Training CobwebTree:  73%|  | 7988/11014 [02:07<00:53, 57.06it/s]
Training CobwebTree:  73%|  | 7994/11014 [02:07<00:53, 56.90it/s]
Training CobwebTree:  73%|  | 8000/11014 [02:07<00:53, 56.25it/s]
Training CobwebTree:  73%|  | 8006/11014 [02:07<00:53, 55.73it/s]
Training CobwebTree:  73%|  | 8012/11014 [02:07<00:54, 55.44it/s]
Training CobwebTree:  73%|  | 8018/11014 [02:07<00:53, 56.50it/s]
Training CobwebTree:  73%|  | 8024/11014 [02:07<00:54, 54.89it/s]
Training CobwebTree:  73%|  | 8030/11014 [02:07<00:54, 54.58it/s]
Training CobwebTree:  73%|  | 8036/11014 [02:07<00:53, 55.97it/s]
Training CobwebTree:  73%|  | 8042/11014 [02:08<00:52, 56.18it/s]
Training CobwebTree:  73%|  | 8048/11014 [02:08<00:51, 57.19it/s]
Training CobwebTree:  73%|  | 8054/11014 [02:08<00:52, 55.95it/s]
Training CobwebTree:  73%|  | 8060/11014 [02:08<00:52, 56.74it/s]
Training CobwebTree:  73%|  | 8066/11014 [02:08<00:51, 56.71it/s]
Training CobwebTree:  73%|  | 8072/11014 [02:08<00:51, 56.62it/s]
Training CobwebTree:  73%|  | 8078/11014 [02:08<00:52, 56.42it/s]
Training CobwebTree:  73%|  | 8084/11014 [02:08<00:51, 56.46it/s]
Training CobwebTree:  73%|  | 8090/11014 [02:08<00:53, 55.05it/s]
Training CobwebTree:  74%|  | 8097/11014 [02:08<00:51, 56.71it/s]
Training CobwebTree:  74%|  | 8103/11014 [02:09<00:51, 56.50it/s]
Training CobwebTree:  74%|  | 8109/11014 [02:09<00:51, 56.40it/s]
Training CobwebTree:  74%|  | 8115/11014 [02:09<00:51, 56.60it/s]
Training CobwebTree:  74%|  | 8121/11014 [02:09<00:53, 54.35it/s]
Training CobwebTree:  74%|  | 8127/11014 [02:09<00:52, 54.64it/s]
Training CobwebTree:  74%|  | 8133/11014 [02:09<00:52, 54.78it/s]
Training CobwebTree:  74%|  | 8140/11014 [02:09<00:50, 57.05it/s]
Training CobwebTree:  74%|  | 8146/11014 [02:09<00:50, 56.79it/s]
Training CobwebTree:  74%|  | 8152/11014 [02:09<00:50, 56.90it/s]
Training CobwebTree:  74%|  | 8158/11014 [02:10<00:51, 55.54it/s]
Training CobwebTree:  74%|  | 8164/11014 [02:10<00:51, 55.48it/s]
Training CobwebTree:  74%|  | 8171/11014 [02:10<00:48, 58.28it/s]
Training CobwebTree:  74%|  | 8177/11014 [02:10<00:49, 57.71it/s]
Training CobwebTree:  74%|  | 8183/11014 [02:10<00:48, 58.23it/s]
Training CobwebTree:  74%|  | 8190/11014 [02:10<00:47, 59.30it/s]
Training CobwebTree:  74%|  | 8196/11014 [02:10<00:49, 57.26it/s]
Training CobwebTree:  74%|  | 8202/11014 [02:10<00:50, 55.86it/s]
Training CobwebTree:  75%|  | 8208/11014 [02:10<00:49, 56.60it/s]
Training CobwebTree:  75%|  | 8214/11014 [02:11<00:50, 55.69it/s]
Training CobwebTree:  75%|  | 8221/11014 [02:11<00:48, 57.90it/s]
Training CobwebTree:  75%|  | 8227/11014 [02:11<00:49, 56.72it/s]
Training CobwebTree:  75%|  | 8233/11014 [02:11<00:49, 56.16it/s]
Training CobwebTree:  75%|  | 8239/11014 [02:11<00:49, 55.58it/s]
Training CobwebTree:  75%|  | 8245/11014 [02:11<00:49, 55.62it/s]
Training CobwebTree:  75%|  | 8251/11014 [02:11<00:48, 56.48it/s]
Training CobwebTree:  75%|  | 8257/11014 [02:11<00:49, 56.06it/s]
Training CobwebTree:  75%|  | 8263/11014 [02:11<00:49, 55.67it/s]
Training CobwebTree:  75%|  | 8269/11014 [02:12<00:48, 56.13it/s]
Training CobwebTree:  75%|  | 8276/11014 [02:12<00:47, 57.76it/s]
Training CobwebTree:  75%|  | 8282/11014 [02:12<00:48, 56.12it/s]
Training CobwebTree:  75%|  | 8288/11014 [02:12<00:49, 55.18it/s]
Training CobwebTree:  75%|  | 8294/11014 [02:12<00:49, 54.51it/s]
Training CobwebTree:  75%|  | 8301/11014 [02:12<00:47, 57.27it/s]
Training CobwebTree:  75%|  | 8307/11014 [02:12<00:47, 57.50it/s]
Training CobwebTree:  75%|  | 8313/11014 [02:12<00:47, 57.43it/s]
Training CobwebTree:  76%|  | 8319/11014 [02:12<00:47, 56.80it/s]
Training CobwebTree:  76%|  | 8325/11014 [02:13<00:47, 56.38it/s]
Training CobwebTree:  76%|  | 8331/11014 [02:13<00:47, 56.54it/s]
Training CobwebTree:  76%|  | 8337/11014 [02:13<00:47, 56.31it/s]
Training CobwebTree:  76%|  | 8343/11014 [02:13<00:47, 56.55it/s]
Training CobwebTree:  76%|  | 8349/11014 [02:13<00:47, 56.09it/s]
Training CobwebTree:  76%|  | 8355/11014 [02:13<00:50, 53.15it/s]
Training CobwebTree:  76%|  | 8361/11014 [02:13<00:49, 54.13it/s]
Training CobwebTree:  76%|  | 8367/11014 [02:13<00:48, 54.72it/s]
Training CobwebTree:  76%|  | 8373/11014 [02:13<00:48, 53.99it/s]
Training CobwebTree:  76%|  | 8380/11014 [02:14<00:46, 56.68it/s]
Training CobwebTree:  76%|  | 8386/11014 [02:14<00:46, 56.56it/s]
Training CobwebTree:  76%|  | 8393/11014 [02:14<00:45, 57.76it/s]
Training CobwebTree:  76%|  | 8400/11014 [02:14<00:44, 58.35it/s]
Training CobwebTree:  76%|  | 8406/11014 [02:14<00:45, 57.04it/s]
Training CobwebTree:  76%|  | 8413/11014 [02:14<00:43, 59.29it/s]
Training CobwebTree:  76%|  | 8420/11014 [02:14<00:42, 60.97it/s]
Training CobwebTree:  77%|  | 8427/11014 [02:14<00:45, 57.08it/s]
Training CobwebTree:  77%|  | 8434/11014 [02:14<00:44, 58.01it/s]
Training CobwebTree:  77%|  | 8440/11014 [02:15<00:44, 57.96it/s]
Training CobwebTree:  77%|  | 8446/11014 [02:15<00:44, 57.77it/s]
Training CobwebTree:  77%|  | 8452/11014 [02:15<00:44, 57.97it/s]
Training CobwebTree:  77%|  | 8458/11014 [02:15<00:45, 56.30it/s]
Training CobwebTree:  77%|  | 8465/11014 [02:15<00:43, 58.01it/s]
Training CobwebTree:  77%|  | 8471/11014 [02:15<00:44, 56.84it/s]
Training CobwebTree:  77%|  | 8477/11014 [02:15<00:44, 57.44it/s]
Training CobwebTree:  77%|  | 8483/11014 [02:15<00:45, 55.71it/s]
Training CobwebTree:  77%|  | 8489/11014 [02:15<00:45, 55.80it/s]
Training CobwebTree:  77%|  | 8495/11014 [02:16<00:46, 54.30it/s]
Training CobwebTree:  77%|  | 8502/11014 [02:16<00:44, 56.88it/s]
Training CobwebTree:  77%|  | 8508/11014 [02:16<00:43, 57.03it/s]
Training CobwebTree:  77%|  | 8514/11014 [02:16<00:43, 57.10it/s]
Training CobwebTree:  77%|  | 8520/11014 [02:16<00:43, 57.84it/s]
Training CobwebTree:  77%|  | 8526/11014 [02:16<00:43, 57.45it/s]
Training CobwebTree:  77%|  | 8533/11014 [02:16<00:41, 59.37it/s]
Training CobwebTree:  78%|  | 8539/11014 [02:16<00:41, 59.28it/s]
Training CobwebTree:  78%|  | 8546/11014 [02:16<00:40, 60.91it/s]
Training CobwebTree:  78%|  | 8553/11014 [02:16<00:40, 60.13it/s]
Training CobwebTree:  78%|  | 8560/11014 [02:17<00:41, 58.67it/s]
Training CobwebTree:  78%|  | 8566/11014 [02:17<00:42, 57.58it/s]
Training CobwebTree:  78%|  | 8572/11014 [02:17<00:42, 57.03it/s]
Training CobwebTree:  78%|  | 8579/11014 [02:17<00:41, 58.79it/s]
Training CobwebTree:  78%|  | 8585/11014 [02:17<00:41, 58.51it/s]
Training CobwebTree:  78%|  | 8592/11014 [02:17<00:40, 59.56it/s]
Training CobwebTree:  78%|  | 8599/11014 [02:17<00:40, 59.87it/s]
Training CobwebTree:  78%|  | 8605/11014 [02:17<00:41, 57.97it/s]
Training CobwebTree:  78%|  | 8611/11014 [02:17<00:41, 58.18it/s]
Training CobwebTree:  78%|  | 8618/11014 [02:18<00:40, 58.89it/s]
Training CobwebTree:  78%|  | 8624/11014 [02:18<00:40, 58.44it/s]
Training CobwebTree:  78%|  | 8630/11014 [02:18<00:40, 58.84it/s]
Training CobwebTree:  78%|  | 8636/11014 [02:18<00:41, 57.43it/s]
Training CobwebTree:  78%|  | 8642/11014 [02:18<00:41, 57.14it/s]
Training CobwebTree:  79%|  | 8648/11014 [02:18<00:42, 56.11it/s]
Training CobwebTree:  79%|  | 8654/11014 [02:18<00:42, 55.00it/s]
Training CobwebTree:  79%|  | 8660/11014 [02:18<00:41, 56.26it/s]
Training CobwebTree:  79%|  | 8667/11014 [02:18<00:40, 57.32it/s]
Training CobwebTree:  79%|  | 8674/11014 [02:19<00:40, 58.37it/s]
Training CobwebTree:  79%|  | 8680/11014 [02:19<00:40, 58.27it/s]
Training CobwebTree:  79%|  | 8686/11014 [02:19<00:39, 58.30it/s]
Training CobwebTree:  79%|  | 8692/11014 [02:19<00:41, 56.20it/s]
Training CobwebTree:  79%|  | 8698/11014 [02:19<00:41, 56.10it/s]
Training CobwebTree:  79%|  | 8704/11014 [02:19<00:41, 55.14it/s]
Training CobwebTree:  79%|  | 8710/11014 [02:19<00:41, 55.18it/s]
Training CobwebTree:  79%|  | 8716/11014 [02:19<00:42, 54.27it/s]
Training CobwebTree:  79%|  | 8722/11014 [02:19<00:42, 54.02it/s]
Training CobwebTree:  79%|  | 8728/11014 [02:20<00:43, 52.15it/s]
Training CobwebTree:  79%|  | 8734/11014 [02:20<00:42, 53.16it/s]
Training CobwebTree:  79%|  | 8740/11014 [02:20<00:42, 53.35it/s]
Training CobwebTree:  79%|  | 8746/11014 [02:20<00:41, 55.01it/s]
Training CobwebTree:  79%|  | 8752/11014 [02:20<00:40, 56.21it/s]
Training CobwebTree:  80%|  | 8758/11014 [02:20<00:40, 55.05it/s]
Training CobwebTree:  80%|  | 8765/11014 [02:20<00:40, 56.15it/s]
Training CobwebTree:  80%|  | 8771/11014 [02:20<00:40, 54.91it/s]
Training CobwebTree:  80%|  | 8777/11014 [02:20<00:40, 54.82it/s]
Training CobwebTree:  80%|  | 8783/11014 [02:21<00:40, 55.06it/s]
Training CobwebTree:  80%|  | 8789/11014 [02:21<00:40, 55.28it/s]
Training CobwebTree:  80%|  | 8795/11014 [02:21<00:40, 55.34it/s]
Training CobwebTree:  80%|  | 8801/11014 [02:21<00:39, 55.60it/s]
Training CobwebTree:  80%|  | 8807/11014 [02:21<00:39, 55.82it/s]
Training CobwebTree:  80%|  | 8813/11014 [02:21<00:39, 55.80it/s]
Training CobwebTree:  80%|  | 8819/11014 [02:21<00:40, 54.45it/s]
Training CobwebTree:  80%|  | 8825/11014 [02:21<00:41, 52.51it/s]
Training CobwebTree:  80%|  | 8832/11014 [02:21<00:39, 55.83it/s]
Training CobwebTree:  80%|  | 8838/11014 [02:22<00:40, 53.98it/s]
Training CobwebTree:  80%|  | 8844/11014 [02:22<00:40, 54.21it/s]
Training CobwebTree:  80%|  | 8850/11014 [02:22<00:39, 54.26it/s]
Training CobwebTree:  80%|  | 8856/11014 [02:22<00:38, 55.52it/s]
Training CobwebTree:  80%|  | 8862/11014 [02:22<00:39, 54.72it/s]
Training CobwebTree:  81%|  | 8868/11014 [02:22<00:39, 53.85it/s]
Training CobwebTree:  81%|  | 8874/11014 [02:22<00:39, 54.22it/s]
Training CobwebTree:  81%|  | 8880/11014 [02:22<00:38, 55.56it/s]
Training CobwebTree:  81%|  | 8887/11014 [02:22<00:37, 56.54it/s]
Training CobwebTree:  81%|  | 8894/11014 [02:23<00:36, 57.93it/s]
Training CobwebTree:  81%|  | 8900/11014 [02:23<00:36, 57.70it/s]
Training CobwebTree:  81%|  | 8906/11014 [02:23<00:37, 56.60it/s]
Training CobwebTree:  81%|  | 8912/11014 [02:23<00:38, 54.40it/s]
Training CobwebTree:  81%|  | 8918/11014 [02:23<00:37, 55.30it/s]
Training CobwebTree:  81%|  | 8924/11014 [02:23<00:38, 54.65it/s]
Training CobwebTree:  81%|  | 8930/11014 [02:23<00:37, 54.87it/s]
Training CobwebTree:  81%|  | 8937/11014 [02:23<00:36, 56.47it/s]
Training CobwebTree:  81%|  | 8944/11014 [02:23<00:35, 57.89it/s]
Training CobwebTree:  81%| | 8950/11014 [02:24<00:35, 58.09it/s]
Training CobwebTree:  81%| | 8957/11014 [02:24<00:35, 58.59it/s]
Training CobwebTree:  81%| | 8963/11014 [02:24<00:36, 56.32it/s]
Training CobwebTree:  81%| | 8969/11014 [02:24<00:36, 56.13it/s]
Training CobwebTree:  81%| | 8976/11014 [02:24<00:35, 57.69it/s]
Training CobwebTree:  82%| | 8982/11014 [02:24<00:35, 56.48it/s]
Training CobwebTree:  82%| | 8988/11014 [02:24<00:36, 55.63it/s]
Training CobwebTree:  82%| | 8994/11014 [02:24<00:36, 55.20it/s]
Training CobwebTree:  82%| | 9000/11014 [02:24<00:35, 56.02it/s]
Training CobwebTree:  82%| | 9006/11014 [02:25<00:37, 53.49it/s]
Training CobwebTree:  82%| | 9012/11014 [02:25<00:36, 54.76it/s]
Training CobwebTree:  82%| | 9018/11014 [02:25<00:35, 56.17it/s]
Training CobwebTree:  82%| | 9024/11014 [02:25<00:35, 56.46it/s]
Training CobwebTree:  82%| | 9030/11014 [02:25<00:35, 55.49it/s]
Training CobwebTree:  82%| | 9036/11014 [02:25<00:36, 53.56it/s]
Training CobwebTree:  82%| | 9042/11014 [02:25<00:36, 53.81it/s]
Training CobwebTree:  82%| | 9048/11014 [02:25<00:38, 51.19it/s]
Training CobwebTree:  82%| | 9055/11014 [02:25<00:36, 54.02it/s]
Training CobwebTree:  82%| | 9061/11014 [02:26<00:35, 55.11it/s]
Training CobwebTree:  82%| | 9068/11014 [02:26<00:34, 56.08it/s]
Training CobwebTree:  82%| | 9074/11014 [02:26<00:35, 55.17it/s]
Training CobwebTree:  82%| | 9080/11014 [02:26<00:34, 56.08it/s]
Training CobwebTree:  82%| | 9086/11014 [02:26<00:33, 56.99it/s]
Training CobwebTree:  83%| | 9092/11014 [02:26<00:34, 55.05it/s]
Training CobwebTree:  83%| | 9099/11014 [02:26<00:33, 57.27it/s]
Training CobwebTree:  83%| | 9105/11014 [02:26<00:34, 55.44it/s]
Training CobwebTree:  83%| | 9111/11014 [02:27<00:34, 54.66it/s]
Training CobwebTree:  83%| | 9117/11014 [02:27<00:34, 55.24it/s]
Training CobwebTree:  83%| | 9123/11014 [02:27<00:34, 54.61it/s]
Training CobwebTree:  83%| | 9129/11014 [02:27<00:33, 56.05it/s]
Training CobwebTree:  83%| | 9135/11014 [02:27<00:32, 57.15it/s]
Training CobwebTree:  83%| | 9141/11014 [02:27<00:32, 56.99it/s]
Training CobwebTree:  83%| | 9147/11014 [02:27<00:32, 57.70it/s]
Training CobwebTree:  83%| | 9154/11014 [02:27<00:31, 58.85it/s]
Training CobwebTree:  83%| | 9160/11014 [02:27<00:32, 57.58it/s]
Training CobwebTree:  83%| | 9166/11014 [02:27<00:32, 57.00it/s]
Training CobwebTree:  83%| | 9173/11014 [02:28<00:32, 57.33it/s]
Training CobwebTree:  83%| | 9179/11014 [02:28<00:32, 55.98it/s]
Training CobwebTree:  83%| | 9185/11014 [02:28<00:32, 55.94it/s]
Training CobwebTree:  83%| | 9191/11014 [02:28<00:32, 56.16it/s]
Training CobwebTree:  84%| | 9197/11014 [02:28<00:32, 56.06it/s]
Training CobwebTree:  84%| | 9203/11014 [02:28<00:32, 56.00it/s]
Training CobwebTree:  84%| | 9209/11014 [02:28<00:32, 54.73it/s]
Training CobwebTree:  84%| | 9215/11014 [02:28<00:33, 53.41it/s]
Training CobwebTree:  84%| | 9221/11014 [02:28<00:33, 53.91it/s]
Training CobwebTree:  84%| | 9227/11014 [02:29<00:33, 53.91it/s]
Training CobwebTree:  84%| | 9233/11014 [02:29<00:32, 55.34it/s]
Training CobwebTree:  84%| | 9239/11014 [02:29<00:31, 55.66it/s]
Training CobwebTree:  84%| | 9245/11014 [02:29<00:31, 55.58it/s]
Training CobwebTree:  84%| | 9251/11014 [02:29<00:31, 55.85it/s]
Training CobwebTree:  84%| | 9257/11014 [02:29<00:32, 54.58it/s]
Training CobwebTree:  84%| | 9264/11014 [02:29<00:31, 56.44it/s]
Training CobwebTree:  84%| | 9270/11014 [02:29<00:32, 53.56it/s]
Training CobwebTree:  84%| | 9276/11014 [02:29<00:31, 54.51it/s]
Training CobwebTree:  84%| | 9282/11014 [02:30<00:32, 52.70it/s]
Training CobwebTree:  84%| | 9288/11014 [02:30<00:32, 52.76it/s]
Training CobwebTree:  84%| | 9294/11014 [02:30<00:31, 53.96it/s]
Training CobwebTree:  84%| | 9300/11014 [02:30<00:32, 53.44it/s]
Training CobwebTree:  84%| | 9306/11014 [02:30<00:31, 54.77it/s]
Training CobwebTree:  85%| | 9312/11014 [02:30<00:32, 53.13it/s]
Training CobwebTree:  85%| | 9318/11014 [02:30<00:31, 53.35it/s]
Training CobwebTree:  85%| | 9324/11014 [02:30<00:31, 53.44it/s]
Training CobwebTree:  85%| | 9330/11014 [02:30<00:31, 54.02it/s]
Training CobwebTree:  85%| | 9336/11014 [02:31<00:31, 53.48it/s]
Training CobwebTree:  85%| | 9342/11014 [02:31<00:30, 54.47it/s]
Training CobwebTree:  85%| | 9348/11014 [02:31<00:30, 55.35it/s]
Training CobwebTree:  85%| | 9354/11014 [02:31<00:30, 54.03it/s]
Training CobwebTree:  85%| | 9360/11014 [02:31<00:30, 54.04it/s]
Training CobwebTree:  85%| | 9366/11014 [02:31<00:31, 51.70it/s]
Training CobwebTree:  85%| | 9373/11014 [02:31<00:30, 54.01it/s]
Training CobwebTree:  85%| | 9379/11014 [02:31<00:29, 55.09it/s]
Training CobwebTree:  85%| | 9385/11014 [02:31<00:29, 54.92it/s]
Training CobwebTree:  85%| | 9391/11014 [02:32<00:30, 53.58it/s]
Training CobwebTree:  85%| | 9398/11014 [02:32<00:29, 55.49it/s]
Training CobwebTree:  85%| | 9404/11014 [02:32<00:29, 55.36it/s]
Training CobwebTree:  85%| | 9410/11014 [02:32<00:28, 55.80it/s]
Training CobwebTree:  85%| | 9416/11014 [02:32<00:28, 55.18it/s]
Training CobwebTree:  86%| | 9422/11014 [02:32<00:28, 55.63it/s]
Training CobwebTree:  86%| | 9428/11014 [02:32<00:29, 53.24it/s]
Training CobwebTree:  86%| | 9434/11014 [02:32<00:28, 55.04it/s]
Training CobwebTree:  86%| | 9440/11014 [02:32<00:27, 56.34it/s]
Training CobwebTree:  86%| | 9446/11014 [02:33<00:28, 55.19it/s]
Training CobwebTree:  86%| | 9453/11014 [02:33<00:27, 56.38it/s]
Training CobwebTree:  86%| | 9459/11014 [02:33<00:27, 55.61it/s]
Training CobwebTree:  86%| | 9466/11014 [02:33<00:27, 56.95it/s]
Training CobwebTree:  86%| | 9472/11014 [02:33<00:26, 57.25it/s]
Training CobwebTree:  86%| | 9478/11014 [02:33<00:26, 57.27it/s]
Training CobwebTree:  86%| | 9485/11014 [02:33<00:25, 60.42it/s]
Training CobwebTree:  86%| | 9492/11014 [02:33<00:25, 58.68it/s]
Training CobwebTree:  86%| | 9498/11014 [02:33<00:26, 58.13it/s]
Training CobwebTree:  86%| | 9504/11014 [02:34<00:26, 56.91it/s]
Training CobwebTree:  86%| | 9510/11014 [02:34<00:26, 57.63it/s]
Training CobwebTree:  86%| | 9516/11014 [02:34<00:26, 56.07it/s]
Training CobwebTree:  86%| | 9522/11014 [02:34<00:26, 55.29it/s]
Training CobwebTree:  87%| | 9529/11014 [02:34<00:26, 56.71it/s]
Training CobwebTree:  87%| | 9535/11014 [02:34<00:26, 56.86it/s]
Training CobwebTree:  87%| | 9541/11014 [02:34<00:26, 55.69it/s]
Training CobwebTree:  87%| | 9547/11014 [02:34<00:27, 53.59it/s]
Training CobwebTree:  87%| | 9553/11014 [02:34<00:28, 52.04it/s]
Training CobwebTree:  87%| | 9560/11014 [02:35<00:26, 54.34it/s]
Training CobwebTree:  87%| | 9566/11014 [02:35<00:26, 54.12it/s]
Training CobwebTree:  87%| | 9572/11014 [02:35<00:26, 55.09it/s]
Training CobwebTree:  87%| | 9578/11014 [02:35<00:26, 55.09it/s]
Training CobwebTree:  87%| | 9584/11014 [02:35<00:25, 56.12it/s]
Training CobwebTree:  87%| | 9590/11014 [02:35<00:25, 55.85it/s]
Training CobwebTree:  87%| | 9596/11014 [02:35<00:25, 55.77it/s]
Training CobwebTree:  87%| | 9602/11014 [02:35<00:26, 53.05it/s]
Training CobwebTree:  87%| | 9608/11014 [02:36<00:26, 52.93it/s]
Training CobwebTree:  87%| | 9614/11014 [02:36<00:26, 53.73it/s]
Training CobwebTree:  87%| | 9620/11014 [02:36<00:26, 53.09it/s]
Training CobwebTree:  87%| | 9626/11014 [02:36<00:26, 52.69it/s]
Training CobwebTree:  87%| | 9633/11014 [02:36<00:25, 54.32it/s]
Training CobwebTree:  88%| | 9640/11014 [02:36<00:24, 56.86it/s]
Training CobwebTree:  88%| | 9646/11014 [02:36<00:24, 56.27it/s]
Training CobwebTree:  88%| | 9652/11014 [02:36<00:24, 56.43it/s]
Training CobwebTree:  88%| | 9658/11014 [02:36<00:23, 56.54it/s]
Training CobwebTree:  88%| | 9664/11014 [02:36<00:23, 57.13it/s]
Training CobwebTree:  88%| | 9671/11014 [02:37<00:23, 58.34it/s]
Training CobwebTree:  88%| | 9677/11014 [02:37<00:23, 56.63it/s]
Training CobwebTree:  88%| | 9683/11014 [02:37<00:23, 56.18it/s]
Training CobwebTree:  88%| | 9689/11014 [02:37<00:23, 55.29it/s]
Training CobwebTree:  88%| | 9695/11014 [02:37<00:24, 54.70it/s]
Training CobwebTree:  88%| | 9701/11014 [02:37<00:24, 53.40it/s]
Training CobwebTree:  88%| | 9707/11014 [02:37<00:23, 54.85it/s]
Training CobwebTree:  88%| | 9713/11014 [02:37<00:23, 54.55it/s]
Training CobwebTree:  88%| | 9719/11014 [02:38<00:24, 53.25it/s]
Training CobwebTree:  88%| | 9725/11014 [02:38<00:23, 54.52it/s]
Training CobwebTree:  88%| | 9731/11014 [02:38<00:23, 54.43it/s]
Training CobwebTree:  88%| | 9737/11014 [02:38<00:23, 53.50it/s]
Training CobwebTree:  88%| | 9743/11014 [02:38<00:24, 52.38it/s]
Training CobwebTree:  89%| | 9749/11014 [02:38<00:24, 52.52it/s]
Training CobwebTree:  89%| | 9755/11014 [02:38<00:24, 52.16it/s]
Training CobwebTree:  89%| | 9761/11014 [02:38<00:23, 54.16it/s]
Training CobwebTree:  89%| | 9767/11014 [02:38<00:22, 55.46it/s]
Training CobwebTree:  89%| | 9773/11014 [02:39<00:22, 54.78it/s]
Training CobwebTree:  89%| | 9779/11014 [02:39<00:22, 55.72it/s]
Training CobwebTree:  89%| | 9785/11014 [02:39<00:22, 53.47it/s]
Training CobwebTree:  89%| | 9791/11014 [02:39<00:22, 53.56it/s]
Training CobwebTree:  89%| | 9797/11014 [02:39<00:22, 54.73it/s]
Training CobwebTree:  89%| | 9803/11014 [02:39<00:22, 54.60it/s]
Training CobwebTree:  89%| | 9809/11014 [02:39<00:21, 55.06it/s]
Training CobwebTree:  89%| | 9815/11014 [02:39<00:22, 54.24it/s]
Training CobwebTree:  89%| | 9821/11014 [02:39<00:21, 54.71it/s]
Training CobwebTree:  89%| | 9827/11014 [02:40<00:22, 53.26it/s]
Training CobwebTree:  89%| | 9833/11014 [02:40<00:22, 51.95it/s]
Training CobwebTree:  89%| | 9839/11014 [02:40<00:23, 51.05it/s]
Training CobwebTree:  89%| | 9846/11014 [02:40<00:21, 54.31it/s]
Training CobwebTree:  89%| | 9852/11014 [02:40<00:21, 53.16it/s]
Training CobwebTree:  90%| | 9858/11014 [02:40<00:22, 52.10it/s]
Training CobwebTree:  90%| | 9865/11014 [02:40<00:21, 54.21it/s]
Training CobwebTree:  90%| | 9871/11014 [02:40<00:20, 55.56it/s]
Training CobwebTree:  90%| | 9877/11014 [02:40<00:20, 56.44it/s]
Training CobwebTree:  90%| | 9883/11014 [02:41<00:20, 56.48it/s]
Training CobwebTree:  90%| | 9889/11014 [02:41<00:19, 57.19it/s]
Training CobwebTree:  90%| | 9895/11014 [02:41<00:19, 57.14it/s]
Training CobwebTree:  90%| | 9901/11014 [02:41<00:19, 55.98it/s]
Training CobwebTree:  90%| | 9907/11014 [02:41<00:20, 54.41it/s]
Training CobwebTree:  90%| | 9913/11014 [02:41<00:19, 55.82it/s]
Training CobwebTree:  90%| | 9919/11014 [02:41<00:19, 55.35it/s]
Training CobwebTree:  90%| | 9925/11014 [02:41<00:20, 53.88it/s]
Training CobwebTree:  90%| | 9931/11014 [02:41<00:21, 50.57it/s]
Training CobwebTree:  90%| | 9937/11014 [02:42<00:21, 51.14it/s]
Training CobwebTree:  90%| | 9943/11014 [02:42<00:20, 51.57it/s]
Training CobwebTree:  90%| | 9949/11014 [02:42<00:19, 53.26it/s]
Training CobwebTree:  90%| | 9955/11014 [02:42<00:20, 52.88it/s]
Training CobwebTree:  90%| | 9962/11014 [02:42<00:19, 55.13it/s]
Training CobwebTree:  91%| | 9968/11014 [02:42<00:18, 55.08it/s]
Training CobwebTree:  91%| | 9974/11014 [02:42<00:19, 54.19it/s]
Training CobwebTree:  91%| | 9980/11014 [02:42<00:19, 53.15it/s]
Training CobwebTree:  91%| | 9987/11014 [02:42<00:18, 55.56it/s]
Training CobwebTree:  91%| | 9993/11014 [02:43<00:18, 54.14it/s]
Training CobwebTree:  91%| | 10000/11014 [02:43<00:17, 57.22it/s]
Training CobwebTree:  91%| | 10006/11014 [02:43<00:18, 55.66it/s]
Training CobwebTree:  91%| | 10012/11014 [02:43<00:17, 56.73it/s]
Training CobwebTree:  91%| | 10019/11014 [02:43<00:17, 57.39it/s]
Training CobwebTree:  91%| | 10025/11014 [02:43<00:18, 54.29it/s]
Training CobwebTree:  91%| | 10031/11014 [02:43<00:17, 55.63it/s]
Training CobwebTree:  91%| | 10037/11014 [02:43<00:17, 54.87it/s]
Training CobwebTree:  91%| | 10043/11014 [02:43<00:17, 56.23it/s]
Training CobwebTree:  91%| | 10050/11014 [02:44<00:16, 57.58it/s]
Training CobwebTree:  91%|| 10056/11014 [02:44<00:16, 57.39it/s]
Training CobwebTree:  91%|| 10062/11014 [02:44<00:16, 57.49it/s]
Training CobwebTree:  91%|| 10069/11014 [02:44<00:16, 58.08it/s]
Training CobwebTree:  91%|| 10075/11014 [02:44<00:16, 56.68it/s]
Training CobwebTree:  92%|| 10081/11014 [02:44<00:16, 55.51it/s]
Training CobwebTree:  92%|| 10087/11014 [02:44<00:17, 53.28it/s]
Training CobwebTree:  92%|| 10093/11014 [02:44<00:17, 53.03it/s]
Training CobwebTree:  92%|| 10100/11014 [02:44<00:16, 54.50it/s]
Training CobwebTree:  92%|| 10106/11014 [02:45<00:16, 54.48it/s]
Training CobwebTree:  92%|| 10113/11014 [02:45<00:15, 56.40it/s]
Training CobwebTree:  92%|| 10119/11014 [02:45<00:15, 56.42it/s]
Training CobwebTree:  92%|| 10125/11014 [02:45<00:15, 56.97it/s]
Training CobwebTree:  92%|| 10131/11014 [02:45<00:15, 56.19it/s]
Training CobwebTree:  92%|| 10137/11014 [02:45<00:15, 56.96it/s]
Training CobwebTree:  92%|| 10143/11014 [02:45<00:15, 57.49it/s]
Training CobwebTree:  92%|| 10149/11014 [02:45<00:14, 57.87it/s]
Training CobwebTree:  92%|| 10155/11014 [02:45<00:15, 56.94it/s]
Training CobwebTree:  92%|| 10162/11014 [02:46<00:14, 58.02it/s]
Training CobwebTree:  92%|| 10168/11014 [02:46<00:14, 57.20it/s]
Training CobwebTree:  92%|| 10174/11014 [02:46<00:14, 57.87it/s]
Training CobwebTree:  92%|| 10180/11014 [02:46<00:14, 57.79it/s]
Training CobwebTree:  92%|| 10187/11014 [02:46<00:14, 58.46it/s]
Training CobwebTree:  93%|| 10193/11014 [02:46<00:14, 56.90it/s]
Training CobwebTree:  93%|| 10199/11014 [02:46<00:14, 54.44it/s]
Training CobwebTree:  93%|| 10205/11014 [02:46<00:14, 54.55it/s]
Training CobwebTree:  93%|| 10211/11014 [02:46<00:14, 54.06it/s]
Training CobwebTree:  93%|| 10217/11014 [02:47<00:14, 54.81it/s]
Training CobwebTree:  93%|| 10223/11014 [02:47<00:14, 53.62it/s]
Training CobwebTree:  93%|| 10229/11014 [02:47<00:14, 52.37it/s]
Training CobwebTree:  93%|| 10235/11014 [02:47<00:14, 52.46it/s]
Training CobwebTree:  93%|| 10241/11014 [02:47<00:14, 52.91it/s]
Training CobwebTree:  93%|| 10247/11014 [02:47<00:14, 53.09it/s]
Training CobwebTree:  93%|| 10253/11014 [02:47<00:14, 53.34it/s]
Training CobwebTree:  93%|| 10259/11014 [02:47<00:14, 52.84it/s]
Training CobwebTree:  93%|| 10265/11014 [02:47<00:14, 51.97it/s]
Training CobwebTree:  93%|| 10271/11014 [02:48<00:14, 52.79it/s]
Training CobwebTree:  93%|| 10277/11014 [02:48<00:13, 53.18it/s]
Training CobwebTree:  93%|| 10283/11014 [02:48<00:13, 54.58it/s]
Training CobwebTree:  93%|| 10289/11014 [02:48<00:12, 55.89it/s]
Training CobwebTree:  93%|| 10295/11014 [02:48<00:13, 54.99it/s]
Training CobwebTree:  94%|| 10301/11014 [02:48<00:13, 52.99it/s]
Training CobwebTree:  94%|| 10307/11014 [02:48<00:13, 53.25it/s]
Training CobwebTree:  94%|| 10313/11014 [02:48<00:12, 54.06it/s]
Training CobwebTree:  94%|| 10319/11014 [02:48<00:12, 54.13it/s]
Training CobwebTree:  94%|| 10325/11014 [02:49<00:12, 53.56it/s]
Training CobwebTree:  94%|| 10331/11014 [02:49<00:12, 54.63it/s]
Training CobwebTree:  94%|| 10337/11014 [02:49<00:12, 53.03it/s]
Training CobwebTree:  94%|| 10343/11014 [02:49<00:12, 53.81it/s]
Training CobwebTree:  94%|| 10349/11014 [02:49<00:12, 54.22it/s]
Training CobwebTree:  94%|| 10355/11014 [02:49<00:12, 53.12it/s]
Training CobwebTree:  94%|| 10361/11014 [02:49<00:12, 53.90it/s]
Training CobwebTree:  94%|| 10367/11014 [02:49<00:11, 54.45it/s]
Training CobwebTree:  94%|| 10373/11014 [02:49<00:11, 54.96it/s]
Training CobwebTree:  94%|| 10379/11014 [02:50<00:11, 54.81it/s]
Training CobwebTree:  94%|| 10385/11014 [02:50<00:11, 53.23it/s]
Training CobwebTree:  94%|| 10391/11014 [02:50<00:11, 54.80it/s]
Training CobwebTree:  94%|| 10397/11014 [02:50<00:10, 56.19it/s]
Training CobwebTree:  94%|| 10403/11014 [02:50<00:10, 56.75it/s]
Training CobwebTree:  95%|| 10409/11014 [02:50<00:10, 56.46it/s]
Training CobwebTree:  95%|| 10415/11014 [02:50<00:10, 56.73it/s]
Training CobwebTree:  95%|| 10421/11014 [02:50<00:10, 55.92it/s]
Training CobwebTree:  95%|| 10427/11014 [02:50<00:10, 55.02it/s]
Training CobwebTree:  95%|| 10433/11014 [02:51<00:10, 54.37it/s]
Training CobwebTree:  95%|| 10439/11014 [02:51<00:10, 53.49it/s]
Training CobwebTree:  95%|| 10445/11014 [02:51<00:10, 53.48it/s]
Training CobwebTree:  95%|| 10451/11014 [02:51<00:10, 53.15it/s]
Training CobwebTree:  95%|| 10457/11014 [02:51<00:10, 54.01it/s]
Training CobwebTree:  95%|| 10463/11014 [02:51<00:10, 52.27it/s]
Training CobwebTree:  95%|| 10469/11014 [02:51<00:10, 52.88it/s]
Training CobwebTree:  95%|| 10475/11014 [02:51<00:10, 52.37it/s]
Training CobwebTree:  95%|| 10481/11014 [02:51<00:09, 53.97it/s]
Training CobwebTree:  95%|| 10487/11014 [02:52<00:09, 53.65it/s]
Training CobwebTree:  95%|| 10493/11014 [02:52<00:09, 52.70it/s]
Training CobwebTree:  95%|| 10499/11014 [02:52<00:09, 54.14it/s]
Training CobwebTree:  95%|| 10505/11014 [02:52<00:09, 54.39it/s]
Training CobwebTree:  95%|| 10511/11014 [02:52<00:09, 54.77it/s]
Training CobwebTree:  95%|| 10517/11014 [02:52<00:09, 53.98it/s]
Training CobwebTree:  96%|| 10523/11014 [02:52<00:08, 54.62it/s]
Training CobwebTree:  96%|| 10530/11014 [02:52<00:08, 55.81it/s]
Training CobwebTree:  96%|| 10537/11014 [02:52<00:08, 56.63it/s]
Training CobwebTree:  96%|| 10544/11014 [02:53<00:08, 57.23it/s]
Training CobwebTree:  96%|| 10550/11014 [02:53<00:08, 57.41it/s]
Training CobwebTree:  96%|| 10556/11014 [02:53<00:08, 54.49it/s]
Training CobwebTree:  96%|| 10562/11014 [02:53<00:08, 54.24it/s]
Training CobwebTree:  96%|| 10568/11014 [02:53<00:08, 54.00it/s]
Training CobwebTree:  96%|| 10574/11014 [02:53<00:08, 54.28it/s]
Training CobwebTree:  96%|| 10580/11014 [02:53<00:07, 54.78it/s]
Training CobwebTree:  96%|| 10586/11014 [02:53<00:08, 53.07it/s]
Training CobwebTree:  96%|| 10592/11014 [02:53<00:07, 53.26it/s]
Training CobwebTree:  96%|| 10598/11014 [02:54<00:07, 53.49it/s]
Training CobwebTree:  96%|| 10604/11014 [02:54<00:08, 51.08it/s]
Training CobwebTree:  96%|| 10610/11014 [02:54<00:07, 53.07it/s]
Training CobwebTree:  96%|| 10616/11014 [02:54<00:07, 52.29it/s]
Training CobwebTree:  96%|| 10622/11014 [02:54<00:07, 52.25it/s]
Training CobwebTree:  96%|| 10628/11014 [02:54<00:07, 51.13it/s]
Training CobwebTree:  97%|| 10634/11014 [02:54<00:07, 51.92it/s]
Training CobwebTree:  97%|| 10640/11014 [02:54<00:07, 51.62it/s]
Training CobwebTree:  97%|| 10646/11014 [02:55<00:06, 53.07it/s]
Training CobwebTree:  97%|| 10652/11014 [02:55<00:06, 52.06it/s]
Training CobwebTree:  97%|| 10658/11014 [02:55<00:06, 52.30it/s]
Training CobwebTree:  97%|| 10664/11014 [02:55<00:06, 53.35it/s]
Training CobwebTree:  97%|| 10670/11014 [02:55<00:06, 54.18it/s]
Training CobwebTree:  97%|| 10676/11014 [02:55<00:06, 53.29it/s]
Training CobwebTree:  97%|| 10682/11014 [02:55<00:06, 54.72it/s]
Training CobwebTree:  97%|| 10688/11014 [02:55<00:05, 55.06it/s]
Training CobwebTree:  97%|| 10694/11014 [02:55<00:05, 54.58it/s]
Training CobwebTree:  97%|| 10700/11014 [02:56<00:05, 54.75it/s]
Training CobwebTree:  97%|| 10706/11014 [02:56<00:05, 54.36it/s]
Training CobwebTree:  97%|| 10712/11014 [02:56<00:05, 54.92it/s]
Training CobwebTree:  97%|| 10719/11014 [02:56<00:05, 56.94it/s]
Training CobwebTree:  97%|| 10726/11014 [02:56<00:04, 58.54it/s]
Training CobwebTree:  97%|| 10732/11014 [02:56<00:04, 57.15it/s]
Training CobwebTree:  97%|| 10738/11014 [02:56<00:04, 56.44it/s]
Training CobwebTree:  98%|| 10744/11014 [02:56<00:04, 55.94it/s]
Training CobwebTree:  98%|| 10750/11014 [02:56<00:04, 55.84it/s]
Training CobwebTree:  98%|| 10756/11014 [02:57<00:04, 54.79it/s]
Training CobwebTree:  98%|| 10762/11014 [02:57<00:04, 54.15it/s]
Training CobwebTree:  98%|| 10768/11014 [02:57<00:04, 54.43it/s]
Training CobwebTree:  98%|| 10774/11014 [02:57<00:04, 52.11it/s]
Training CobwebTree:  98%|| 10780/11014 [02:57<00:04, 53.88it/s]
Training CobwebTree:  98%|| 10786/11014 [02:57<00:04, 54.65it/s]
Training CobwebTree:  98%|| 10792/11014 [02:57<00:04, 52.83it/s]
Training CobwebTree:  98%|| 10798/11014 [02:57<00:04, 53.22it/s]
Training CobwebTree:  98%|| 10805/11014 [02:57<00:03, 56.08it/s]
Training CobwebTree:  98%|| 10811/11014 [02:58<00:03, 56.52it/s]
Training CobwebTree:  98%|| 10817/11014 [02:58<00:03, 54.67it/s]
Training CobwebTree:  98%|| 10823/11014 [02:58<00:03, 54.62it/s]
Training CobwebTree:  98%|| 10829/11014 [02:58<00:03, 54.72it/s]
Training CobwebTree:  98%|| 10835/11014 [02:58<00:03, 55.05it/s]
Training CobwebTree:  98%|| 10841/11014 [02:58<00:03, 54.16it/s]
Training CobwebTree:  98%|| 10847/11014 [02:58<00:03, 52.68it/s]
Training CobwebTree:  99%|| 10853/11014 [02:58<00:03, 52.61it/s]
Training CobwebTree:  99%|| 10859/11014 [02:58<00:03, 51.58it/s]
Training CobwebTree:  99%|| 10865/11014 [02:59<00:03, 49.42it/s]
Training CobwebTree:  99%|| 10871/11014 [02:59<00:02, 50.59it/s]
Training CobwebTree:  99%|| 10877/11014 [02:59<00:02, 49.57it/s]
Training CobwebTree:  99%|| 10883/11014 [02:59<00:02, 51.59it/s]
Training CobwebTree:  99%|| 10889/11014 [02:59<00:02, 51.93it/s]
Training CobwebTree:  99%|| 10895/11014 [02:59<00:02, 52.19it/s]
Training CobwebTree:  99%|| 10901/11014 [02:59<00:02, 53.86it/s]
Training CobwebTree:  99%|| 10907/11014 [02:59<00:01, 53.82it/s]
Training CobwebTree:  99%|| 10914/11014 [02:59<00:01, 54.84it/s]
Training CobwebTree:  99%|| 10920/11014 [03:00<00:01, 55.30it/s]
Training CobwebTree:  99%|| 10926/11014 [03:00<00:01, 55.72it/s]
Training CobwebTree:  99%|| 10932/11014 [03:00<00:01, 56.24it/s]
Training CobwebTree:  99%|| 10938/11014 [03:00<00:01, 55.16it/s]
Training CobwebTree:  99%|| 10944/11014 [03:00<00:01, 54.49it/s]
Training CobwebTree:  99%|| 10951/11014 [03:00<00:01, 55.77it/s]
Training CobwebTree:  99%|| 10957/11014 [03:00<00:01, 55.63it/s]
Training CobwebTree: 100%|| 10963/11014 [03:00<00:00, 56.71it/s]
Training CobwebTree: 100%|| 10969/11014 [03:00<00:00, 56.94it/s]
Training CobwebTree: 100%|| 10975/11014 [03:01<00:00, 57.76it/s]
Training CobwebTree: 100%|| 10981/11014 [03:01<00:00, 57.42it/s]
Training CobwebTree: 100%|| 10987/11014 [03:01<00:00, 58.12it/s]
Training CobwebTree: 100%|| 10993/11014 [03:01<00:00, 56.31it/s]
Training CobwebTree: 100%|| 11000/11014 [03:01<00:00, 58.77it/s]
Training CobwebTree: 100%|| 11006/11014 [03:01<00:00, 57.04it/s]
Training CobwebTree: 100%|| 11012/11014 [03:01<00:00, 56.28it/s]
Training CobwebTree: 100%|| 11014/11014 [03:01<00:00, 60.60it/s]
2025-12-20 23:27:23,021 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:27:24,300 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (7232 virtual)
2025-12-20 23:27:24,307 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3127 virtual)
2025-12-20 23:27:24,311 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (1323 virtual)
2025-12-20 23:27:24,314 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (713 virtual)
2025-12-20 23:27:24,318 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (-5372 virtual)
2025-12-20 23:27:24,321 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-3523 virtual)
2025-12-20 23:27:24,326 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (12146 virtual)
2025-12-20 23:27:24,329 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (22148 virtual)
2025-12-20 23:27:24,332 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (19719 virtual)
2025-12-20 23:27:24,384 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (5184 virtual)
2025-12-20 23:27:24,386 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (6705 virtual)
2025-12-20 23:27:24,622 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (-5029 virtual)
2025-12-20 23:27:24,627 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (-3476 virtual)
2025-12-20 23:27:24,644 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (-2950 virtual)
2025-12-20 23:27:24,673 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (2109 virtual)
2025-12-20 23:27:24,687 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (2483 virtual)
2025-12-20 23:27:24,703 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (6024 virtual)
2025-12-20 23:27:24,715 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (8719 virtual)
2025-12-20 23:27:24,735 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (10782 virtual)
2025-12-20 23:27:24,743 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (12662 virtual)
2025-12-20 23:27:24,764 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (14417 virtual)
2025-12-20 23:27:24,817 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (16318 virtual)
2025-12-20 23:27:24,840 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (21460 virtual)
2025-12-20 23:27:24,867 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (36852 virtual)
2025-12-20 23:27:24,897 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (39766 virtual)
2025-12-20 23:27:24,939 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (41441 virtual)
2025-12-20 23:27:24,952 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (51322 virtual)
2025-12-20 23:27:24,971 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (52687 virtual)
2025-12-20 23:27:24,980 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (52913 virtual)
2025-12-20 23:27:25,003 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (55693 virtual)
2025-12-20 23:27:25,012 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (52992 virtual)
2025-12-20 23:27:25,028 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (50615 virtual)
2025-12-20 23:27:25,126 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (45525 virtual)
2025-12-20 23:27:25,149 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (45324 virtual)
2025-12-20 23:27:25,184 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (42113 virtual)
2025-12-20 23:27:25,212 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (43690 virtual)
2025-12-20 23:27:25,232 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (42608 virtual)
2025-12-20 23:27:25,268 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (39072 virtual)
2025-12-20 23:27:25,312 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (40044 virtual)
2025-12-20 23:27:25,367 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (41542 virtual)
2025-12-20 23:27:25,375 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (45793 virtual)
2025-12-20 23:27:25,399 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (47498 virtual)
2025-12-20 23:27:25,476 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (42550 virtual)
2025-12-20 23:27:25,537 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (37489 virtual)
2025-12-20 23:27:25,561 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (39918 virtual)
2025-12-20 23:27:25,631 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (31027 virtual)
2025-12-20 23:27:25,635 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (40008 virtual)
2025-12-20 23:27:25,782 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (41502 virtual)
2025-12-20 23:27:25,784 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (46622 virtual)
2025-12-20 23:27:25,799 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (48729 virtual)
2025-12-20 23:27:25,805 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (44346 virtual)
2025-12-20 23:27:25,848 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (48297 virtual)
2025-12-20 23:27:25,904 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (35558 virtual)
2025-12-20 23:27:26,001 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (37592 virtual)
2025-12-20 23:27:26,065 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (24474 virtual)
2025-12-20 23:27:26,083 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (24761 virtual)
2025-12-20 23:27:26,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,141 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,142 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,145 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,148 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,185 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,204 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,212 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,222 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,240 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,308 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,334 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,453 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,486 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,618 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,914 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:26,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:26,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:27,001 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:27,006 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:27,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:27,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:27,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:27,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:27,265 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:27,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:27,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:27,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:29,762 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:27:29,858 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 663359 virtual documents
2025-12-20 23:27:31,210 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=47, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-20 23:27:32,540 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5593 virtual)
2025-12-20 23:27:32,544 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10727 virtual)
2025-12-20 23:27:32,546 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (26432 virtual)
2025-12-20 23:27:32,547 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (30159 virtual)
2025-12-20 23:27:32,548 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (32725 virtual)
2025-12-20 23:27:32,549 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (36278 virtual)
2025-12-20 23:27:32,550 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (39220 virtual)
2025-12-20 23:27:32,552 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (54327 virtual)
2025-12-20 23:27:32,553 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (60577 virtual)
2025-12-20 23:27:32,554 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63971 virtual)
2025-12-20 23:27:32,555 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (68747 virtual)
2025-12-20 23:27:32,556 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (78123 virtual)
2025-12-20 23:27:32,557 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (82521 virtual)
2025-12-20 23:27:32,559 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (90313 virtual)
2025-12-20 23:27:32,561 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (95725 virtual)
2025-12-20 23:27:32,562 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (100032 virtual)
2025-12-20 23:27:32,562 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (103002 virtual)
2025-12-20 23:27:32,564 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (109828 virtual)
2025-12-20 23:27:32,565 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (115400 virtual)
2025-12-20 23:27:32,566 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (124477 virtual)
2025-12-20 23:27:32,567 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (128588 virtual)
2025-12-20 23:27:32,568 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (131939 virtual)
2025-12-20 23:27:32,571 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (159346 virtual)
2025-12-20 23:27:32,573 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (175748 virtual)
2025-12-20 23:27:32,574 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (179483 virtual)
2025-12-20 23:27:32,576 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (186119 virtual)
2025-12-20 23:27:32,577 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (189134 virtual)
2025-12-20 23:27:32,578 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (194011 virtual)
2025-12-20 23:27:32,579 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (198338 virtual)
2025-12-20 23:27:32,580 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (201418 virtual)
2025-12-20 23:27:32,581 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (205336 virtual)
2025-12-20 23:27:32,582 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (210865 virtual)
2025-12-20 23:27:32,583 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (215487 virtual)
2025-12-20 23:27:32,584 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (222784 virtual)
2025-12-20 23:27:32,585 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (227542 virtual)
2025-12-20 23:27:32,587 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (237105 virtual)
2025-12-20 23:27:32,587 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (242098 virtual)
2025-12-20 23:27:32,588 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (246462 virtual)
2025-12-20 23:27:32,589 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (250096 virtual)
2025-12-20 23:27:32,590 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (255323 virtual)
2025-12-20 23:27:32,591 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (258628 virtual)
2025-12-20 23:27:32,592 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (263349 virtual)
2025-12-20 23:27:32,593 INFO gensim.topic_coherence.text_analysis: 43 batches submitted to accumulate stats from 2752 documents (268233 virtual)
2025-12-20 23:27:32,594 INFO gensim.topic_coherence.text_analysis: 44 batches submitted to accumulate stats from 2816 documents (274132 virtual)
2025-12-20 23:27:32,595 INFO gensim.topic_coherence.text_analysis: 45 batches submitted to accumulate stats from 2880 documents (282971 virtual)
2025-12-20 23:27:32,596 INFO gensim.topic_coherence.text_analysis: 46 batches submitted to accumulate stats from 2944 documents (286673 virtual)
2025-12-20 23:27:32,597 INFO gensim.topic_coherence.text_analysis: 47 batches submitted to accumulate stats from 3008 documents (290264 virtual)
2025-12-20 23:27:32,598 INFO gensim.topic_coherence.text_analysis: 48 batches submitted to accumulate stats from 3072 documents (296037 virtual)
2025-12-20 23:27:32,600 INFO gensim.topic_coherence.text_analysis: 49 batches submitted to accumulate stats from 3136 documents (310124 virtual)
2025-12-20 23:27:32,601 INFO gensim.topic_coherence.text_analysis: 50 batches submitted to accumulate stats from 3200 documents (317050 virtual)
2025-12-20 23:27:32,602 INFO gensim.topic_coherence.text_analysis: 51 batches submitted to accumulate stats from 3264 documents (320598 virtual)
2025-12-20 23:27:32,604 INFO gensim.topic_coherence.text_analysis: 52 batches submitted to accumulate stats from 3328 documents (334909 virtual)
2025-12-20 23:27:32,605 INFO gensim.topic_coherence.text_analysis: 53 batches submitted to accumulate stats from 3392 documents (341683 virtual)
2025-12-20 23:27:32,606 INFO gensim.topic_coherence.text_analysis: 54 batches submitted to accumulate stats from 3456 documents (351624 virtual)
2025-12-20 23:27:32,608 INFO gensim.topic_coherence.text_analysis: 55 batches submitted to accumulate stats from 3520 documents (360719 virtual)
2025-12-20 23:27:32,609 INFO gensim.topic_coherence.text_analysis: 56 batches submitted to accumulate stats from 3584 documents (365651 virtual)
2025-12-20 23:27:32,610 INFO gensim.topic_coherence.text_analysis: 57 batches submitted to accumulate stats from 3648 documents (375582 virtual)
2025-12-20 23:27:32,615 INFO gensim.topic_coherence.text_analysis: 58 batches submitted to accumulate stats from 3712 documents (380043 virtual)
2025-12-20 23:27:32,646 INFO gensim.topic_coherence.text_analysis: 59 batches submitted to accumulate stats from 3776 documents (390262 virtual)
2025-12-20 23:27:32,647 INFO gensim.topic_coherence.text_analysis: 60 batches submitted to accumulate stats from 3840 documents (394060 virtual)
2025-12-20 23:27:32,647 INFO gensim.topic_coherence.text_analysis: 61 batches submitted to accumulate stats from 3904 documents (398804 virtual)
2025-12-20 23:27:32,666 INFO gensim.topic_coherence.text_analysis: 62 batches submitted to accumulate stats from 3968 documents (402970 virtual)
2025-12-20 23:27:32,668 INFO gensim.topic_coherence.text_analysis: 63 batches submitted to accumulate stats from 4032 documents (417617 virtual)
2025-12-20 23:27:32,669 INFO gensim.topic_coherence.text_analysis: 64 batches submitted to accumulate stats from 4096 documents (425918 virtual)
2025-12-20 23:27:32,671 INFO gensim.topic_coherence.text_analysis: 65 batches submitted to accumulate stats from 4160 documents (437460 virtual)
2025-12-20 23:27:32,686 INFO gensim.topic_coherence.text_analysis: 66 batches submitted to accumulate stats from 4224 documents (441365 virtual)
2025-12-20 23:27:32,694 INFO gensim.topic_coherence.text_analysis: 67 batches submitted to accumulate stats from 4288 documents (446589 virtual)
2025-12-20 23:27:32,694 INFO gensim.topic_coherence.text_analysis: 68 batches submitted to accumulate stats from 4352 documents (450244 virtual)
2025-12-20 23:27:32,698 INFO gensim.topic_coherence.text_analysis: 69 batches submitted to accumulate stats from 4416 documents (478452 virtual)
2025-12-20 23:27:32,706 INFO gensim.topic_coherence.text_analysis: 70 batches submitted to accumulate stats from 4480 documents (482978 virtual)
2025-12-20 23:27:32,718 INFO gensim.topic_coherence.text_analysis: 71 batches submitted to accumulate stats from 4544 documents (494166 virtual)
2025-12-20 23:27:32,722 INFO gensim.topic_coherence.text_analysis: 72 batches submitted to accumulate stats from 4608 documents (502241 virtual)
2025-12-20 23:27:32,730 INFO gensim.topic_coherence.text_analysis: 73 batches submitted to accumulate stats from 4672 documents (518522 virtual)
2025-12-20 23:27:32,734 INFO gensim.topic_coherence.text_analysis: 74 batches submitted to accumulate stats from 4736 documents (526287 virtual)
2025-12-20 23:27:32,742 INFO gensim.topic_coherence.text_analysis: 75 batches submitted to accumulate stats from 4800 documents (532913 virtual)
2025-12-20 23:27:32,754 INFO gensim.topic_coherence.text_analysis: 76 batches submitted to accumulate stats from 4864 documents (536619 virtual)
2025-12-20 23:27:32,822 INFO gensim.topic_coherence.text_analysis: 77 batches submitted to accumulate stats from 4928 documents (548493 virtual)
2025-12-20 23:27:32,830 INFO gensim.topic_coherence.text_analysis: 78 batches submitted to accumulate stats from 4992 documents (551958 virtual)
2025-12-20 23:27:32,854 INFO gensim.topic_coherence.text_analysis: 79 batches submitted to accumulate stats from 5056 documents (555379 virtual)
2025-12-20 23:27:32,867 INFO gensim.topic_coherence.text_analysis: 80 batches submitted to accumulate stats from 5120 documents (564992 virtual)
2025-12-20 23:27:32,879 INFO gensim.topic_coherence.text_analysis: 81 batches submitted to accumulate stats from 5184 documents (568990 virtual)
2025-12-20 23:27:32,880 INFO gensim.topic_coherence.text_analysis: 82 batches submitted to accumulate stats from 5248 documents (574796 virtual)
2025-12-20 23:27:32,881 INFO gensim.topic_coherence.text_analysis: 83 batches submitted to accumulate stats from 5312 documents (581815 virtual)
2025-12-20 23:27:32,902 INFO gensim.topic_coherence.text_analysis: 84 batches submitted to accumulate stats from 5376 documents (585873 virtual)
2025-12-20 23:27:32,904 INFO gensim.topic_coherence.text_analysis: 85 batches submitted to accumulate stats from 5440 documents (591771 virtual)
2025-12-20 23:27:32,915 INFO gensim.topic_coherence.text_analysis: 86 batches submitted to accumulate stats from 5504 documents (597046 virtual)
2025-12-20 23:27:32,916 INFO gensim.topic_coherence.text_analysis: 87 batches submitted to accumulate stats from 5568 documents (601849 virtual)
2025-12-20 23:27:32,939 INFO gensim.topic_coherence.text_analysis: 88 batches submitted to accumulate stats from 5632 documents (608725 virtual)
2025-12-20 23:27:32,940 INFO gensim.topic_coherence.text_analysis: 89 batches submitted to accumulate stats from 5696 documents (615021 virtual)
2025-12-20 23:27:32,947 INFO gensim.topic_coherence.text_analysis: 90 batches submitted to accumulate stats from 5760 documents (621265 virtual)
2025-12-20 23:27:32,948 INFO gensim.topic_coherence.text_analysis: 91 batches submitted to accumulate stats from 5824 documents (627724 virtual)
2025-12-20 23:27:32,974 INFO gensim.topic_coherence.text_analysis: 92 batches submitted to accumulate stats from 5888 documents (631679 virtual)
2025-12-20 23:27:32,975 INFO gensim.topic_coherence.text_analysis: 93 batches submitted to accumulate stats from 5952 documents (635736 virtual)
2025-12-20 23:27:32,976 INFO gensim.topic_coherence.text_analysis: 94 batches submitted to accumulate stats from 6016 documents (643713 virtual)
2025-12-20 23:27:32,987 INFO gensim.topic_coherence.text_analysis: 95 batches submitted to accumulate stats from 6080 documents (649874 virtual)
2025-12-20 23:27:33,007 INFO gensim.topic_coherence.text_analysis: 96 batches submitted to accumulate stats from 6144 documents (658090 virtual)
2025-12-20 23:27:33,007 INFO gensim.topic_coherence.text_analysis: 97 batches submitted to accumulate stats from 6208 documents (661695 virtual)
2025-12-20 23:27:33,009 INFO gensim.topic_coherence.text_analysis: 98 batches submitted to accumulate stats from 6272 documents (669808 virtual)
2025-12-20 23:27:33,014 INFO gensim.topic_coherence.text_analysis: 99 batches submitted to accumulate stats from 6336 documents (673686 virtual)
2025-12-20 23:27:33,023 INFO gensim.topic_coherence.text_analysis: 100 batches submitted to accumulate stats from 6400 documents (678673 virtual)
2025-12-20 23:27:33,027 INFO gensim.topic_coherence.text_analysis: 101 batches submitted to accumulate stats from 6464 documents (683677 virtual)
2025-12-20 23:27:33,027 INFO gensim.topic_coherence.text_analysis: 102 batches submitted to accumulate stats from 6528 documents (687618 virtual)
2025-12-20 23:27:33,029 INFO gensim.topic_coherence.text_analysis: 103 batches submitted to accumulate stats from 6592 documents (698272 virtual)
2025-12-20 23:27:33,103 INFO gensim.topic_coherence.text_analysis: 104 batches submitted to accumulate stats from 6656 documents (703739 virtual)
2025-12-20 23:27:33,123 INFO gensim.topic_coherence.text_analysis: 105 batches submitted to accumulate stats from 6720 documents (712044 virtual)
2025-12-20 23:27:33,124 INFO gensim.topic_coherence.text_analysis: 106 batches submitted to accumulate stats from 6784 documents (719942 virtual)
2025-12-20 23:27:33,139 INFO gensim.topic_coherence.text_analysis: 107 batches submitted to accumulate stats from 6848 documents (730593 virtual)
2025-12-20 23:27:33,167 INFO gensim.topic_coherence.text_analysis: 108 batches submitted to accumulate stats from 6912 documents (738698 virtual)
2025-12-20 23:27:33,168 INFO gensim.topic_coherence.text_analysis: 109 batches submitted to accumulate stats from 6976 documents (744918 virtual)
2025-12-20 23:27:33,182 INFO gensim.topic_coherence.text_analysis: 110 batches submitted to accumulate stats from 7040 documents (748587 virtual)
2025-12-20 23:27:33,191 INFO gensim.topic_coherence.text_analysis: 111 batches submitted to accumulate stats from 7104 documents (754283 virtual)
2025-12-20 23:27:33,219 INFO gensim.topic_coherence.text_analysis: 112 batches submitted to accumulate stats from 7168 documents (759411 virtual)
2025-12-20 23:27:33,219 INFO gensim.topic_coherence.text_analysis: 113 batches submitted to accumulate stats from 7232 documents (763074 virtual)
2025-12-20 23:27:33,227 INFO gensim.topic_coherence.text_analysis: 114 batches submitted to accumulate stats from 7296 documents (769146 virtual)
2025-12-20 23:27:33,228 INFO gensim.topic_coherence.text_analysis: 115 batches submitted to accumulate stats from 7360 documents (778550 virtual)
2025-12-20 23:27:33,229 INFO gensim.topic_coherence.text_analysis: 116 batches submitted to accumulate stats from 7424 documents (782687 virtual)
2025-12-20 23:27:33,229 INFO gensim.topic_coherence.text_analysis: 117 batches submitted to accumulate stats from 7488 documents (787370 virtual)
2025-12-20 23:27:33,257 INFO gensim.topic_coherence.text_analysis: 118 batches submitted to accumulate stats from 7552 documents (792747 virtual)
2025-12-20 23:27:33,258 INFO gensim.topic_coherence.text_analysis: 119 batches submitted to accumulate stats from 7616 documents (795834 virtual)
2025-12-20 23:27:33,259 INFO gensim.topic_coherence.text_analysis: 120 batches submitted to accumulate stats from 7680 documents (799472 virtual)
2025-12-20 23:27:33,260 INFO gensim.topic_coherence.text_analysis: 121 batches submitted to accumulate stats from 7744 documents (804251 virtual)
2025-12-20 23:27:33,261 INFO gensim.topic_coherence.text_analysis: 122 batches submitted to accumulate stats from 7808 documents (818289 virtual)
2025-12-20 23:27:33,311 INFO gensim.topic_coherence.text_analysis: 123 batches submitted to accumulate stats from 7872 documents (823742 virtual)
2025-12-20 23:27:33,322 INFO gensim.topic_coherence.text_analysis: 124 batches submitted to accumulate stats from 7936 documents (829121 virtual)
2025-12-20 23:27:33,327 INFO gensim.topic_coherence.text_analysis: 125 batches submitted to accumulate stats from 8000 documents (839918 virtual)
2025-12-20 23:27:33,350 INFO gensim.topic_coherence.text_analysis: 126 batches submitted to accumulate stats from 8064 documents (843357 virtual)
2025-12-20 23:27:33,351 INFO gensim.topic_coherence.text_analysis: 127 batches submitted to accumulate stats from 8128 documents (847194 virtual)
2025-12-20 23:27:33,366 INFO gensim.topic_coherence.text_analysis: 128 batches submitted to accumulate stats from 8192 documents (850480 virtual)
2025-12-20 23:27:33,374 INFO gensim.topic_coherence.text_analysis: 129 batches submitted to accumulate stats from 8256 documents (854672 virtual)
2025-12-20 23:27:33,376 INFO gensim.topic_coherence.text_analysis: 130 batches submitted to accumulate stats from 8320 documents (863027 virtual)
2025-12-20 23:27:33,382 INFO gensim.topic_coherence.text_analysis: 131 batches submitted to accumulate stats from 8384 documents (865772 virtual)
2025-12-20 23:27:33,388 INFO gensim.topic_coherence.text_analysis: 132 batches submitted to accumulate stats from 8448 documents (884808 virtual)
2025-12-20 23:27:33,410 INFO gensim.topic_coherence.text_analysis: 133 batches submitted to accumulate stats from 8512 documents (889004 virtual)
2025-12-20 23:27:33,419 INFO gensim.topic_coherence.text_analysis: 134 batches submitted to accumulate stats from 8576 documents (894985 virtual)
2025-12-20 23:27:33,419 INFO gensim.topic_coherence.text_analysis: 135 batches submitted to accumulate stats from 8640 documents (898703 virtual)
2025-12-20 23:27:33,438 INFO gensim.topic_coherence.text_analysis: 136 batches submitted to accumulate stats from 8704 documents (901982 virtual)
2025-12-20 23:27:33,447 INFO gensim.topic_coherence.text_analysis: 137 batches submitted to accumulate stats from 8768 documents (906587 virtual)
2025-12-20 23:27:33,454 INFO gensim.topic_coherence.text_analysis: 138 batches submitted to accumulate stats from 8832 documents (910463 virtual)
2025-12-20 23:27:33,461 INFO gensim.topic_coherence.text_analysis: 139 batches submitted to accumulate stats from 8896 documents (931102 virtual)
2025-12-20 23:27:33,491 INFO gensim.topic_coherence.text_analysis: 140 batches submitted to accumulate stats from 8960 documents (942622 virtual)
2025-12-20 23:27:33,507 INFO gensim.topic_coherence.text_analysis: 141 batches submitted to accumulate stats from 9024 documents (951129 virtual)
2025-12-20 23:27:33,522 INFO gensim.topic_coherence.text_analysis: 142 batches submitted to accumulate stats from 9088 documents (955276 virtual)
2025-12-20 23:27:33,530 INFO gensim.topic_coherence.text_analysis: 143 batches submitted to accumulate stats from 9152 documents (959539 virtual)
2025-12-20 23:27:33,535 INFO gensim.topic_coherence.text_analysis: 144 batches submitted to accumulate stats from 9216 documents (965946 virtual)
2025-12-20 23:27:33,542 INFO gensim.topic_coherence.text_analysis: 145 batches submitted to accumulate stats from 9280 documents (970853 virtual)
2025-12-20 23:27:33,546 INFO gensim.topic_coherence.text_analysis: 146 batches submitted to accumulate stats from 9344 documents (973829 virtual)
2025-12-20 23:27:33,564 INFO gensim.topic_coherence.text_analysis: 147 batches submitted to accumulate stats from 9408 documents (989097 virtual)
2025-12-20 23:27:33,575 INFO gensim.topic_coherence.text_analysis: 148 batches submitted to accumulate stats from 9472 documents (994234 virtual)
2025-12-20 23:27:33,586 INFO gensim.topic_coherence.text_analysis: 149 batches submitted to accumulate stats from 9536 documents (997762 virtual)
2025-12-20 23:27:33,587 INFO gensim.topic_coherence.text_analysis: 150 batches submitted to accumulate stats from 9600 documents (1000793 virtual)
2025-12-20 23:27:33,603 INFO gensim.topic_coherence.text_analysis: 151 batches submitted to accumulate stats from 9664 documents (1006413 virtual)
2025-12-20 23:27:33,614 INFO gensim.topic_coherence.text_analysis: 152 batches submitted to accumulate stats from 9728 documents (1011923 virtual)
2025-12-20 23:27:33,626 INFO gensim.topic_coherence.text_analysis: 153 batches submitted to accumulate stats from 9792 documents (1014946 virtual)
2025-12-20 23:27:33,634 INFO gensim.topic_coherence.text_analysis: 154 batches submitted to accumulate stats from 9856 documents (1018740 virtual)
2025-12-20 23:27:33,638 INFO gensim.topic_coherence.text_analysis: 155 batches submitted to accumulate stats from 9920 documents (1022376 virtual)
2025-12-20 23:27:33,646 INFO gensim.topic_coherence.text_analysis: 156 batches submitted to accumulate stats from 9984 documents (1026825 virtual)
2025-12-20 23:27:33,648 INFO gensim.topic_coherence.text_analysis: 157 batches submitted to accumulate stats from 10048 documents (1040358 virtual)
2025-12-20 23:27:33,666 INFO gensim.topic_coherence.text_analysis: 158 batches submitted to accumulate stats from 10112 documents (1044737 virtual)
2025-12-20 23:27:33,679 INFO gensim.topic_coherence.text_analysis: 159 batches submitted to accumulate stats from 10176 documents (1050861 virtual)
2025-12-20 23:27:33,687 INFO gensim.topic_coherence.text_analysis: 160 batches submitted to accumulate stats from 10240 documents (1056370 virtual)
2025-12-20 23:27:33,687 INFO gensim.topic_coherence.text_analysis: 161 batches submitted to accumulate stats from 10304 documents (1062228 virtual)
2025-12-20 23:27:33,695 INFO gensim.topic_coherence.text_analysis: 162 batches submitted to accumulate stats from 10368 documents (1074392 virtual)
2025-12-20 23:27:33,722 INFO gensim.topic_coherence.text_analysis: 163 batches submitted to accumulate stats from 10432 documents (1078963 virtual)
2025-12-20 23:27:33,734 INFO gensim.topic_coherence.text_analysis: 164 batches submitted to accumulate stats from 10496 documents (1082443 virtual)
2025-12-20 23:27:33,735 INFO gensim.topic_coherence.text_analysis: 165 batches submitted to accumulate stats from 10560 documents (1088508 virtual)
2025-12-20 23:27:33,736 INFO gensim.topic_coherence.text_analysis: 166 batches submitted to accumulate stats from 10624 documents (1093083 virtual)
2025-12-20 23:27:33,750 INFO gensim.topic_coherence.text_analysis: 167 batches submitted to accumulate stats from 10688 documents (1096984 virtual)
2025-12-20 23:27:33,762 INFO gensim.topic_coherence.text_analysis: 168 batches submitted to accumulate stats from 10752 documents (1101614 virtual)
2025-12-20 23:27:33,790 INFO gensim.topic_coherence.text_analysis: 169 batches submitted to accumulate stats from 10816 documents (1105041 virtual)
2025-12-20 23:27:33,791 INFO gensim.topic_coherence.text_analysis: 170 batches submitted to accumulate stats from 10880 documents (1112474 virtual)
2025-12-20 23:27:33,803 INFO gensim.topic_coherence.text_analysis: 171 batches submitted to accumulate stats from 10944 documents (1119161 virtual)
2025-12-20 23:27:33,818 INFO gensim.topic_coherence.text_analysis: 172 batches submitted to accumulate stats from 11008 documents (1123702 virtual)
2025-12-20 23:27:33,826 INFO gensim.topic_coherence.text_analysis: 173 batches submitted to accumulate stats from 11072 documents (1123966 virtual)
2025-12-20 23:27:34,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,141 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,146 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,146 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,162 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,192 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,226 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,272 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,334 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,362 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,366 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,381 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,406 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,518 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,553 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,770 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:34,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:34,886 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:35,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-20 23:27:35,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-20 23:27:38,308 INFO gensim.topic_coherence.text_analysis: 47 accumulators retrieved from output queue
2025-12-20 23:27:38,367 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1127780 virtual documents
2025-12-20 23:27:39,126 INFO __main__: Model 0 (HDBSCAN) metrics: {'coherence_c_v': 0.6193012383626985, 'coherence_npmi': -0.015790994243445933, 'topic_diversity': 1.0, 'inter_topic_similarity': 0.45833754539489746}
2025-12-20 23:27:39,127 INFO __main__: Model 1 (KMeans) metrics: {'coherence_c_v': 0.7018510670427864, 'coherence_npmi': 0.11611213567384626, 'topic_diversity': 0.798, 'inter_topic_similarity': 0.29080572724342346}
2025-12-20 23:27:39,127 INFO __main__: Model 2 (BERTopicCobwebWrapper) metrics: {'coherence_c_v': 0.7227749143812358, 'coherence_npmi': 0.13322698971772978, 'topic_diversity': 0.8156862745098039, 'inter_topic_similarity': 0.287833034992218}
