2025-12-23 08:53:45,115 INFO __main__: Starting incremental benchmark for dataset=stackexchange
2025-12-23 08:54:27,229 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:27,478 INFO gensim.corpora.dictionary: built Dictionary<43658 unique tokens: ['01', '10', '1047', '11', '116']...> from 5000 documents (total 604501 corpus positions)
2025-12-23 08:54:27,485 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<43658 unique tokens: ['01', '10', '1047', '11', '116']...> from 5000 documents (total 604501 corpus positions)", 'datetime': '2025-12-23T08:54:27.478630', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:28,417 INFO sentence_transformers.SentenceTransformer: Use pytorch device_name: cuda:0
2025-12-23 08:54:28,418 INFO sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: all-roberta-large-v1
2025-12-23 08:54:31,208 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:54:47,005 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:47,029 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:54:47,029 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:54:47.029798', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:47,030 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:48,971 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:54:48,973 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:54:48,974 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:54:48,976 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:54:48,979 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2315 virtual)
2025-12-23 08:54:49,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,024 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,040 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,044 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,044 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,053 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,057 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,058 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,066 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,073 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,225 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,236 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:50,092 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:50,130 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 21132 virtual documents
2025-12-23 08:54:50,229 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:50,254 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:54:50,254 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:54:50.254130', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:50,255 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:52,509 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:54:52,511 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:54:52,513 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:54:52,515 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:54:52,517 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:54:52,520 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:54:52,521 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:54:52,523 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (52315 virtual)
2025-12-23 08:54:52,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,621 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,626 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,649 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,661 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,709 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,924 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,863 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:53,914 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 52322 virtual documents
2025-12-23 08:54:54,005 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:54,029 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:54:54,029 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:54:54.029648', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:58,668 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:55:03,573 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:03,643 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:03,643 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:03.643543', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:03,644 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:05,530 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:55:05,532 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:55:05,534 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:55:05,535 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:55:05,539 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2315 virtual)
2025-12-23 08:55:05,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,656 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:05,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:05,885 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:06,724 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:06,778 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 21132 virtual documents
2025-12-23 08:55:06,913 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:06,936 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:06,937 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:06.937002', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:06,938 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:08,839 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:55:08,841 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:55:08,843 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:55:08,846 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:55:08,848 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:55:08,850 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:55:08,852 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:55:08,854 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (52315 virtual)
2025-12-23 08:55:08,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,925 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,930 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,933 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,933 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,946 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,950 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,965 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,970 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:08,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,202 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:09,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:09,321 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,114 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:10,142 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 52322 virtual documents
2025-12-23 08:55:10,253 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:10,278 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:10,278 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:10.278689', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:14,940 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
Training CobwebTree:   0%|          | 0/500 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 19/500 [00:00<00:02, 179.64it/s]Training CobwebTree:   7%|         | 37/500 [00:00<00:04, 114.69it/s]Training CobwebTree:  10%|         | 50/500 [00:00<00:04, 103.14it/s]Training CobwebTree:  12%|        | 61/500 [00:00<00:04, 101.22it/s]Training CobwebTree:  14%|        | 72/500 [00:00<00:04, 93.63it/s] Training CobwebTree:  16%|        | 82/500 [00:00<00:04, 83.62it/s]Training CobwebTree:  18%|        | 91/500 [00:00<00:05, 81.11it/s]Training CobwebTree:  20%|        | 100/500 [00:01<00:05, 79.84it/s]Training CobwebTree:  22%|       | 109/500 [00:01<00:05, 78.05it/s]Training CobwebTree:  23%|       | 117/500 [00:01<00:05, 75.15it/s]Training CobwebTree:  25%|       | 125/500 [00:01<00:05, 74.29it/s]Training CobwebTree:  27%|       | 133/500 [00:01<00:05, 72.71it/s]Training CobwebTree:  28%|       | 141/500 [00:01<00:05, 69.65it/s]Training CobwebTree:  30%|       | 148/500 [00:01<00:05, 68.58it/s]Training CobwebTree:  31%|       | 156/500 [00:01<00:04, 69.28it/s]Training CobwebTree:  33%|      | 164/500 [00:02<00:04, 68.45it/s]Training CobwebTree:  34%|      | 172/500 [00:02<00:04, 69.14it/s]Training CobwebTree:  36%|      | 179/500 [00:02<00:04, 66.02it/s]Training CobwebTree:  37%|      | 187/500 [00:02<00:04, 69.61it/s]Training CobwebTree:  39%|      | 195/500 [00:02<00:04, 67.89it/s]Training CobwebTree:  41%|      | 203/500 [00:02<00:04, 70.02it/s]Training CobwebTree:  42%|     | 211/500 [00:02<00:04, 67.70it/s]Training CobwebTree:  44%|     | 218/500 [00:02<00:04, 65.62it/s]Training CobwebTree:  45%|     | 225/500 [00:02<00:04, 62.77it/s]Training CobwebTree:  46%|     | 232/500 [00:03<00:04, 63.18it/s]Training CobwebTree:  48%|     | 239/500 [00:03<00:04, 63.88it/s]Training CobwebTree:  49%|     | 246/500 [00:03<00:04, 61.54it/s]Training CobwebTree:  51%|     | 253/500 [00:03<00:04, 57.80it/s]Training CobwebTree:  52%|    | 259/500 [00:03<00:04, 57.90it/s]Training CobwebTree:  53%|    | 265/500 [00:03<00:04, 58.11it/s]Training CobwebTree:  54%|    | 272/500 [00:03<00:03, 59.49it/s]Training CobwebTree:  56%|    | 278/500 [00:03<00:03, 59.39it/s]Training CobwebTree:  57%|    | 285/500 [00:03<00:03, 59.97it/s]Training CobwebTree:  59%|    | 293/500 [00:04<00:03, 63.06it/s]Training CobwebTree:  60%|    | 300/500 [00:04<00:03, 62.39it/s]Training CobwebTree:  61%|   | 307/500 [00:04<00:03, 61.96it/s]Training CobwebTree:  63%|   | 314/500 [00:04<00:02, 62.02it/s]Training CobwebTree:  64%|   | 321/500 [00:04<00:02, 61.90it/s]Training CobwebTree:  66%|   | 328/500 [00:04<00:02, 60.37it/s]Training CobwebTree:  67%|   | 335/500 [00:04<00:02, 59.92it/s]Training CobwebTree:  68%|   | 342/500 [00:04<00:02, 61.66it/s]Training CobwebTree:  70%|   | 349/500 [00:05<00:02, 58.43it/s]Training CobwebTree:  71%|   | 356/500 [00:05<00:02, 59.74it/s]Training CobwebTree:  73%|  | 363/500 [00:05<00:02, 60.26it/s]Training CobwebTree:  74%|  | 370/500 [00:05<00:02, 59.14it/s]Training CobwebTree:  75%|  | 376/500 [00:05<00:02, 57.16it/s]Training CobwebTree:  77%|  | 383/500 [00:05<00:02, 58.46it/s]Training CobwebTree:  78%|  | 390/500 [00:05<00:01, 60.30it/s]Training CobwebTree:  79%|  | 397/500 [00:05<00:01, 59.78it/s]Training CobwebTree:  81%|  | 403/500 [00:05<00:01, 54.99it/s]Training CobwebTree:  82%| | 410/500 [00:06<00:01, 57.16it/s]Training CobwebTree:  83%| | 417/500 [00:06<00:01, 58.76it/s]Training CobwebTree:  85%| | 423/500 [00:06<00:01, 58.68it/s]Training CobwebTree:  86%| | 429/500 [00:06<00:01, 56.46it/s]Training CobwebTree:  87%| | 435/500 [00:06<00:01, 55.89it/s]Training CobwebTree:  88%| | 441/500 [00:06<00:01, 55.43it/s]Training CobwebTree:  89%| | 447/500 [00:06<00:00, 54.57it/s]Training CobwebTree:  91%| | 453/500 [00:06<00:00, 55.11it/s]Training CobwebTree:  92%|| 459/500 [00:06<00:00, 55.31it/s]Training CobwebTree:  93%|| 465/500 [00:07<00:00, 53.90it/s]Training CobwebTree:  94%|| 471/500 [00:07<00:00, 53.33it/s]Training CobwebTree:  95%|| 477/500 [00:07<00:00, 51.63it/s]Training CobwebTree:  97%|| 483/500 [00:07<00:00, 50.30it/s]Training CobwebTree:  98%|| 489/500 [00:07<00:00, 50.30it/s]Training CobwebTree:  99%|| 495/500 [00:07<00:00, 50.52it/s]Training CobwebTree: 100%|| 500/500 [00:07<00:00, 64.49it/s]
2025-12-23 08:55:27,630 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:27,655 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:27,655 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:27.655326', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:27,656 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:29,567 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:55:29,569 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:55:29,571 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:55:29,573 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:55:29,577 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2315 virtual)
2025-12-23 08:55:29,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,644 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,705 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,924 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,933 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,934 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:29,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:29,988 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,016 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,824 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:30,866 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 21132 virtual documents
2025-12-23 08:55:31,083 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:31,107 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:31,107 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:31.107422', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:31,109 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:33,170 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:55:33,172 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:55:33,174 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:55:33,178 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:55:33,180 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:55:33,182 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:55:33,184 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:55:33,186 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (52315 virtual)
2025-12-23 08:55:33,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,281 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,289 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:33,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:33,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,834 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:34,870 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 52322 virtual documents
2025-12-23 08:55:35,030 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:35,054 INFO gensim.corpora.dictionary: built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)
2025-12-23 08:55:35,054 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8245 unique tokens: ['01', '10', '1047', '11', '116']...> from 500 documents (total 56815 corpus positions)", 'datetime': '2025-12-23T08:55:35.054474', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:39,735 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:44,236 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:44,266 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:55:44,266 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:55:44.266150', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:44,267 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:46,253 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:55:46,256 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:55:46,258 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:55:46,260 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:55:46,264 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:55:46,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,397 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,584 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:46,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:46,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,540 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:47,598 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 25422 virtual documents
2025-12-23 08:55:47,717 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:47,747 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:55:47,747 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:55:47.747367', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:47,748 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:49,834 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:55:49,836 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:55:49,838 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:55:49,839 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:55:49,841 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:55:49,843 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:55:49,845 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:55:49,847 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:55:49,849 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:55:49,850 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63957 virtual)
2025-12-23 08:55:49,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:49,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,950 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,977 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,192 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,265 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:51,306 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:51,342 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 63964 virtual documents
2025-12-23 08:55:51,432 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:51,462 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:55:51,462 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:55:51.462104', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:58,331 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:59,970 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:00,001 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:00,001 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:00.001423', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:00,002 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:02,080 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:56:02,082 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:56:02,084 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:56:02,085 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:56:02,089 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:56:02,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,202 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,214 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,222 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,224 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,469 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,496 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:03,440 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:03,506 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 25422 virtual documents
2025-12-23 08:56:03,655 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:03,685 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:03,685 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:03.685711', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:03,687 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:05,677 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:56:05,679 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:56:05,681 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:56:05,682 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:56:05,683 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:56:05,684 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:56:05,685 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:56:05,687 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:56:05,688 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:56:05,689 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63957 virtual)
2025-12-23 08:56:05,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,780 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,817 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,165 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:06,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,238 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:07,426 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:07,471 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 63964 virtual documents
2025-12-23 08:56:07,577 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:07,610 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:07,610 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:07.610905', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:14,510 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   6%|         | 7/125 [00:00<00:01, 62.42it/s]Training CobwebTree:  11%|         | 14/125 [00:00<00:01, 62.72it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:01, 61.71it/s]Training CobwebTree:  22%|       | 28/125 [00:00<00:01, 61.25it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 60.12it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 59.52it/s]Training CobwebTree:  38%|      | 48/125 [00:00<00:01, 58.23it/s]Training CobwebTree:  44%|     | 55/125 [00:00<00:01, 58.64it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 58.51it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:00, 57.44it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:00, 54.75it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:00, 53.84it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 51.21it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 52.71it/s]Training CobwebTree:  78%|  | 98/125 [00:01<00:00, 53.04it/s]Training CobwebTree:  83%| | 104/125 [00:01<00:00, 52.03it/s]Training CobwebTree:  88%| | 110/125 [00:01<00:00, 53.60it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 54.57it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 55.42it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 56.02it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:18,391 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:18,420 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:18,420 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:18.420959', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:18,422 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:20,429 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:56:20,431 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:56:20,434 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:56:20,436 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:56:20,440 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:56:20,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,549 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:20,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:20,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:21,057 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:21,822 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:21,865 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 25422 virtual documents
2025-12-23 08:56:22,105 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:22,135 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:22,135 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:22.135198', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:22,137 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:24,305 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:56:24,308 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:56:24,309 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:56:24,311 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:56:24,313 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:56:24,316 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:56:24,318 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:56:24,320 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:56:24,322 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:56:24,324 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (63957 virtual)
2025-12-23 08:56:24,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,893 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:25,837 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:25,899 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 63964 virtual documents
2025-12-23 08:56:26,056 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:26,086 INFO gensim.corpora.dictionary: built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)
2025-12-23 08:56:26,086 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9780 unique tokens: ['01', '10', '1047', '11', '116']...> from 625 documents (total 69582 corpus positions)", 'datetime': '2025-12-23T08:56:26.086255', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:32,998 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:35,070 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:35,106 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:56:35,106 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:56:35.106457', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:35,107 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:37,123 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:56:37,125 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:56:37,127 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:56:37,128 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:56:37,132 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:56:37,138 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:56:37,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,248 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,265 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,537 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:38,564 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30479 virtual documents
2025-12-23 08:56:38,688 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:38,724 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:56:38,724 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:56:38.724425', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:38,725 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:40,784 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:56:40,786 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:56:40,787 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:56:40,789 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:56:40,791 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:56:40,793 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:56:40,794 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:56:40,797 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:56:40,799 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:56:40,801 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:56:40,803 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:56:40,804 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (77133 virtual)
2025-12-23 08:56:40,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,908 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,082 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,224 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:41,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,288 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:42,328 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 77140 virtual documents
2025-12-23 08:56:42,421 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:42,459 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:56:42,459 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:56:42.459143', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:50,795 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:52,460 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:52,497 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:56:52,497 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:56:52.497779', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:52,499 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:54,599 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:56:54,600 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:56:54,602 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:56:54,604 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:56:54,608 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:56:54,614 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:56:54,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,736 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,817 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:54,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:55,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:55,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:55,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:55,033 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:55,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:55,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:55,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:55,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:55,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,399 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:56,449 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30479 virtual documents
2025-12-23 08:56:56,601 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:56,637 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:56:56,637 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:56:56.637925', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:56,639 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:58,697 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:56:58,699 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:56:58,701 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:56:58,704 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:56:58,706 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:56:58,708 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:56:58,710 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:56:58,712 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:56:58,714 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:56:58,716 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:56:58,718 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:56:58,720 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (77133 virtual)
2025-12-23 08:56:58,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:58,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,196 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,198 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,208 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,246 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:59,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:59,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,198 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:00,267 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 77140 virtual documents
2025-12-23 08:57:00,380 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:00,416 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:57:00,416 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:57:00.416494', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:08,792 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 52.43it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 55.41it/s]Training CobwebTree:  15%|        | 19/125 [00:00<00:01, 58.81it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:01, 58.00it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:01, 55.87it/s]Training CobwebTree:  30%|       | 38/125 [00:00<00:01, 57.49it/s]Training CobwebTree:  35%|      | 44/125 [00:00<00:01, 56.68it/s]Training CobwebTree:  40%|      | 50/125 [00:00<00:01, 54.92it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 53.55it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 53.58it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 51.94it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:01, 46.96it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 50.85it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 50.55it/s]Training CobwebTree:  74%|  | 93/125 [00:01<00:00, 51.88it/s]Training CobwebTree:  79%|  | 99/125 [00:01<00:00, 50.64it/s]Training CobwebTree:  84%| | 105/125 [00:01<00:00, 51.48it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 52.36it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 52.32it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 53.26it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 53.05it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:12,925 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:12,961 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:57:12,961 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:57:12.961236', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:12,963 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:14,991 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:57:14,993 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:57:14,996 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:57:14,998 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:57:15,002 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:57:15,008 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:57:15,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,149 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,153 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,153 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,158 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,158 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,467 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,669 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:16,691 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:16,746 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30479 virtual documents
2025-12-23 08:57:17,106 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:17,142 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:57:17,142 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:57:17.142496', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:17,145 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:19,558 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:57:19,563 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:57:19,566 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:57:19,568 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:57:19,570 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:57:19,573 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:57:19,577 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:57:19,579 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:57:19,582 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:57:19,583 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (77133 virtual)
2025-12-23 08:57:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,985 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,209 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:20,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,335 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:21,397 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 77140 virtual documents
2025-12-23 08:57:21,645 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:21,682 INFO gensim.corpora.dictionary: built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)
2025-12-23 08:57:21,682 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11110 unique tokens: ['01', '10', '1047', '11', '116']...> from 750 documents (total 83883 corpus positions)", 'datetime': '2025-12-23T08:57:21.682634', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:30,060 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:32,162 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:32,209 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:32,209 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:32.209649', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:32,210 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:34,326 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:57:34,329 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:57:34,331 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:57:34,333 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:57:34,337 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:57:34,343 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:57:34,345 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:57:34,348 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:57:34,350 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7552 virtual)
2025-12-23 08:57:34,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,766 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,797 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,896 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:35,872 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:35,901 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 39854 virtual documents
2025-12-23 08:57:36,051 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:36,095 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:36,095 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:36.095351', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:36,096 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:38,218 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:57:38,220 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:57:38,223 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:57:38,225 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:57:38,227 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:57:38,230 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:57:38,231 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:57:38,234 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:57:38,236 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:57:38,238 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:57:38,240 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:57:38,242 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:57:38,245 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:57:38,247 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (95052 virtual)
2025-12-23 08:57:38,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,344 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,344 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,401 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,406 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,813 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,813 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:38,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:38,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:39,871 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:39,915 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 95059 virtual documents
2025-12-23 08:57:40,020 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:40,063 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:40,064 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:40.063964', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:49,840 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:51,543 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:51,585 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:51,585 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:51.585905', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:51,587 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:53,620 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:57:53,622 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:57:53,624 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:57:53,626 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:57:53,630 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:57:53,636 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:57:53,638 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:57:53,641 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:57:53,643 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7552 virtual)
2025-12-23 08:57:53,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,696 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:53,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:53,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:54,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,184 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:54,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:55,198 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:55,230 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 39854 virtual documents
2025-12-23 08:57:55,392 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:55,435 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:55,435 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:55.435553', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:55,437 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:57,519 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:57:57,522 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:57:57,524 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:57:57,525 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:57:57,527 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:57:57,529 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:57:57,531 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:57:57,533 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:57:57,535 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:57:57,537 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:57:57,540 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:57:57,542 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:57:57,545 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:57:57,547 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (95052 virtual)
2025-12-23 08:57:57,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,670 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,685 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,020 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,057 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,137 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:58,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:58,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:59,197 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:59,242 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 95059 virtual documents
2025-12-23 08:57:59,358 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:59,401 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:57:59,401 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:57:59.401351', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:09,252 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 49.61it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 53.01it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 48.51it/s]Training CobwebTree:  18%|        | 23/125 [00:00<00:02, 46.85it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 53.06it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 54.09it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 53.96it/s]Training CobwebTree:  38%|      | 48/125 [00:00<00:01, 55.02it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 55.65it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 51.78it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 50.22it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 49.25it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:00, 50.75it/s]Training CobwebTree:  67%|   | 84/125 [00:01<00:00, 49.82it/s]Training CobwebTree:  72%|  | 90/125 [00:01<00:00, 49.28it/s]Training CobwebTree:  76%|  | 95/125 [00:01<00:00, 48.69it/s]Training CobwebTree:  81%|  | 101/125 [00:01<00:00, 50.81it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 49.33it/s]Training CobwebTree:  90%| | 113/125 [00:02<00:00, 51.47it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 50.33it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 50.83it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 51.00it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:13,523 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:13,570 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:58:13,570 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:58:13.570215', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:13,572 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:16,054 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:58:16,056 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:58:16,059 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:58:16,061 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:58:16,065 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:58:16,071 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:58:16,073 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:58:16,076 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:58:16,078 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7552 virtual)
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,505 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:17,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:17,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:17,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:17,937 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:18,206 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:18,273 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 39854 virtual documents
2025-12-23 08:58:18,639 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:18,682 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:58:18,682 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:58:18.682238', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:18,685 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:20,789 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:58:20,791 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:58:20,793 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:58:20,795 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:58:20,797 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:58:20,799 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:58:20,801 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:58:20,804 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:58:20,806 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:58:20,808 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:58:20,810 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:58:20,813 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:58:20,816 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:58:20,818 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (95052 virtual)
2025-12-23 08:58:20,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,549 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,586 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:21,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:22,605 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:22,663 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 95059 virtual documents
2025-12-23 08:58:22,915 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:22,959 INFO gensim.corpora.dictionary: built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)
2025-12-23 08:58:22,959 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12587 unique tokens: ['01', '10', '1047', '11', '116']...> from 875 documents (total 102927 corpus positions)", 'datetime': '2025-12-23T08:58:22.959679', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:32,817 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:34,932 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:34,981 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:58:34,981 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:58:34.981569', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:34,983 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:37,394 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:58:37,396 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:58:37,399 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:58:37,401 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:58:37,405 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:58:37,411 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:58:37,413 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:58:37,416 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:58:37,419 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 08:58:37,421 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 08:58:37,423 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9356 virtual)
2025-12-23 08:58:37,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,556 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,597 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,602 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,938 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,953 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,969 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:37,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:37,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,006 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:39,298 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:39,361 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 46171 virtual documents
2025-12-23 08:58:39,510 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:39,559 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:58:39,559 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:58:39.559493', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:39,561 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:41,626 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:58:41,628 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:58:41,630 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:58:41,633 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:58:41,635 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:58:41,637 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:58:41,639 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:58:41,641 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:58:41,643 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:58:41,645 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:58:41,648 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:58:41,650 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:58:41,653 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:58:41,655 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 08:58:41,658 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 08:58:41,659 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (109356 virtual)
2025-12-23 08:58:41,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:41,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:41,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,029 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,364 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,378 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:43,430 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 109363 virtual documents
2025-12-23 08:58:43,550 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:43,601 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:58:43,601 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:58:43.601333', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:43,612 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:54,747 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:56,461 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:56,510 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:58:56,510 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:58:56.510429', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:56,511 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:58,656 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:58:58,658 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:58:58,660 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:58:58,661 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:58:58,665 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:58:58,671 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:58:58,673 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:58:58,676 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:58:58,679 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 08:58:58,681 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 08:58:58,682 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9356 virtual)
2025-12-23 08:58:58,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:58,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,368 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:00,412 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 46171 virtual documents
2025-12-23 08:59:00,563 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:00,612 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:59:00,612 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:59:00.612284', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:00,614 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:02,770 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:59:02,772 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:59:02,774 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:59:02,777 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:59:02,779 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:59:02,781 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:59:02,783 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:59:02,785 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:59:02,787 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:59:02,790 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:59:02,792 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:59:02,794 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:59:02,797 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:59:02,799 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 08:59:02,802 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 08:59:02,803 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (109356 virtual)
2025-12-23 08:59:02,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:02,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,889 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:03,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:03,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,517 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:04,552 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 109363 virtual documents
2025-12-23 08:59:04,671 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:04,721 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:59:04,721 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:59:04.721222', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:04,732 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:15,991 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 48.49it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 52.40it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 49.03it/s]Training CobwebTree:  18%|        | 23/125 [00:00<00:02, 48.82it/s]Training CobwebTree:  23%|       | 29/125 [00:00<00:01, 50.10it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 52.21it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 48.06it/s]Training CobwebTree:  38%|      | 47/125 [00:00<00:01, 47.81it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 48.34it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 47.60it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 50.01it/s]Training CobwebTree:  55%|    | 69/125 [00:01<00:01, 50.41it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:00, 51.22it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 49.77it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 50.27it/s]Training CobwebTree:  74%|  | 93/125 [00:01<00:00, 50.51it/s]Training CobwebTree:  79%|  | 99/125 [00:02<00:00, 47.70it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 45.69it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 46.45it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 48.79it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 47.75it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 47.68it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.81it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:20,373 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:20,422 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:59:20,423 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:59:20.422984', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:20,425 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:22,560 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:59:22,562 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:59:22,563 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:59:22,565 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:59:22,569 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:59:22,575 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:59:22,578 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:59:22,581 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:59:22,583 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 08:59:22,585 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 08:59:22,587 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9356 virtual)
2025-12-23 08:59:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:22,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,180 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,344 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:23,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:23,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:24,775 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:24,836 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 46171 virtual documents
2025-12-23 08:59:25,202 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:25,250 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:59:25,251 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:59:25.251053', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:25,254 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:27,383 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:59:27,386 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:59:27,388 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:59:27,390 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:59:27,392 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:59:27,394 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:59:27,396 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:59:27,398 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:59:27,400 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:59:27,402 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:59:27,405 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:59:27,407 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:59:27,410 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:59:27,413 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 08:59:27,415 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 08:59:27,417 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (109356 virtual)
2025-12-23 08:59:27,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,467 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,467 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,469 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,469 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,477 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,477 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,481 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:27,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,148 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:28,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:28,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,301 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:29,357 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 109363 virtual documents
2025-12-23 08:59:29,607 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:29,658 INFO gensim.corpora.dictionary: built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)
2025-12-23 08:59:29,658 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13905 unique tokens: ['01', '10', '1047', '11', '116']...> from 1000 documents (total 118356 corpus positions)", 'datetime': '2025-12-23T08:59:29.658770', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:29,671 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:40,924 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:43,064 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:43,119 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 08:59:43,119 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T08:59:43.119521', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:43,121 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:45,276 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 08:59:45,278 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 08:59:45,280 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 08:59:45,282 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 08:59:45,286 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 08:59:45,291 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 08:59:45,294 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 08:59:45,296 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 08:59:45,299 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 08:59:45,301 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 08:59:45,303 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 08:59:45,307 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (10015 virtual)
2025-12-23 08:59:45,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,838 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,850 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,912 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,965 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:47,024 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:47,060 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 51823 virtual documents
2025-12-23 08:59:47,248 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:47,304 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 08:59:47,304 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T08:59:47.304443', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:47,306 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:49,424 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 08:59:49,426 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 08:59:49,428 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 08:59:49,429 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 08:59:49,431 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 08:59:49,433 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 08:59:49,435 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 08:59:49,437 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 08:59:49,439 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 08:59:49,441 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 08:59:49,444 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 08:59:49,446 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 08:59:49,449 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 08:59:49,451 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 08:59:49,454 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 08:59:49,456 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 08:59:49,458 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 08:59:49,472 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (122515 virtual)
2025-12-23 08:59:49,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,585 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,585 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:49,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,088 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,114 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,196 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,565 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:51,611 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 122522 virtual documents
2025-12-23 08:59:51,744 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:51,801 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 08:59:51,801 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T08:59:51.801330', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:51,811 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:04,304 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:06,000 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:06,054 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:06,054 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:06.054968', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:06,056 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:08,119 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:00:08,121 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:00:08,122 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:00:08,124 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:00:08,128 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:00:08,134 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:00:08,136 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:00:08,139 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:00:08,141 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:00:08,144 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:00:08,146 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:00:08,149 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (10015 virtual)
2025-12-23 09:00:08,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,297 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,325 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,718 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:08,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:08,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,864 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:09,909 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 51823 virtual documents
2025-12-23 09:00:10,069 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:10,124 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:10,124 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:10.124227', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:10,126 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:12,196 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:00:12,198 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:00:12,199 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:00:12,201 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:00:12,203 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:00:12,205 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:00:12,207 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:00:12,209 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:00:12,211 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:00:12,213 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:00:12,216 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:00:12,218 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:00:12,221 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:00:12,223 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:00:12,226 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:00:12,228 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:00:12,244 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:00:12,246 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (122515 virtual)
2025-12-23 09:00:12,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,362 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,844 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,896 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,949 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:12,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:12,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:14,052 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:14,110 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 122522 virtual documents
2025-12-23 09:00:14,227 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:14,282 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:14,282 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:14.282239', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:14,293 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:26,867 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 47.82it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 47.46it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 50.17it/s]Training CobwebTree:  18%|        | 22/125 [00:00<00:01, 52.31it/s]Training CobwebTree:  22%|       | 28/125 [00:00<00:01, 50.90it/s]Training CobwebTree:  27%|       | 34/125 [00:00<00:01, 50.90it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 49.51it/s]Training CobwebTree:  36%|      | 45/125 [00:00<00:01, 46.30it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 48.50it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 50.71it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 49.27it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 48.18it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 47.19it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:00, 47.77it/s]Training CobwebTree:  67%|   | 84/125 [00:01<00:00, 49.12it/s]Training CobwebTree:  71%|   | 89/125 [00:01<00:00, 48.64it/s]Training CobwebTree:  76%|  | 95/125 [00:01<00:00, 49.37it/s]Training CobwebTree:  80%|  | 100/125 [00:02<00:00, 49.40it/s]Training CobwebTree:  84%| | 105/125 [00:02<00:00, 49.16it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 50.57it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 50.71it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 50.06it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 49.40it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:31,219 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:31,274 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:31,274 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:31.274646', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:31,277 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:33,499 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:00:33,502 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:00:33,504 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:00:33,507 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:00:33,511 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:00:33,517 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:00:33,523 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:00:33,526 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:00:33,529 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:00:33,531 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:00:33,533 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:00:33,537 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (10015 virtual)
2025-12-23 09:00:33,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:33,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,144 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,324 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,341 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:34,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:34,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,520 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:35,586 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 51823 virtual documents
2025-12-23 09:00:36,222 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:36,277 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:36,277 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:36.277236', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:36,280 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:38,479 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:00:38,482 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:00:38,484 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:00:38,486 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:00:38,487 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:00:38,490 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:00:38,492 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:00:38,494 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:00:38,496 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:00:38,498 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:00:38,501 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:00:38,503 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:00:38,506 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:00:38,509 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:00:38,511 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:00:38,513 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:00:38,515 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:00:38,517 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (122515 virtual)
2025-12-23 09:00:38,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:38,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,252 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,309 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,456 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:39,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:39,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:40,553 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:40,618 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 122522 virtual documents
2025-12-23 09:00:40,859 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:40,915 INFO gensim.corpora.dictionary: built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)
2025-12-23 09:00:40,915 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<15154 unique tokens: ['01', '10', '1047', '11', '116']...> from 1125 documents (total 132640 corpus positions)", 'datetime': '2025-12-23T09:00:40.915899', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:40,928 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:53,568 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:55,727 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:55,789 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:00:55,789 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:00:55.789684', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:55,791 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:57,892 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:00:57,894 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:00:57,895 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:00:57,897 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:00:57,901 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:00:57,907 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:00:57,909 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:00:57,912 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:00:57,915 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:00:57,917 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:00:57,919 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:00:57,923 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:00:57,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:57,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,142 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,221 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,557 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,613 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,760 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:59,800 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 55957 virtual documents
2025-12-23 09:00:59,997 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:00,058 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:00,058 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:00.058346', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:00,060 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:02,158 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:01:02,160 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:01:02,161 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:01:02,163 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:01:02,164 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:01:02,165 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:01:02,167 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:01:02,168 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:01:02,169 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:01:02,171 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:01:02,173 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:01:02,176 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:01:02,179 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:01:02,182 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:01:02,184 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:01:02,186 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:01:02,188 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:01:02,190 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:01:02,193 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:01:02,194 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (134283 virtual)
2025-12-23 09:01:02,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,937 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,960 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:02,985 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:02,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,004 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,109 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,452 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:04,488 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134290 virtual documents
2025-12-23 09:01:04,644 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:04,707 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:04,707 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:04.707644', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:04,719 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:18,623 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:20,295 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:20,357 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:20,357 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:20.357346', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:20,359 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:22,499 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:01:22,501 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:01:22,502 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:01:22,504 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:01:22,508 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:01:22,514 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:01:22,517 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:01:22,520 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:01:22,522 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:01:22,524 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:01:22,526 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:01:22,530 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:01:22,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,986 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,991 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,004 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,018 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,253 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:24,329 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:24,365 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 55957 virtual documents
2025-12-23 09:01:24,538 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:24,599 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:24,599 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:24.599409', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:24,601 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:26,787 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:01:26,789 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:01:26,791 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:01:26,793 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:01:26,795 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:01:26,797 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:01:26,799 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:01:26,801 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:01:26,803 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:01:26,805 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:01:26,807 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:01:26,810 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:01:26,813 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:01:26,815 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:01:26,817 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:01:26,820 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:01:26,822 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:01:26,824 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:01:26,826 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:01:26,827 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (134283 virtual)
2025-12-23 09:01:26,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:26,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,548 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,553 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,574 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,672 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,720 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:28,746 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134290 virtual documents
2025-12-23 09:01:28,862 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:28,923 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:28,923 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:28.923642', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:28,934 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:42,900 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 4/125 [00:00<00:03, 38.38it/s]Training CobwebTree:   7%|         | 9/125 [00:00<00:02, 41.44it/s]Training CobwebTree:  11%|         | 14/125 [00:00<00:02, 44.74it/s]Training CobwebTree:  15%|        | 19/125 [00:00<00:02, 46.12it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 46.15it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 49.81it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 48.26it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 47.78it/s]Training CobwebTree:  36%|      | 45/125 [00:00<00:01, 47.94it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 49.35it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 49.45it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 48.72it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 48.43it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 49.16it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:00, 47.96it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 47.17it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 47.21it/s]Training CobwebTree:  75%|  | 94/125 [00:01<00:00, 48.84it/s]Training CobwebTree:  79%|  | 99/125 [00:02<00:00, 49.06it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 47.93it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 49.10it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 49.27it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 49.31it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.21it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:47,347 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:47,407 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:47,407 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:47.407905', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:47,410 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:49,819 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:01:49,822 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:01:49,825 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:01:49,827 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:01:49,832 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:01:49,838 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:01:49,841 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:01:49,844 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:01:49,846 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:01:49,848 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:01:49,850 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:01:49,855 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:01:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,918 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,926 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,926 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,926 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:49,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,801 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,896 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:50,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:50,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,058 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:52,424 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 55957 virtual documents
2025-12-23 09:01:52,794 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:52,854 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:52,854 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:52.854592', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:52,858 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:55,090 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:01:55,093 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:01:55,094 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:01:55,096 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:01:55,099 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:01:55,102 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:01:55,104 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:01:55,106 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:01:55,108 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:01:55,111 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:01:55,113 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:01:55,116 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:01:55,119 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:01:55,121 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:01:55,124 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:01:55,126 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:01:55,128 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:01:55,131 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:01:55,133 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:01:55,134 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (134283 virtual)
2025-12-23 09:01:55,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,284 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,284 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:55,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,989 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:55,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,101 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,140 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:56,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:56,224 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,297 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:57,356 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134290 virtual documents
2025-12-23 09:01:57,611 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:57,671 INFO gensim.corpora.dictionary: built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)
2025-12-23 09:01:57,671 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<16209 unique tokens: ['01', '10', '1047', '11', '116']...> from 1250 documents (total 145533 corpus positions)", 'datetime': '2025-12-23T09:01:57.671764', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:57,685 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:11,801 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:14,115 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:14,186 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:14,186 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:14.186347', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:14,188 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:16,405 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:02:16,408 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:02:16,411 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:02:16,413 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:02:16,417 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:02:16,423 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:02:16,425 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:02:16,429 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:02:16,431 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:02:16,434 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:02:16,436 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:02:16,440 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:02:16,446 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:02:16,465 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15809 virtual)
2025-12-23 09:02:16,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,136 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,174 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,268 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:18,455 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:18,499 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 66510 virtual documents
2025-12-23 09:02:18,719 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:18,787 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:18,787 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:18.787669', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:18,790 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:21,322 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:02:21,325 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:02:21,327 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:02:21,331 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:02:21,333 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:02:21,335 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:02:21,337 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:02:21,339 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:02:21,341 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:02:21,343 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:02:21,346 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:02:21,348 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:02:21,351 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:02:21,354 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:02:21,356 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:02:21,359 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:02:21,361 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:02:21,363 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:02:21,365 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:02:21,367 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:02:21,370 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:02:21,373 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (153309 virtual)
2025-12-23 09:02:21,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,950 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,198 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,257 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:22,416 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:23,612 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:23,654 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 153319 virtual documents
2025-12-23 09:02:23,822 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:23,895 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:23,895 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:23.895143', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:23,907 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:39,324 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:41,069 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:41,137 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:41,137 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:41.137541', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:41,139 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:43,316 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:02:43,318 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:02:43,320 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:02:43,322 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:02:43,326 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:02:43,332 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:02:43,335 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:02:43,337 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:02:43,340 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:02:43,342 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:02:43,344 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:02:43,348 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:02:43,354 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:02:43,356 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15809 virtual)
2025-12-23 09:02:43,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,493 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,498 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,513 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,518 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,812 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,868 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,868 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,985 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:43,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,992 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,993 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:44,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:44,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:44,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:44,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:44,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:45,278 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:45,306 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 66510 virtual documents
2025-12-23 09:02:45,471 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:45,538 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:45,539 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:45.538996', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:45,541 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:47,720 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:02:47,722 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:02:47,724 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:02:47,726 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:02:47,727 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:02:47,729 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:02:47,731 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:02:47,734 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:02:47,736 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:02:47,738 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:02:47,741 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:02:47,743 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:02:47,746 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:02:47,749 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:02:47,751 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:02:47,753 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:02:47,755 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:02:47,757 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:02:47,759 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:02:47,761 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:02:47,763 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:02:47,766 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (153309 virtual)
2025-12-23 09:02:47,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,481 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:49,813 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:49,860 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 153319 virtual documents
2025-12-23 09:02:49,995 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:50,064 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:02:50,064 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:02:50.064432', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:50,075 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:05,562 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 47.00it/s]Training CobwebTree:   9%|         | 11/125 [00:00<00:02, 48.73it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 45.75it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:02, 45.89it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:02, 46.73it/s]Training CobwebTree:  26%|       | 32/125 [00:00<00:02, 46.18it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 45.84it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 47.77it/s]Training CobwebTree:  39%|      | 49/125 [00:01<00:01, 48.89it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 49.01it/s]Training CobwebTree:  47%|     | 59/125 [00:01<00:01, 48.26it/s]Training CobwebTree:  51%|     | 64/125 [00:01<00:01, 45.95it/s]Training CobwebTree:  55%|    | 69/125 [00:01<00:01, 45.28it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:01, 45.90it/s]Training CobwebTree:  63%|   | 79/125 [00:01<00:00, 46.50it/s]Training CobwebTree:  67%|   | 84/125 [00:01<00:00, 44.29it/s]Training CobwebTree:  71%|   | 89/125 [00:01<00:00, 44.25it/s]Training CobwebTree:  75%|  | 94/125 [00:02<00:00, 45.53it/s]Training CobwebTree:  79%|  | 99/125 [00:02<00:00, 46.07it/s]Training CobwebTree:  84%| | 105/125 [00:02<00:00, 47.74it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 48.17it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 48.66it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 48.86it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.57it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 47.03it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:10,138 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:10,206 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:03:10,206 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:03:10.206162', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:10,208 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:12,459 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:03:12,462 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:03:12,463 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:03:12,466 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:03:12,470 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:03:12,477 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:03:12,479 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:03:12,482 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:03:12,484 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:03:12,487 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:03:12,489 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:03:12,493 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:03:12,500 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:03:12,503 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15809 virtual)
2025-12-23 09:03:12,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,492 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,628 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,786 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:15,095 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:15,171 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 66510 virtual documents
2025-12-23 09:03:15,593 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:15,661 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:03:15,661 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:03:15.661351', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:15,665 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:17,837 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:03:17,840 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:03:17,843 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:03:17,846 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:03:17,849 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:03:17,851 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:03:17,853 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:03:17,863 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:03:17,865 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:03:17,867 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:03:17,869 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:03:17,872 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:03:17,875 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:03:17,877 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:03:17,880 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:03:17,882 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:03:17,884 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:03:17,887 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:03:17,889 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:03:17,891 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:03:17,894 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:03:17,897 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (153309 virtual)
2025-12-23 09:03:17,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:17,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,011 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,085 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,898 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:18,960 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:18,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:19,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:19,021 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:19,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:19,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:19,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:20,129 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:20,197 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 153319 virtual documents
2025-12-23 09:03:20,459 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:20,529 INFO gensim.corpora.dictionary: built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)
2025-12-23 09:03:20,529 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<17761 unique tokens: ['01', '10', '1047', '11', '116']...> from 1375 documents (total 165684 corpus positions)", 'datetime': '2025-12-23T09:03:20.529493', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:20,542 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:36,005 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:38,286 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:38,362 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:03:38,362 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:03:38.362626', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:38,364 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:40,486 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:03:40,489 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:03:40,493 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:03:40,495 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:03:40,499 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:03:40,505 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:03:40,507 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:03:40,510 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:03:40,512 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:03:40,515 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:03:40,517 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:03:40,521 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:03:40,527 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:03:40,530 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:03:40,533 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (16165 virtual)
2025-12-23 09:03:40,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:40,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:40,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,040 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,120 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,176 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,224 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,458 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:42,491 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71085 virtual documents
2025-12-23 09:03:42,646 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:42,720 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:03:42,720 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:03:42.720184', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:42,722 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:44,904 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:03:44,907 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:03:44,908 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:03:44,910 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:03:44,911 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:03:44,913 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:03:44,915 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:03:44,932 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:03:44,934 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:03:44,936 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:03:44,939 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:03:44,941 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:03:44,944 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:03:44,947 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:03:44,949 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:03:44,951 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:03:44,953 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:03:44,956 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:03:44,958 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:03:44,960 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:03:44,962 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:03:44,982 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:03:44,984 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:03:44,999 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (166165 virtual)
2025-12-23 09:03:45,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,092 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,117 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,117 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,477 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,668 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,813 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:45,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:45,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:47,428 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:47,459 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 166175 virtual documents
2025-12-23 09:03:47,584 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:47,658 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:03:47,658 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:03:47.658789', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:47,673 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:04,556 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:06,308 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:06,383 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:06,383 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:06.383739', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:06,385 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:08,715 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:04:08,718 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:04:08,720 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:04:08,723 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:04:08,727 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:04:08,733 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:04:08,735 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:04:08,738 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:04:08,741 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:04:08,743 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:04:08,745 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:04:08,749 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:04:08,755 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:04:08,758 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:04:08,762 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (16165 virtual)
2025-12-23 09:04:08,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,344 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,436 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,452 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,452 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,467 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,468 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,624 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:10,701 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:10,749 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71085 virtual documents
2025-12-23 09:04:10,916 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:10,989 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:10,990 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:10.990120', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:10,996 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:13,184 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:04:13,187 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:04:13,188 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:04:13,190 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:04:13,192 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:04:13,194 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:04:13,196 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:04:13,198 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:04:13,200 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:04:13,203 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:04:13,205 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:04:13,207 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:04:13,210 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:04:13,213 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:04:13,215 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:04:13,218 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:04:13,220 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:04:13,222 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:04:13,224 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:04:13,226 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:04:13,228 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:04:13,232 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:04:13,234 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:04:13,235 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (166165 virtual)
2025-12-23 09:04:13,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,622 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,844 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,949 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:13,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:13,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,121 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,154 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,162 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,180 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,189 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,192 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,209 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:14,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:14,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:15,348 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:15,389 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 166175 virtual documents
2025-12-23 09:04:15,525 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:15,598 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:15,598 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:15.598856', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:15,610 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:32,562 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 4/125 [00:00<00:03, 38.77it/s]Training CobwebTree:   6%|         | 8/125 [00:00<00:02, 39.15it/s]Training CobwebTree:  10%|         | 13/125 [00:00<00:02, 40.76it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 42.60it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 45.83it/s]Training CobwebTree:  23%|       | 29/125 [00:00<00:02, 45.41it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 47.87it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 47.61it/s]Training CobwebTree:  36%|      | 45/125 [00:00<00:01, 47.36it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 47.57it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 47.73it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 47.30it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 44.70it/s]Training CobwebTree:  56%|    | 70/125 [00:01<00:01, 45.87it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 47.16it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 46.51it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 47.15it/s]Training CobwebTree:  73%|  | 91/125 [00:01<00:00, 45.97it/s]Training CobwebTree:  77%|  | 96/125 [00:02<00:00, 45.57it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 43.59it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 42.44it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 43.24it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 44.34it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 44.60it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 45.01it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:37,280 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:37,355 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:37,355 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:37.355429', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:37,358 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:39,542 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:04:39,545 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:04:39,547 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:04:39,550 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:04:39,554 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:04:39,561 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:04:39,563 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:04:39,566 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:04:39,568 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:04:39,571 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:04:39,573 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:04:39,577 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:04:39,584 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:04:39,587 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:04:39,590 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (16165 virtual)
2025-12-23 09:04:39,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,696 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,696 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,696 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:39,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:39,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,144 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,584 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:40,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:40,878 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:41,880 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:42,258 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71085 virtual documents
2025-12-23 09:04:42,681 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:42,754 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:42,754 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:42.754832', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:42,758 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:45,051 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:04:45,053 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:04:45,055 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:04:45,058 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:04:45,061 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:04:45,063 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:04:45,065 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:04:45,068 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:04:45,070 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:04:45,072 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:04:45,075 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:04:45,077 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:04:45,080 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:04:45,083 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:04:45,085 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:04:45,088 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:04:45,090 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:04:45,092 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:04:45,094 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:04:45,096 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:04:45,099 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:04:45,103 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:04:45,105 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:04:45,106 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (166165 virtual)
2025-12-23 09:04:45,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,206 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,916 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:45,938 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:45,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,011 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,152 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,157 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,168 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,190 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,190 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,200 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:46,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:46,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,437 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:47,505 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 166175 virtual documents
2025-12-23 09:04:47,786 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:47,859 INFO gensim.corpora.dictionary: built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)
2025-12-23 09:04:47,859 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18760 unique tokens: ['01', '10', '1047', '11', '116']...> from 1500 documents (total 179665 corpus positions)", 'datetime': '2025-12-23T09:04:47.859856', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:47,872 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:04,826 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:07,160 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:07,243 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:07,243 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:07.243311', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:07,245 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:09,469 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:05:09,472 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:05:09,474 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:05:09,476 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:05:09,481 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:05:09,487 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:05:09,489 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:05:09,492 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:05:09,494 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:05:09,497 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:05:09,499 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:05:09,503 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:05:09,509 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:05:09,513 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:05:09,518 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:05:09,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,622 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:09,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:09,957 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,062 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,072 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,177 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,300 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:10,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:10,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:11,556 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:11,609 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 76723 virtual documents
2025-12-23 09:05:11,814 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:11,894 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:11,894 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:11.894342', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:11,896 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:14,456 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:05:14,459 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:05:14,461 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:05:14,462 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:05:14,464 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:05:14,466 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:05:14,468 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:05:14,470 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:05:14,472 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:05:14,474 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:05:14,477 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:05:14,479 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:05:14,482 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:05:14,484 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:05:14,487 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:05:14,489 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:05:14,491 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:05:14,493 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:05:14,495 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:05:14,524 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:05:14,527 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:05:14,567 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:05:14,590 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:05:14,621 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:05:14,636 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:05:14,638 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (179952 virtual)
2025-12-23 09:05:14,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:14,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:14,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,360 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,373 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,506 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:15,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:15,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:16,655 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:16,695 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 179962 virtual documents
2025-12-23 09:05:16,881 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:16,963 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:16,964 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:16.964024', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:16,975 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:35,357 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:37,133 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:37,215 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:37,215 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:37.215583', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:37,217 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:39,433 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:05:39,436 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:05:39,438 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:05:39,440 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:05:39,444 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:05:39,450 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:05:39,453 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:05:39,456 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:05:39,458 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:05:39,461 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:05:39,463 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:05:39,467 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:05:39,473 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:05:39,477 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:05:39,481 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:05:39,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,549 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,616 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,616 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,826 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:39,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:39,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,058 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,088 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,288 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,305 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:40,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:40,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:41,578 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:41,627 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 76723 virtual documents
2025-12-23 09:05:41,797 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:41,881 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:41,881 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:41.881443', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:41,883 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:44,165 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:05:44,167 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:05:44,170 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:05:44,172 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:05:44,173 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:05:44,175 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:05:44,177 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:05:44,180 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:05:44,182 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:05:44,184 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:05:44,190 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:05:44,192 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:05:44,196 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:05:44,198 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:05:44,200 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:05:44,203 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:05:44,205 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:05:44,207 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:05:44,209 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:05:44,212 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:05:44,214 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:05:44,218 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:05:44,220 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:05:44,223 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:05:44,226 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:05:44,227 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (179952 virtual)
2025-12-23 09:05:44,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:44,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,029 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,105 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,109 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,125 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,152 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,181 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:45,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:45,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,478 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:46,511 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 179962 virtual documents
2025-12-23 09:05:46,648 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:46,729 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:05:46,729 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:05:46.729905', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:46,745 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:05,235 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 4/125 [00:00<00:03, 38.18it/s]Training CobwebTree:   7%|         | 9/125 [00:00<00:02, 43.66it/s]Training CobwebTree:  11%|         | 14/125 [00:00<00:02, 45.21it/s]Training CobwebTree:  15%|        | 19/125 [00:00<00:02, 42.79it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 43.83it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 45.39it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 46.71it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 45.50it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:01, 47.43it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 42.72it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 43.91it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 43.34it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 42.57it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 44.41it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 45.35it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 45.89it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 45.78it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 46.76it/s]Training CobwebTree:  78%|  | 98/125 [00:02<00:00, 47.52it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 48.48it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 46.68it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 45.43it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 42.24it/s]Training CobwebTree:  99%|| 124/125 [00:02<00:00, 43.62it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 44.62it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:09,981 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:10,068 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:06:10,068 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:06:10.068180', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:10,071 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:12,300 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:06:12,302 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:06:12,304 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:06:12,307 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:06:12,311 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:06:12,318 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:06:12,320 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:06:12,323 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:06:12,325 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:06:12,327 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:06:12,329 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:06:12,333 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:06:12,340 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:06:12,343 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:06:12,348 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:06:12,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,445 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,813 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:12,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:12,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,353 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:13,786 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:13,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:15,161 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:15,234 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 76723 virtual documents
2025-12-23 09:06:15,653 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:15,734 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:06:15,734 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:06:15.734388', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:15,738 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:17,919 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:06:17,922 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:06:17,925 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:06:17,928 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:06:17,931 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:06:17,934 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:06:17,936 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:06:17,938 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:06:17,941 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:06:17,943 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:06:17,945 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:06:17,948 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:06:17,951 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:06:17,953 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:06:17,956 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:06:17,959 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:06:17,961 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:06:17,963 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:06:17,965 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:06:17,968 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:06:17,970 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:06:17,974 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:06:17,976 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:06:17,979 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:06:17,981 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:06:17,982 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (179952 virtual)
2025-12-23 09:06:18,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:18,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,000 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:18,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,044 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,202 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:19,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:19,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:20,391 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:20,468 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 179962 virtual documents
2025-12-23 09:06:20,743 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:20,826 INFO gensim.corpora.dictionary: built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)
2025-12-23 09:06:20,826 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<19775 unique tokens: ['01', '10', '1047', '11', '116']...> from 1625 documents (total 194577 corpus positions)", 'datetime': '2025-12-23T09:06:20.826174', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:20,839 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:39,301 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:41,642 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:41,731 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:06:41,732 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:06:41.732055', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:41,734 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:43,978 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:06:43,980 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:06:43,982 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:06:43,984 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:06:43,988 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:06:43,994 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:06:43,997 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:06:44,000 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:06:44,002 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:06:44,004 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:06:44,006 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:06:44,010 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:06:44,016 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:06:44,020 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:06:44,024 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:06:44,031 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (20295 virtual)
2025-12-23 09:06:44,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,174 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,241 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,344 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,881 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,990 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:45,026 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:45,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:45,052 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:45,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:45,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:46,584 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:46,627 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 83430 virtual documents
2025-12-23 09:06:46,812 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:46,898 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:06:46,898 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:06:46.898789', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:46,901 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:49,152 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:06:49,155 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:06:49,158 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:06:49,160 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:06:49,162 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:06:49,164 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:06:49,166 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:06:49,169 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:06:49,171 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:06:49,173 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:06:49,176 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:06:49,178 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:06:49,181 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:06:49,183 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:06:49,186 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:06:49,188 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:06:49,190 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:06:49,192 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:06:49,194 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:06:49,196 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:06:49,199 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:06:49,202 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:06:49,204 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:06:49,207 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:06:49,209 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:06:49,211 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (183526 virtual)
2025-12-23 09:06:49,214 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (193095 virtual)
2025-12-23 09:06:49,215 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (195250 virtual)
2025-12-23 09:06:49,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,894 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:50,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:50,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:51,492 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:51,533 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 195261 virtual documents
2025-12-23 09:06:51,701 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:51,788 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:06:51,788 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:06:51.788903', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:51,800 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:11,686 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:13,454 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:13,555 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:13,555 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:13.555540', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:13,557 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:15,763 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:07:15,766 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:07:15,768 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:07:15,771 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:07:15,775 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:07:15,781 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:07:15,783 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:07:15,786 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:07:15,788 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:07:15,791 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:07:15,793 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:07:15,797 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:07:15,803 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:07:15,807 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:07:15,811 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:07:15,818 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (20295 virtual)
2025-12-23 09:07:15,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,949 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,950 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,950 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,953 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:15,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:15,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,005 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,008 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,013 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,018 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,372 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,588 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,770 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:16,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:16,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:17,985 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:18,022 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 83430 virtual documents
2025-12-23 09:07:18,190 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:18,283 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:18,283 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:18.283152', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:18,285 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:20,511 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:07:20,514 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:07:20,516 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:07:20,517 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:07:20,519 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:07:20,521 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:07:20,523 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:07:20,525 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:07:20,527 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:07:20,529 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:07:20,532 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:07:20,534 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:07:20,537 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:07:20,540 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:07:20,542 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:07:20,544 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:07:20,546 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:07:20,548 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:07:20,550 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:07:20,552 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:07:20,554 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:07:20,558 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:07:20,560 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:07:20,563 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:07:20,564 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:07:20,566 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (183526 virtual)
2025-12-23 09:07:20,569 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (193095 virtual)
2025-12-23 09:07:20,569 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (195250 virtual)
2025-12-23 09:07:20,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:20,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,757 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:20,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,622 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,684 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,688 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:21,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:21,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:22,866 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:22,899 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 195261 virtual documents
2025-12-23 09:07:23,035 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:23,132 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:23,132 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:23.132195', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:23,143 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:43,118 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 42.21it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 43.41it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 46.07it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 43.62it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 43.63it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 42.82it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 41.46it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:02, 40.22it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 41.63it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 41.90it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 42.98it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 40.73it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 40.75it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 42.85it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 42.43it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:01, 42.35it/s]Training CobwebTree:  69%|   | 86/125 [00:02<00:00, 41.45it/s]Training CobwebTree:  73%|  | 91/125 [00:02<00:00, 41.01it/s]Training CobwebTree:  77%|  | 96/125 [00:02<00:00, 41.54it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 43.43it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 44.76it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 43.67it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 43.37it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 44.61it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 42.67it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:48,018 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:48,105 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:48,105 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:48.105928', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:48,108 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:50,443 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:07:50,445 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:07:50,447 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:07:50,449 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:07:50,453 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:07:50,459 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:07:50,462 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:07:50,464 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:07:50,467 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:07:50,469 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:07:50,471 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:07:50,475 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:07:50,481 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:07:50,484 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:07:50,489 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:07:50,496 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (20295 virtual)
2025-12-23 09:07:50,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:50,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:50,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,461 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,572 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,928 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:51,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:51,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:53,473 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:53,549 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 83430 virtual documents
2025-12-23 09:07:53,954 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:54,040 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:54,040 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:54.040788', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:54,044 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:56,258 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:07:56,261 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:07:56,264 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:07:56,267 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:07:56,270 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:07:56,272 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:07:56,274 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:07:56,277 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:07:56,279 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:07:56,281 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:07:56,284 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:07:56,287 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:07:56,289 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:07:56,292 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:07:56,294 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:07:56,296 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:07:56,298 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:07:56,301 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:07:56,303 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:07:56,305 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:07:56,307 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:07:56,311 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:07:56,313 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:07:56,316 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:07:56,318 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:07:56,320 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (183526 virtual)
2025-12-23 09:07:56,323 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (193095 virtual)
2025-12-23 09:07:56,324 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (195250 virtual)
2025-12-23 09:07:56,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,518 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,518 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:56,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:56,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,652 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:57,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:57,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:58,795 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:58,871 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 195261 virtual documents
2025-12-23 09:07:59,141 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:59,227 INFO gensim.corpora.dictionary: built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)
2025-12-23 09:07:59,227 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<20936 unique tokens: ['01', '10', '1047', '11', '116']...> from 1750 documents (total 211000 corpus positions)", 'datetime': '2025-12-23T09:07:59.227218', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:59,240 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:19,237 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:21,585 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:21,682 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:08:21,682 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:08:21.682825', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:21,685 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:23,938 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:08:23,942 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:08:23,945 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:08:23,948 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:08:23,952 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:08:23,958 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:08:23,961 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:08:23,964 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:08:23,966 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:08:23,968 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:08:23,970 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:08:23,975 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:08:23,981 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:08:23,985 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:08:23,990 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:08:23,996 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (20295 virtual)
2025-12-23 09:08:23,999 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (21185 virtual)
2025-12-23 09:08:24,003 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (23072 virtual)
2025-12-23 09:08:24,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,730 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,841 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,850 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:24,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,981 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:24,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:25,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:25,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:25,037 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:25,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:25,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:25,084 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:25,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:25,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:25,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:25,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:26,681 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:26,723 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 89971 virtual documents
2025-12-23 09:08:26,943 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:27,037 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:08:27,037 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:08:27.037758', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:27,040 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:29,248 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:08:29,251 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:08:29,255 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:08:29,258 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:08:29,260 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:08:29,263 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:08:29,264 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:08:29,267 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:08:29,269 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:08:29,271 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:08:29,274 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:08:29,276 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:08:29,279 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:08:29,282 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:08:29,284 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:08:29,286 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:08:29,289 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:08:29,291 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:08:29,293 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:08:29,295 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:08:29,298 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:08:29,301 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:08:29,304 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:08:29,307 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:08:29,309 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:08:29,311 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (183526 virtual)
2025-12-23 09:08:29,314 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (193095 virtual)
2025-12-23 09:08:29,317 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (200385 virtual)
2025-12-23 09:08:29,320 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (208672 virtual)
2025-12-23 09:08:29,352 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (210480 virtual)
2025-12-23 09:08:29,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:29,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:29,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,000 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,473 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,506 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,661 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:30,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:31,825 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:31,860 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 210492 virtual documents
2025-12-23 09:08:32,032 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:32,127 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:08:32,127 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:08:32.127867', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:32,139 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:53,499 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:55,220 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:55,318 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:08:55,318 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:08:55.318333', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:55,320 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:57,672 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (132 virtual)
2025-12-23 09:08:57,674 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1363 virtual)
2025-12-23 09:08:57,676 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (1457 virtual)
2025-12-23 09:08:57,678 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (1980 virtual)
2025-12-23 09:08:57,682 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (2221 virtual)
2025-12-23 09:08:57,688 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (3023 virtual)
2025-12-23 09:08:57,690 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (3912 virtual)
2025-12-23 09:08:57,693 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6951 virtual)
2025-12-23 09:08:57,696 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (7891 virtual)
2025-12-23 09:08:57,698 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (9205 virtual)
2025-12-23 09:08:57,700 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (9298 virtual)
2025-12-23 09:08:57,704 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (9749 virtual)
2025-12-23 09:08:57,710 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (10312 virtual)
2025-12-23 09:08:57,714 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (15805 virtual)
2025-12-23 09:08:57,718 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (18832 virtual)
2025-12-23 09:08:57,724 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (20295 virtual)
2025-12-23 09:08:57,727 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (21185 virtual)
2025-12-23 09:08:57,730 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (23072 virtual)
2025-12-23 09:08:57,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,832 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,492 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,537 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:58,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:00,038 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:09:00,073 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 89971 virtual documents
2025-12-23 09:09:00,262 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:09:00,355 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:09:00,355 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:09:00.355911', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:09:00,358 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:09:02,550 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (6160 virtual)
2025-12-23 09:09:02,553 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (12204 virtual)
2025-12-23 09:09:02,555 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (19332 virtual)
2025-12-23 09:09:02,558 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (26963 virtual)
2025-12-23 09:09:02,560 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (33457 virtual)
2025-12-23 09:09:02,562 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (40380 virtual)
2025-12-23 09:09:02,564 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (45946 virtual)
2025-12-23 09:09:02,566 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (53421 virtual)
2025-12-23 09:09:02,569 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (59769 virtual)
2025-12-23 09:09:02,571 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (65892 virtual)
2025-12-23 09:09:02,573 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (73423 virtual)
2025-12-23 09:09:02,575 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (80712 virtual)
2025-12-23 09:09:02,578 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (90151 virtual)
2025-12-23 09:09:02,581 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (97491 virtual)
2025-12-23 09:09:02,583 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (105205 virtual)
2025-12-23 09:09:02,586 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (111698 virtual)
2025-12-23 09:09:02,587 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (118003 virtual)
2025-12-23 09:09:02,589 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (124949 virtual)
2025-12-23 09:09:02,592 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (131219 virtual)
2025-12-23 09:09:02,593 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (137247 virtual)
2025-12-23 09:09:02,596 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (144712 virtual)
2025-12-23 09:09:02,599 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (156605 virtual)
2025-12-23 09:09:02,601 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (162999 virtual)
2025-12-23 09:09:02,604 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (172432 virtual)
2025-12-23 09:09:02,606 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (177674 virtual)
2025-12-23 09:09:02,608 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (183526 virtual)
2025-12-23 09:09:02,611 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (193095 virtual)
2025-12-23 09:09:02,636 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (200385 virtual)
2025-12-23 09:09:02,639 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (208672 virtual)
2025-12-23 09:09:02,639 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (210480 virtual)
2025-12-23 09:09:02,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:02,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:02,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,493 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,509 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,597 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,752 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:03,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:03,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:05,033 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:09:05,066 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 210492 virtual documents
2025-12-23 09:09:05,219 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:09:05,313 INFO gensim.corpora.dictionary: built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)
2025-12-23 09:09:05,313 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21966 unique tokens: ['01', '10', '1047', '11', '116']...> from 1875 documents (total 227355 corpus positions)", 'datetime': '2025-12-23T09:09:05.313414', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:09:05,325 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
