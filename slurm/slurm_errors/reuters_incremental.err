2025-12-23 08:53:45,115 INFO __main__: Starting incremental benchmark for dataset=reuters_rcv1
2025-12-23 08:53:46,952 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:53:47,157 INFO gensim.corpora.dictionary: built Dictionary<21311 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 4633 documents (total 378319 corpus positions)
2025-12-23 08:53:47,179 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<21311 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 4633 documents (total 378319 corpus positions)", 'datetime': '2025-12-23T08:53:47.157989', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:53:49,472 INFO sentence_transformers.SentenceTransformer: Use pytorch device_name: cuda:0
2025-12-23 08:53:49,472 INFO sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: all-roberta-large-v1
2025-12-23 08:53:55,602 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:54:11,286 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:11,309 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:11,309 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:11.309765', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:11,310 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:13,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,588 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,597 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,608 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,628 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,646 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,736 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:14,673 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:14,747 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9197 virtual documents
2025-12-23 08:54:14,831 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:14,853 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:14,853 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:14.853938', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:14,854 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:17,289 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:54:17,291 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:54:17,292 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:54:17,293 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:54:17,294 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:54:17,296 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:54:17,297 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:54:17,299 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35065 virtual)
2025-12-23 08:54:17,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,369 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,392 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,397 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,400 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,406 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:17,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:18,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:18,780 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:18,802 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 35067 virtual documents
2025-12-23 08:54:18,870 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:18,893 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:18,893 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:18.893291', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:23,022 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:54:27,373 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:27,395 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:27,395 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:27.395938', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:27,396 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:29,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,652 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:29,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,673 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,673 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,688 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,688 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,700 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,710 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,726 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:29,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:30,776 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:30,834 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9197 virtual documents
2025-12-23 08:54:31,012 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:31,034 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:31,034 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:31.034432', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:31,035 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:33,221 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:54:33,224 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:54:33,225 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:54:33,227 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:54:33,229 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:54:33,230 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:54:33,232 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:54:33,233 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35065 virtual)
2025-12-23 08:54:33,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,289 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,337 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,564 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:33,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:33,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:34,517 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:34,587 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 35067 virtual documents
2025-12-23 08:54:34,704 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:34,727 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:34,727 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:34.727307', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:38,867 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
Training CobwebTree:   0%|          | 0/500 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 18/500 [00:00<00:02, 179.05it/s]Training CobwebTree:   7%|         | 36/500 [00:00<00:03, 130.35it/s]Training CobwebTree:  10%|         | 50/500 [00:00<00:03, 115.11it/s]Training CobwebTree:  12%|        | 62/500 [00:00<00:04, 102.12it/s]Training CobwebTree:  15%|        | 73/500 [00:00<00:04, 96.29it/s] Training CobwebTree:  17%|        | 83/500 [00:00<00:04, 89.90it/s]Training CobwebTree:  19%|        | 93/500 [00:00<00:04, 85.52it/s]Training CobwebTree:  20%|        | 102/500 [00:01<00:04, 85.17it/s]Training CobwebTree:  22%|       | 111/500 [00:01<00:04, 78.84it/s]Training CobwebTree:  24%|       | 120/500 [00:01<00:04, 81.37it/s]Training CobwebTree:  26%|       | 129/500 [00:01<00:04, 77.07it/s]Training CobwebTree:  27%|       | 137/500 [00:01<00:04, 72.92it/s]Training CobwebTree:  29%|       | 145/500 [00:01<00:04, 72.01it/s]Training CobwebTree:  31%|       | 153/500 [00:01<00:04, 71.34it/s]Training CobwebTree:  32%|      | 161/500 [00:01<00:04, 69.48it/s]Training CobwebTree:  34%|      | 168/500 [00:02<00:04, 68.36it/s]Training CobwebTree:  35%|      | 176/500 [00:02<00:04, 69.75it/s]Training CobwebTree:  37%|      | 184/500 [00:02<00:04, 70.18it/s]Training CobwebTree:  38%|      | 192/500 [00:02<00:04, 66.91it/s]Training CobwebTree:  40%|      | 199/500 [00:02<00:04, 65.39it/s]Training CobwebTree:  41%|      | 206/500 [00:02<00:04, 59.83it/s]Training CobwebTree:  43%|     | 213/500 [00:02<00:04, 60.25it/s]Training CobwebTree:  44%|     | 220/500 [00:02<00:04, 61.41it/s]Training CobwebTree:  45%|     | 227/500 [00:02<00:04, 57.29it/s]Training CobwebTree:  47%|     | 235/500 [00:03<00:04, 61.22it/s]Training CobwebTree:  48%|     | 242/500 [00:03<00:04, 62.76it/s]Training CobwebTree:  50%|     | 249/500 [00:03<00:04, 60.20it/s]Training CobwebTree:  51%|     | 256/500 [00:03<00:03, 62.26it/s]Training CobwebTree:  53%|    | 263/500 [00:03<00:03, 61.79it/s]Training CobwebTree:  54%|    | 270/500 [00:03<00:03, 63.53it/s]Training CobwebTree:  55%|    | 277/500 [00:03<00:03, 64.46it/s]Training CobwebTree:  57%|    | 284/500 [00:03<00:03, 61.30it/s]Training CobwebTree:  58%|    | 291/500 [00:03<00:03, 61.39it/s]Training CobwebTree:  60%|    | 298/500 [00:04<00:03, 57.25it/s]Training CobwebTree:  61%|    | 305/500 [00:04<00:03, 56.37it/s]Training CobwebTree:  62%|   | 311/500 [00:04<00:03, 54.63it/s]Training CobwebTree:  63%|   | 317/500 [00:04<00:03, 54.80it/s]Training CobwebTree:  65%|   | 323/500 [00:04<00:03, 55.61it/s]Training CobwebTree:  66%|   | 329/500 [00:04<00:03, 52.96it/s]Training CobwebTree:  67%|   | 335/500 [00:04<00:03, 54.45it/s]Training CobwebTree:  68%|   | 342/500 [00:04<00:02, 55.63it/s]Training CobwebTree:  70%|   | 349/500 [00:05<00:02, 58.58it/s]Training CobwebTree:  71%|   | 356/500 [00:05<00:02, 58.86it/s]Training CobwebTree:  72%|  | 362/500 [00:05<00:02, 57.66it/s]Training CobwebTree:  74%|  | 368/500 [00:05<00:02, 56.80it/s]Training CobwebTree:  75%|  | 374/500 [00:05<00:02, 57.07it/s]Training CobwebTree:  76%|  | 380/500 [00:05<00:02, 56.83it/s]Training CobwebTree:  77%|  | 386/500 [00:05<00:02, 55.95it/s]Training CobwebTree:  78%|  | 392/500 [00:05<00:01, 55.42it/s]Training CobwebTree:  80%|  | 398/500 [00:05<00:01, 53.89it/s]Training CobwebTree:  81%|  | 404/500 [00:06<00:01, 52.97it/s]Training CobwebTree:  82%| | 410/500 [00:06<00:01, 53.27it/s]Training CobwebTree:  83%| | 416/500 [00:06<00:01, 52.99it/s]Training CobwebTree:  85%| | 423/500 [00:06<00:01, 56.29it/s]Training CobwebTree:  86%| | 430/500 [00:06<00:01, 57.93it/s]Training CobwebTree:  87%| | 436/500 [00:06<00:01, 56.76it/s]Training CobwebTree:  88%| | 442/500 [00:06<00:01, 55.55it/s]Training CobwebTree:  90%| | 448/500 [00:06<00:00, 53.72it/s]Training CobwebTree:  91%| | 454/500 [00:06<00:00, 55.15it/s]Training CobwebTree:  92%|| 460/500 [00:07<00:00, 54.09it/s]Training CobwebTree:  93%|| 466/500 [00:07<00:00, 52.93it/s]Training CobwebTree:  94%|| 472/500 [00:07<00:00, 53.86it/s]Training CobwebTree:  96%|| 478/500 [00:07<00:00, 52.63it/s]Training CobwebTree:  97%|| 484/500 [00:07<00:00, 53.84it/s]Training CobwebTree:  98%|| 490/500 [00:07<00:00, 54.32it/s]Training CobwebTree:  99%|| 496/500 [00:07<00:00, 51.98it/s]Training CobwebTree: 100%|| 500/500 [00:07<00:00, 63.88it/s]
2025-12-23 08:54:51,147 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:51,169 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:51,169 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:51.169915', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:51,171 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:53,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,513 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,570 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,574 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,622 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:53,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:54,837 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:54,898 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9197 virtual documents
2025-12-23 08:54:55,179 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:55,202 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:55,202 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:55.202168', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:55,204 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:57,379 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:54:57,381 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:54:57,383 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:54:57,384 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:54:57,386 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:54:57,388 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:54:57,389 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:54:57,391 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35065 virtual)
2025-12-23 08:54:57,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,458 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:57,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:57,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,008 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:59,106 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 35067 virtual documents
2025-12-23 08:54:59,309 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:59,331 INFO gensim.corpora.dictionary: built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)
2025-12-23 08:54:59,331 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6808 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 500 documents (total 39565 corpus positions)", 'datetime': '2025-12-23T08:54:59.331885', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:03,534 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:08,058 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:08,086 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:08,086 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:08.086817', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:08,087 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:10,347 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17727 virtual)
2025-12-23 08:55:10,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,402 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,623 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:10,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:10,724 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:11,616 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:11,686 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12256 virtual documents
2025-12-23 08:55:11,809 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:11,837 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:11,837 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:11.837800', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:11,838 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:14,158 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:55:14,160 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:55:14,161 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:55:14,163 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:55:14,164 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:55:14,166 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:55:14,167 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:55:14,168 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:55:14,170 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:55:14,171 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (44773 virtual)
2025-12-23 08:55:14,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,232 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,262 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,286 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,492 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:14,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,583 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:15,625 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 44775 virtual documents
2025-12-23 08:55:15,713 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:15,741 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:15,741 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:15.741390', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:21,996 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:23,485 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:23,513 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:23,514 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:23.514037', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:23,515 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:25,857 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17727 virtual)
2025-12-23 08:55:25,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:25,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,966 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:25,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,080 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:27,594 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:27,616 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12256 virtual documents
2025-12-23 08:55:27,756 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:27,784 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:27,784 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:27.784962', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:27,786 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:30,040 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:55:30,042 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:55:30,043 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:55:30,045 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:55:30,046 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:55:30,047 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:55:30,049 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:55:30,050 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:55:30,052 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:55:30,054 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (44773 virtual)
2025-12-23 08:55:30,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,116 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,142 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,153 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,158 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,170 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:30,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:30,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:31,493 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:31,549 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 44775 virtual documents
2025-12-23 08:55:31,651 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:31,679 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:31,679 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:31.679936', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:37,987 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 55.94it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 55.88it/s]Training CobwebTree:  15%|        | 19/125 [00:00<00:01, 58.67it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:01, 57.50it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:01, 57.72it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 56.05it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 55.30it/s]Training CobwebTree:  39%|      | 49/125 [00:00<00:01, 53.72it/s]Training CobwebTree:  44%|     | 55/125 [00:00<00:01, 54.56it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 55.81it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:00, 57.20it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:00, 54.99it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:00, 55.10it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 53.49it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 54.94it/s]Training CobwebTree:  78%|  | 98/125 [00:01<00:00, 54.63it/s]Training CobwebTree:  83%| | 104/125 [00:01<00:00, 54.22it/s]Training CobwebTree:  88%| | 110/125 [00:01<00:00, 54.55it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 55.98it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 56.03it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 55.56it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:41,791 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:41,819 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:41,819 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:41.819911', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:41,821 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:44,100 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17727 virtual)
2025-12-23 08:55:44,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,181 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,181 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,189 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,198 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,202 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,212 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,213 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,246 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,388 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:44,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:44,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:45,527 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:45,633 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12256 virtual documents
2025-12-23 08:55:45,904 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:45,932 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:45,932 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:45.932321', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:45,934 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:48,330 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:55:48,332 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:55:48,333 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:55:48,334 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:55:48,335 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:55:48,337 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:55:48,339 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:55:48,340 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:55:48,342 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:55:48,344 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (44773 virtual)
2025-12-23 08:55:48,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,442 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:48,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,836 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:49,872 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:49,925 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 44775 virtual documents
2025-12-23 08:55:50,107 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:50,135 INFO gensim.corpora.dictionary: built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)
2025-12-23 08:55:50,135 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7749 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 625 documents (total 50398 corpus positions)", 'datetime': '2025-12-23T08:55:50.135860', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:56,449 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:58,549 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:58,584 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:55:58,584 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:55:58.584516', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:58,585 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:01,240 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:56:01,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,313 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,366 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,369 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,374 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,421 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,429 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,464 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,557 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:01,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:01,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,671 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:02,697 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15506 virtual documents
2025-12-23 08:56:02,799 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:02,833 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:02,834 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:02.834049', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:02,835 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:05,177 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:56:05,179 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:56:05,181 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:56:05,182 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:56:05,184 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:56:05,185 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:56:05,187 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:56:05,188 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:56:05,190 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:56:05,192 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:56:05,194 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:56:05,195 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (54964 virtual)
2025-12-23 08:56:05,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,256 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,269 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,269 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,573 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:05,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:05,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:06,669 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:06,709 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 54966 virtual documents
2025-12-23 08:56:06,799 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:06,833 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:06,833 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:06.833395', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:14,309 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:15,826 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:15,860 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:15,860 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:15.860843', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:15,861 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:18,075 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:56:18,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,162 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,189 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,340 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:18,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:18,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:19,509 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:19,554 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15506 virtual documents
2025-12-23 08:56:19,700 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:19,737 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:19,737 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:19.737882', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:19,739 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:22,072 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:56:22,074 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:56:22,075 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:56:22,077 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:56:22,078 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:56:22,080 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:56:22,081 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:56:22,083 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:56:22,084 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:56:22,087 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:56:22,089 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:56:22,090 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (54964 virtual)
2025-12-23 08:56:22,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,157 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,174 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,388 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,401 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,472 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:22,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:22,532 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:23,633 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:23,675 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 54966 virtual documents
2025-12-23 08:56:23,774 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:23,809 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:23,809 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:23.809092', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:31,343 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 58.39it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 52.46it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 52.42it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:01, 54.29it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 53.65it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 54.98it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 49.89it/s]Training CobwebTree:  38%|      | 48/125 [00:00<00:01, 52.38it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 53.05it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 52.98it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 54.13it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:00, 53.32it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:00, 54.49it/s]Training CobwebTree:  68%|   | 85/125 [00:01<00:00, 55.73it/s]Training CobwebTree:  73%|  | 91/125 [00:01<00:00, 55.98it/s]Training CobwebTree:  78%|  | 97/125 [00:01<00:00, 51.92it/s]Training CobwebTree:  82%| | 103/125 [00:01<00:00, 53.20it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 53.47it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 52.37it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 53.11it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 53.15it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:35,356 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:35,391 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:35,392 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:35.392025', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:35,394 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:37,778 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:56:37,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,889 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,905 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,268 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:38,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:39,697 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:39,779 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15506 virtual documents
2025-12-23 08:56:40,160 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:40,195 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:40,195 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:40.195481', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:40,198 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:42,648 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:56:42,650 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:56:42,651 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:56:42,653 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:56:42,655 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:56:42,656 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:56:42,658 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:56:42,660 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:56:42,661 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:56:42,663 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:56:42,665 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:56:42,666 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (54964 virtual)
2025-12-23 08:56:42,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,744 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,793 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,796 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,801 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,806 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,813 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,818 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:42,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,989 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:42,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,176 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:43,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:43,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:44,276 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:44,329 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 54966 virtual documents
2025-12-23 08:56:44,569 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:44,603 INFO gensim.corpora.dictionary: built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)
2025-12-23 08:56:44,603 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8883 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 750 documents (total 61714 corpus positions)", 'datetime': '2025-12-23T08:56:44.603770', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:52,144 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:54,261 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:54,301 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:56:54,301 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:56:54.301433', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:54,302 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:56,657 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:56:56,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,782 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,794 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,809 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,922 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,958 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,985 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:56,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:56,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:57,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:57,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:57,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:57,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:57,085 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:58,145 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:58,200 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17486 virtual documents
2025-12-23 08:56:58,336 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:58,376 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:56:58,376 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:56:58.376111', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:58,377 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:00,759 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:57:00,761 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:57:00,763 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:57:00,764 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:57:00,765 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:57:00,767 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:57:00,769 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:57:00,770 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:57:00,772 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:57:00,774 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:57:00,776 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:57:00,777 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:57:00,779 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:57:00,780 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (62748 virtual)
2025-12-23 08:57:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,861 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:00,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:00,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:01,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:01,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:02,339 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:02,368 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 62750 virtual documents
2025-12-23 08:57:02,482 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:02,521 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:02,521 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:02.521765', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:11,201 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:12,600 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:12,640 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:12,640 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:12.640931', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:12,642 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:15,256 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,328 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,332 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:15,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:15,652 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:16,759 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:16,807 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17486 virtual documents
2025-12-23 08:57:16,955 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:16,995 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:16,995 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:16.995193', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:16,996 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:19,417 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:57:19,419 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:57:19,420 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:57:19,422 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:57:19,424 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:57:19,425 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:57:19,427 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:57:19,429 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:57:19,430 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:57:19,432 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:57:19,434 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:57:19,436 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:57:19,437 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:57:19,438 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (62748 virtual)
2025-12-23 08:57:19,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,573 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,608 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,628 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,813 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,824 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,854 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,876 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:19,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:20,966 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:21,004 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 62750 virtual documents
2025-12-23 08:57:21,133 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:21,172 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:21,173 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:21.173000', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:29,912 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 56.22it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 53.81it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 51.77it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 48.95it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 51.08it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 51.36it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 49.38it/s]Training CobwebTree:  38%|      | 48/125 [00:00<00:01, 50.77it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 51.49it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 50.85it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 50.82it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 48.87it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:00, 48.78it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 48.55it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 47.12it/s]Training CobwebTree:  74%|  | 93/125 [00:01<00:00, 48.01it/s]Training CobwebTree:  79%|  | 99/125 [00:01<00:00, 49.45it/s]Training CobwebTree:  84%| | 105/125 [00:02<00:00, 51.75it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 51.37it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 48.23it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 48.70it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 49.77it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:33,925 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:33,970 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:33,970 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:33.970812', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:33,972 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:36,405 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:57:36,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,504 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,618 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,804 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:36,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:36,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:37,981 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:38,041 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17486 virtual documents
2025-12-23 08:57:38,262 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:38,302 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:38,302 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:38.302139', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:38,304 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:40,696 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:57:40,698 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:57:40,700 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:57:40,701 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:57:40,703 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:57:40,705 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:57:40,706 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:57:40,709 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:57:40,711 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:57:40,713 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:57:40,715 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:57:40,717 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:57:40,718 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:57:40,719 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (62748 virtual)
2025-12-23 08:57:40,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:40,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,809 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,814 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:41,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:41,329 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:42,310 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:42,368 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 62750 virtual documents
2025-12-23 08:57:42,544 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:42,583 INFO gensim.corpora.dictionary: built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)
2025-12-23 08:57:42,583 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9651 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 875 documents (total 70623 corpus positions)", 'datetime': '2025-12-23T08:57:42.583349', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:51,354 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:53,551 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:53,597 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:57:53,597 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:57:53.597176', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:53,598 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:56,277 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:57:56,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,382 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,383 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,402 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,406 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,421 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:56,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:56,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:57,760 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:57,801 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19665 virtual documents
2025-12-23 08:57:57,911 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:57,956 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:57:57,956 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:57:57.956426', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:57,957 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:00,343 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:58:00,345 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:58:00,346 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:58:00,347 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:58:00,349 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:58:00,350 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:58:00,352 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:58:00,353 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:58:00,355 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:58:00,357 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:58:00,359 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:58:00,360 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:58:00,362 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:58:00,363 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:58:00,365 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:58:00,366 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (71181 virtual)
2025-12-23 08:58:00,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,441 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,469 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,486 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,770 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,853 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,958 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:01,951 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:01,994 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71183 virtual documents
2025-12-23 08:58:02,084 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:02,129 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:02,129 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:02.129413', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:02,139 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:12,094 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:13,560 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:13,605 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:13,605 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:13.605227', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:13,606 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:15,955 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:58:16,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,082 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,084 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,084 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,086 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,094 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,096 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,121 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,141 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,154 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,174 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,446 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:17,501 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19665 virtual documents
2025-12-23 08:58:17,640 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:17,685 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:17,685 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:17.685616', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:17,686 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:20,013 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:58:20,015 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:58:20,016 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:58:20,017 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:58:20,018 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:58:20,019 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:58:20,020 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:58:20,022 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:58:20,023 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:58:20,026 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:58:20,027 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:58:20,029 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:58:20,030 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:58:20,032 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:58:20,033 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:58:20,035 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (71181 virtual)
2025-12-23 08:58:20,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,129 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,158 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,508 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:20,628 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:20,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:21,641 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:21,669 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71183 virtual documents
2025-12-23 08:58:21,769 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:21,814 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:21,814 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:21.814708', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:21,825 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:31,853 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 42.72it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 42.94it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 45.41it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:02, 48.01it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:01, 49.95it/s]Training CobwebTree:  26%|       | 32/125 [00:00<00:01, 48.62it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 48.35it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 47.57it/s]Training CobwebTree:  38%|      | 48/125 [00:01<00:01, 46.44it/s]Training CobwebTree:  42%|     | 53/125 [00:01<00:01, 44.89it/s]Training CobwebTree:  46%|     | 58/125 [00:01<00:01, 43.69it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 44.26it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 42.73it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 44.59it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:01, 45.62it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 46.13it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 45.43it/s]Training CobwebTree:  74%|  | 93/125 [00:02<00:00, 46.17it/s]Training CobwebTree:  79%|  | 99/125 [00:02<00:00, 47.60it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 47.74it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 48.10it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 45.72it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 46.68it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.71it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 46.49it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:36,116 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:36,162 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:36,162 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:36.162619', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:36,164 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:38,529 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:58:38,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,596 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:38,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:38,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:39,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:39,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:39,013 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:39,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:39,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:40,099 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:40,184 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19665 virtual documents
2025-12-23 08:58:40,396 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:40,441 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:40,441 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:40.441483', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:40,443 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:42,785 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:58:42,788 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:58:42,789 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:58:42,790 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:58:42,792 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:58:42,794 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:58:42,795 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:58:42,797 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:58:42,799 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:58:42,801 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:58:42,803 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:58:42,804 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:58:42,806 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:58:42,807 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:58:42,809 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:58:42,810 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (71181 virtual)
2025-12-23 08:58:42,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,872 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:42,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,917 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,922 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,932 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,937 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:42,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,062 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,225 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,240 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,284 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,316 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,380 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:44,813 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:44,862 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 71183 virtual documents
2025-12-23 08:58:45,009 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:45,053 INFO gensim.corpora.dictionary: built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)
2025-12-23 08:58:45,053 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10339 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1000 documents (total 80181 corpus positions)", 'datetime': '2025-12-23T08:58:45.053262', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:45,064 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:55,100 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:57,400 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:57,453 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:58:57,453 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:58:57.453916', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:57,455 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:59,853 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:58:59,862 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 08:58:59,864 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 08:58:59,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:59,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:59,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:01,454 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:01,497 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 24265 virtual documents
2025-12-23 08:59:01,621 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:01,673 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:01,673 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:01.673924', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:01,675 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:03,999 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:59:04,001 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:59:04,002 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:59:04,002 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:59:04,004 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:59:04,006 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:59:04,008 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:59:04,010 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:59:04,012 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:59:04,014 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:59:04,016 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:59:04,017 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:59:04,019 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:59:04,020 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:59:04,021 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:59:04,023 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 08:59:04,026 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 08:59:04,027 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (84976 virtual)
2025-12-23 08:59:04,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,078 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,098 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,113 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,376 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,602 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:04,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:04,749 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:05,683 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:05,765 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 84978 virtual documents
2025-12-23 08:59:05,862 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:05,915 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:05,915 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:05.915382', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:05,925 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:17,252 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:18,938 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:18,993 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:18,993 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:18.993314', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:18,994 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:21,259 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:59:21,268 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 08:59:21,271 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 08:59:21,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,442 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,458 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,720 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:21,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:21,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:22,919 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:22,945 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 24265 virtual documents
2025-12-23 08:59:23,085 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:23,137 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:23,137 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:23.137806', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:23,139 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:25,557 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:59:25,559 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:59:25,560 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:59:25,562 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:59:25,563 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:59:25,565 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:59:25,566 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:59:25,568 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:59:25,570 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:59:25,572 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:59:25,574 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:59:25,575 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:59:25,577 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:59:25,578 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:59:25,580 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:59:25,582 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 08:59:25,584 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 08:59:25,585 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (84976 virtual)
2025-12-23 08:59:25,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,898 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:25,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:25,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,062 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,080 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,108 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,134 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,146 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:26,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:26,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:27,347 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:27,382 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 84978 virtual documents
2025-12-23 08:59:27,494 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:27,546 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:27,547 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:27.547070', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:27,558 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:38,946 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 55.73it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 52.11it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 51.40it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 49.22it/s]Training CobwebTree:  23%|       | 29/125 [00:00<00:02, 46.64it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:01, 49.50it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 49.90it/s]Training CobwebTree:  38%|      | 47/125 [00:00<00:01, 49.20it/s]Training CobwebTree:  42%|     | 53/125 [00:01<00:01, 50.09it/s]Training CobwebTree:  47%|     | 59/125 [00:01<00:01, 49.13it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 51.22it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 51.47it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 47.83it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 48.63it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 48.64it/s]Training CobwebTree:  74%|  | 93/125 [00:01<00:00, 47.61it/s]Training CobwebTree:  78%|  | 98/125 [00:01<00:00, 47.43it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 46.02it/s]Training CobwebTree:  86%| | 108/125 [00:02<00:00, 45.55it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 47.76it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 49.52it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 46.94it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.62it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:43,320 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:43,374 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:43,374 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:43.374621', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:43,376 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:45,841 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 08:59:45,851 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 08:59:45,853 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 08:59:45,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,933 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,933 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,933 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,936 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,937 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,939 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:45,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:45,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,029 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,034 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,068 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,322 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,376 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,376 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,498 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:47,969 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:48,020 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 24265 virtual documents
2025-12-23 08:59:48,261 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:48,314 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:48,314 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:48.314817', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:48,317 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:50,738 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 08:59:50,740 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 08:59:50,741 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 08:59:50,743 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 08:59:50,745 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 08:59:50,746 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 08:59:50,748 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 08:59:50,749 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 08:59:50,751 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 08:59:50,753 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 08:59:50,755 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 08:59:50,756 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 08:59:50,758 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 08:59:50,760 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 08:59:50,761 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 08:59:50,763 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 08:59:50,766 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 08:59:50,767 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (84976 virtual)
2025-12-23 08:59:50,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:50,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,914 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,916 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,921 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:50,946 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,344 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,345 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:51,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:51,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:52,572 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:52,647 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 84978 virtual documents
2025-12-23 08:59:52,810 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:52,862 INFO gensim.corpora.dictionary: built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)
2025-12-23 08:59:52,863 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11238 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1125 documents (total 95101 corpus positions)", 'datetime': '2025-12-23T08:59:52.863048', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:52,874 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:04,271 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:06,517 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:06,575 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:06,575 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:06.575684', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:06,576 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:08,926 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:00:08,935 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:00:08,937 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:00:08,941 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-31002 virtual)
2025-12-23 09:00:09,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,100 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,110 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,111 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,113 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,120 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,137 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,157 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:09,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:09,392 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:10,598 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:10,665 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 26801 virtual documents
2025-12-23 09:00:10,791 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:10,849 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:10,850 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:10.850049', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:10,851 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:13,255 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:00:13,257 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:00:13,258 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:00:13,260 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:00:13,262 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:00:13,263 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:00:13,265 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:00:13,266 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:00:13,268 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:00:13,270 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:00:13,272 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:00:13,274 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:00:13,275 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:00:13,277 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:00:13,278 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:00:13,280 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:00:13,283 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:00:13,284 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:00:13,286 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:00:13,287 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (93998 virtual)
2025-12-23 09:00:13,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,408 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,676 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,784 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,805 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,896 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,949 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,950 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:13,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:13,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:15,034 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:15,112 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 94000 virtual documents
2025-12-23 09:00:15,217 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:15,276 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:15,276 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:15.276348', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:15,286 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:28,041 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:29,604 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:29,664 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:29,664 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:29.664684', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:29,666 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:32,052 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:00:32,061 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:00:32,063 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:00:32,067 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-31002 virtual)
2025-12-23 09:00:32,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,221 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:32,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:33,737 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:33,799 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 26801 virtual documents
2025-12-23 09:00:33,974 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:34,032 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:34,032 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:34.032837', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:34,034 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:36,571 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:00:36,573 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:00:36,575 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:00:36,577 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:00:36,578 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:00:36,580 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:00:36,581 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:00:36,583 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:00:36,585 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:00:36,587 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:00:36,589 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:00:36,590 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:00:36,592 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:00:36,593 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:00:36,595 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:00:36,612 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:00:36,615 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:00:36,617 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:00:36,618 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:00:36,619 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (93998 virtual)
2025-12-23 09:00:36,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:36,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,989 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,058 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:37,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:37,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:38,765 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:38,797 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 94000 virtual documents
2025-12-23 09:00:38,923 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:38,981 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:38,981 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:38.981945', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:38,992 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:51,796 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 46.05it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 43.12it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 43.34it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 42.82it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 42.58it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 43.25it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 44.20it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 46.58it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:01, 47.09it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 47.89it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 47.51it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 42.61it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 44.05it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 45.25it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 45.92it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 47.64it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 47.89it/s]Training CobwebTree:  74%|  | 93/125 [00:02<00:00, 46.33it/s]Training CobwebTree:  78%|  | 98/125 [00:02<00:00, 46.11it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 45.67it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 47.56it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 48.03it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 47.71it/s]Training CobwebTree:  99%|| 124/125 [00:02<00:00, 46.59it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 45.91it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:56,209 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:56,268 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:00:56,268 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:00:56.268528', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:56,270 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:58,707 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:00:58,716 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:00:58,718 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:00:58,722 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-31002 virtual)
2025-12-23 09:00:58,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,908 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,909 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:58,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:58,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,184 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,258 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,325 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:59,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:59,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:00,584 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:00,634 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 26801 virtual documents
2025-12-23 09:01:00,892 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:00,954 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:01:00,954 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:01:00.954347', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:00,956 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:03,401 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:01:03,404 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:01:03,405 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:01:03,407 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:01:03,408 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:01:03,410 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:01:03,412 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:01:03,413 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:01:03,415 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:01:03,417 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:01:03,419 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:01:03,420 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:01:03,422 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:01:03,423 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:01:03,425 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:01:03,427 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:01:03,430 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:01:03,432 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:01:03,433 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:01:03,434 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (93998 virtual)
2025-12-23 09:01:03,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,940 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,977 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:03,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:03,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,009 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,129 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:04,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:04,212 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:05,323 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:05,397 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 94000 virtual documents
2025-12-23 09:01:05,577 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:05,636 INFO gensim.corpora.dictionary: built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)
2025-12-23 09:01:05,636 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11821 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1250 documents (total 105248 corpus positions)", 'datetime': '2025-12-23T09:01:05.636194', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:05,648 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:18,496 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:20,761 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:20,826 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:20,826 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:20.826786', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:20,827 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:23,296 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:01:23,305 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:01:23,308 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:01:23,312 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:01:23,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,456 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,480 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,669 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:24,980 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:25,040 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30741 virtual documents
2025-12-23 09:01:25,145 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:25,210 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:25,210 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:25.210527', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:25,211 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:27,664 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:01:27,666 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:01:27,667 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:01:27,669 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:01:27,670 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:01:27,672 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:01:27,673 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:01:27,675 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:01:27,677 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:01:27,679 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:01:27,681 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:01:27,682 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:01:27,684 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:01:27,685 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:01:27,687 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:01:27,689 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:01:27,691 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:01:27,693 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:01:27,694 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:01:27,696 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:01:27,698 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:01:27,699 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (105789 virtual)
2025-12-23 09:01:27,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,776 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,777 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,778 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:27,781 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:27,989 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,189 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,198 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,209 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:28,416 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:28,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:29,530 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:29,556 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 105791 virtual documents
2025-12-23 09:01:29,649 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:29,714 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:29,714 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:29.714729', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:29,724 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:43,804 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:45,348 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:45,415 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:45,416 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:45.415989', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:45,417 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:47,794 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:01:47,803 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:01:47,805 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:01:47,810 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:01:47,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,889 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,987 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:47,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:47,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,224 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,364 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:48,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:48,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:49,904 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:49,934 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30741 virtual documents
2025-12-23 09:01:50,068 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:50,134 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:50,134 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:50.134436', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:50,136 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:52,568 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:01:52,570 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:01:52,571 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:01:52,573 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:01:52,574 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:01:52,575 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:01:52,577 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:01:52,579 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:01:52,580 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:01:52,582 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:01:52,584 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:01:52,586 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:01:52,587 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:01:52,589 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:01:52,590 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:01:52,592 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:01:52,594 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:01:52,596 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:01:52,598 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:01:52,600 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:01:52,602 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:01:52,603 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (105789 virtual)
2025-12-23 09:01:52,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:52,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:52,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,143 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,285 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:53,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:53,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:54,459 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:54,510 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 105791 virtual documents
2025-12-23 09:01:54,630 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:54,695 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:01:54,695 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:01:54.695650', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:54,706 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:08,855 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 40.31it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 44.27it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 46.82it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:02, 46.98it/s]Training CobwebTree:  21%|        | 26/125 [00:00<00:02, 46.43it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:02, 46.49it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:02, 44.17it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 42.59it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:02, 37.00it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 40.04it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 41.64it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 43.78it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 44.67it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 45.00it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 45.20it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 46.86it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 47.70it/s]Training CobwebTree:  75%|  | 94/125 [00:02<00:00, 49.33it/s]Training CobwebTree:  79%|  | 99/125 [00:02<00:00, 48.27it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 46.15it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 48.24it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 47.83it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 47.85it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.42it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 45.55it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:13,278 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:13,344 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:02:13,344 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:02:13.344826', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:13,346 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:15,822 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:02:15,832 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:02:15,834 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:02:15,839 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:02:15,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:15,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,983 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,983 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,985 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:15,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:15,998 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:15,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:15,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,028 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,344 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:16,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:16,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,750 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:17,815 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 30741 virtual documents
2025-12-23 09:02:18,087 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:18,152 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:02:18,152 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:02:18.152346', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:18,154 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:20,595 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:02:20,597 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:02:20,599 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:02:20,601 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:02:20,602 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:02:20,604 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:02:20,606 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:02:20,607 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:02:20,609 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:02:20,611 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:02:20,613 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:02:20,615 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:02:20,616 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:02:20,618 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:02:20,619 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:02:20,622 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:02:20,624 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:02:20,626 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:02:20,627 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:02:20,630 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:02:20,632 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:02:20,633 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (105789 virtual)
2025-12-23 09:02:20,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:20,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:20,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,180 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,210 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,248 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:21,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:21,506 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:22,596 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:22,650 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 105791 virtual documents
2025-12-23 09:02:22,851 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:22,917 INFO gensim.corpora.dictionary: built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)
2025-12-23 09:02:22,917 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12583 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1375 documents (total 118164 corpus positions)", 'datetime': '2025-12-23T09:02:22.917458', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:22,929 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:37,087 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:39,293 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:39,364 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:02:39,365 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:02:39.365017', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:39,366 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:41,990 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:02:41,999 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:02:42,001 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:02:42,005 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:02:42,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,140 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,358 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,362 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,377 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,442 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:42,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:42,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:43,723 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:43,780 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 32170 virtual documents
2025-12-23 09:02:43,897 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:43,967 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:02:43,968 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:02:43.967988', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:43,969 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:46,389 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:02:46,391 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:02:46,392 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:02:46,394 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:02:46,395 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:02:46,397 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:02:46,398 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:02:46,400 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:02:46,401 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:02:46,403 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:02:46,405 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:02:46,407 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:02:46,408 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:02:46,410 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:02:46,411 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:02:46,413 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:02:46,415 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:02:46,417 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:02:46,418 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:02:46,420 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:02:46,422 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:02:46,424 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:02:46,425 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:02:46,426 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (113217 virtual)
2025-12-23 09:02:46,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,560 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,794 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,812 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,813 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:46,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,982 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,984 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,994 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:46,986 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,045 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,105 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,128 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,145 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:47,170 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:47,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:48,275 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:48,304 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 113219 virtual documents
2025-12-23 09:02:48,432 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:48,502 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:02:48,502 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:02:48.502653', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:48,513 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:03,833 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:05,280 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:05,350 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:05,350 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:05.350244', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:05,351 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:07,790 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:03:07,800 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:03:07,802 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:03:07,807 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:03:07,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:07,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,964 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:07,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,096 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,200 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:09,619 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:09,652 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 32170 virtual documents
2025-12-23 09:03:09,790 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:09,860 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:09,861 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:09.861094', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:09,862 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:12,330 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:03:12,332 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:03:12,334 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:03:12,335 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:03:12,337 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:03:12,338 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:03:12,340 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:03:12,342 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:03:12,343 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:03:12,346 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:03:12,347 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:03:12,349 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:03:12,351 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:03:12,352 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:03:12,354 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:03:12,356 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:03:12,358 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:03:12,360 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:03:12,361 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:03:12,364 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:03:12,366 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:03:12,367 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:03:12,369 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:03:12,370 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (113217 virtual)
2025-12-23 09:03:12,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,993 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,069 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:13,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:14,295 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:14,325 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 113219 virtual documents
2025-12-23 09:03:14,445 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:14,515 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:14,515 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:14.515718', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:14,526 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:29,920 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 47.98it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 48.26it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 52.26it/s]Training CobwebTree:  18%|        | 22/125 [00:00<00:02, 47.09it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:02, 47.56it/s]Training CobwebTree:  26%|       | 32/125 [00:00<00:01, 47.48it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 44.99it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 45.96it/s]Training CobwebTree:  38%|      | 47/125 [00:01<00:01, 45.26it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 44.72it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 42.92it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 47.45it/s]Training CobwebTree:  55%|    | 69/125 [00:01<00:01, 49.92it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:00, 51.45it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 49.79it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 48.64it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 45.55it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 45.95it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 48.81it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 50.55it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 49.22it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 48.14it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.51it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 47.75it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:34,104 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:34,174 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:34,174 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:34.174625', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:34,176 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:36,547 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:03:36,556 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:03:36,558 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:03:36,563 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:03:36,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,736 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,770 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,785 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,786 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,790 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,805 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:36,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,948 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:36,999 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,078 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,089 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,093 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,264 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:37,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:37,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:38,493 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:38,531 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 32170 virtual documents
2025-12-23 09:03:38,761 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:38,831 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:38,831 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:38.831568', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:38,833 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:41,528 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:03:41,531 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:03:41,533 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:03:41,535 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:03:41,536 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:03:41,538 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:03:41,540 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:03:41,541 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:03:41,543 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:03:41,545 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:03:41,547 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:03:41,548 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:03:41,550 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:03:41,551 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:03:41,553 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:03:41,555 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:03:41,557 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:03:41,559 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:03:41,561 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:03:41,563 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:03:41,565 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:03:41,567 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:03:41,569 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:03:41,569 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (113217 virtual)
2025-12-23 09:03:41,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:41,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:41,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,308 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,320 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,406 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:42,481 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:42,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:43,682 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:43,717 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 113219 virtual documents
2025-12-23 09:03:43,888 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:43,959 INFO gensim.corpora.dictionary: built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)
2025-12-23 09:03:43,959 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13051 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1500 documents (total 126717 corpus positions)", 'datetime': '2025-12-23T09:03:43.959268', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:43,970 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:59,370 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:01,499 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:01,576 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:01,576 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:01.576493', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:01,577 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:03,952 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:04:03,961 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:04:03,963 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:04:03,968 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:04:04,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,045 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,045 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,048 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,050 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,051 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,237 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,392 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,393 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,397 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,561 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,605 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:05,733 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:05,769 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 34160 virtual documents
2025-12-23 09:04:05,905 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:05,981 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:05,982 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:05.982032', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:05,983 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:08,496 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:04:08,498 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:04:08,499 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:04:08,500 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:04:08,502 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:04:08,504 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:04:08,506 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:04:08,507 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:04:08,509 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:04:08,511 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:04:08,513 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:04:08,515 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:04:08,516 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:04:08,518 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:04:08,519 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:04:08,521 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:04:08,524 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:04:08,525 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:04:08,527 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:04:08,529 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:04:08,531 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:04:08,532 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:04:08,534 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:04:08,535 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:04:08,537 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:04:08,538 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (121152 virtual)
2025-12-23 09:04:08,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,641 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:08,965 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,081 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,142 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:09,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:09,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:10,468 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:10,496 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 121154 virtual documents
2025-12-23 09:04:10,602 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:10,678 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:10,678 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:10.678578', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:10,689 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:27,096 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:28,489 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:28,571 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:28,572 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:28.572087', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:28,573 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:31,019 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:04:31,028 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:04:31,030 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:04:31,035 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:04:31,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,230 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:31,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:31,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:32,819 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:32,872 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 34160 virtual documents
2025-12-23 09:04:33,018 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:33,094 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:33,094 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:33.094801', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:33,096 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:35,416 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:04:35,418 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:04:35,419 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:04:35,421 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:04:35,422 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:04:35,424 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:04:35,426 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:04:35,427 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:04:35,429 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:04:35,431 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:04:35,433 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:04:35,435 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:04:35,436 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:04:35,438 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:04:35,439 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:04:35,442 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:04:35,444 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:04:35,445 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:04:35,447 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:04:35,449 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:04:35,464 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:04:35,466 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:04:35,467 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:04:35,469 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:04:35,470 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:04:35,471 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (121152 virtual)
2025-12-23 09:04:35,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:35,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:35,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,114 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,153 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,281 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:36,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:36,325 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:37,374 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:37,406 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 121154 virtual documents
2025-12-23 09:04:37,541 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:37,616 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:37,617 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:37.617119', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:37,627 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:54,142 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 4/125 [00:00<00:03, 39.79it/s]Training CobwebTree:   7%|         | 9/125 [00:00<00:02, 45.68it/s]Training CobwebTree:  11%|         | 14/125 [00:00<00:02, 44.59it/s]Training CobwebTree:  15%|        | 19/125 [00:00<00:02, 44.86it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:02, 44.82it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 48.05it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 49.22it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 48.89it/s]Training CobwebTree:  37%|      | 46/125 [00:00<00:01, 45.13it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 45.78it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 45.90it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 45.25it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 45.03it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 45.68it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:00, 48.07it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 45.96it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 46.14it/s]Training CobwebTree:  74%|  | 93/125 [00:02<00:00, 46.98it/s]Training CobwebTree:  78%|  | 98/125 [00:02<00:00, 46.50it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 46.27it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 47.50it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 47.23it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 46.66it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 47.21it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 46.46it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:58,341 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:58,423 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:04:58,424 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:04:58.424092', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:58,426 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:00,817 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:05:00,826 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:05:00,828 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:05:00,834 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:05:00,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:00,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:00,988 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,402 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:01,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:01,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:03,279 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:03,332 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 34160 virtual documents
2025-12-23 09:05:03,613 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:03,688 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:05:03,688 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:05:03.688826', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:03,691 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:06,104 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:05:06,106 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:05:06,107 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:05:06,109 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:05:06,110 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:05:06,111 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:05:06,112 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:05:06,113 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:05:06,114 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:05:06,115 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:05:06,117 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:05:06,118 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:05:06,119 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:05:06,120 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:05:06,122 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:05:06,125 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:05:06,127 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:05:06,129 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:05:06,130 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:05:06,133 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:05:06,135 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:05:06,137 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:05:06,138 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:05:06,140 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:05:06,142 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:05:06,142 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (121152 virtual)
2025-12-23 09:05:06,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,773 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,817 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,845 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,877 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,889 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:06,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:07,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:07,020 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:07,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:07,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:07,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:07,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:07,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:07,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:07,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:07,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:08,285 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:08,339 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 121154 virtual documents
2025-12-23 09:05:08,555 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:08,629 INFO gensim.corpora.dictionary: built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)
2025-12-23 09:05:08,629 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<13478 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1625 documents (total 135777 corpus positions)", 'datetime': '2025-12-23T09:05:08.629693', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:08,642 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:25,127 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:27,567 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:27,652 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:05:27,653 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:05:27.653027', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:27,654 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:30,079 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:05:30,087 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:05:30,090 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:05:30,095 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:05:30,103 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:05:30,104 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-40528 virtual)
2025-12-23 09:05:30,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,372 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,457 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,470 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:30,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:30,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:31,927 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:31,961 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 38808 virtual documents
2025-12-23 09:05:32,074 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:32,157 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:05:32,157 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:05:32.157403', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:32,158 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:34,527 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:05:34,529 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:05:34,530 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:05:34,531 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:05:34,533 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:05:34,535 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:05:34,537 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:05:34,538 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:05:34,540 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:05:34,542 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:05:34,544 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:05:34,546 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:05:34,547 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:05:34,549 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:05:34,550 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:05:34,552 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:05:34,555 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:05:34,556 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:05:34,558 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:05:34,561 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:05:34,563 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:05:34,564 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:05:34,566 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:05:34,567 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:05:34,569 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:05:34,571 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:05:34,573 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:05:34,574 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (134472 virtual)
2025-12-23 09:05:34,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,761 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,766 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,781 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:34,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:34,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,115 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,141 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,220 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,221 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:35,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:35,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:36,554 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:36,595 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134474 virtual documents
2025-12-23 09:05:36,691 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:36,774 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:05:36,774 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:05:36.774595', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:36,785 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:54,809 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:56,452 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:56,537 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:05:56,537 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:05:56.537434', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:56,539 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:58,919 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:05:58,928 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:05:58,930 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:05:58,935 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:05:58,945 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:05:58,946 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-40528 virtual)
2025-12-23 09:05:59,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,393 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,585 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,608 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:59,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,672 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:59,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:00,861 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:00,894 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 38808 virtual documents
2025-12-23 09:06:01,046 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:01,129 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:06:01,129 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:06:01.129704', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:01,131 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:03,598 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:06:03,600 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:06:03,601 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:06:03,602 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:06:03,604 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:06:03,605 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:06:03,606 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:06:03,607 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:06:03,608 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:06:03,609 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:06:03,610 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:06:03,611 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:06:03,612 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:06:03,613 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:06:03,614 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:06:03,615 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:06:03,616 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:06:03,617 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:06:03,618 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:06:03,620 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:06:03,621 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:06:03,622 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:06:03,623 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:06:03,623 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:06:03,624 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:06:03,625 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:06:03,627 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:06:03,628 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (134472 virtual)
2025-12-23 09:06:03,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:03,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,113 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,114 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,498 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,617 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,622 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:04,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:05,987 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:06,028 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134474 virtual documents
2025-12-23 09:06:06,169 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:06,250 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:06:06,251 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:06:06.251069', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:06,261 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:24,370 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 43.00it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 43.14it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 42.48it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 39.54it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 41.77it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 43.26it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 42.54it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 44.04it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 43.96it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 45.43it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 43.22it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 44.81it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 45.86it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 44.79it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 43.57it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 43.73it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 43.84it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 43.39it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 42.31it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 43.51it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 42.08it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 40.75it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 41.72it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 42.27it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 43.14it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:29,041 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:29,126 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:06:29,126 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:06:29.126585', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:29,128 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:31,601 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:06:31,611 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:06:31,613 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:06:31,618 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:06:31,630 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:06:31,631 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-40528 virtual)
2025-12-23 09:06:31,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,806 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:31,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:31,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,381 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:32,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:32,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:33,734 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:33,796 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 38808 virtual documents
2025-12-23 09:06:34,073 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:34,156 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:06:34,156 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:06:34.156332', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:34,159 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:36,538 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:06:36,541 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:06:36,544 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:06:36,546 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:06:36,549 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:06:36,550 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:06:36,552 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:06:36,554 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:06:36,556 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:06:36,558 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:06:36,560 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:06:36,561 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:06:36,563 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:06:36,565 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:06:36,566 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:06:36,569 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:06:36,571 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:06:36,573 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:06:36,575 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:06:36,577 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:06:36,579 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:06:36,581 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:06:36,583 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:06:36,584 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:06:36,586 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:06:36,588 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:06:36,591 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:06:36,592 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (134472 virtual)
2025-12-23 09:06:36,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,693 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,694 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:36,710 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:36,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,329 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,334 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,366 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:37,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:37,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:38,758 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:38,806 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 134474 virtual documents
2025-12-23 09:06:38,992 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:39,073 INFO gensim.corpora.dictionary: built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)
2025-12-23 09:06:39,073 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14143 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1750 documents (total 150222 corpus positions)", 'datetime': '2025-12-23T09:06:39.073914', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:39,086 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:57,162 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:59,648 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:59,738 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:06:59,738 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:06:59.738667', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:59,740 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:02,192 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:07:02,201 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:07:02,203 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:07:02,208 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:07:02,217 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:07:02,219 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-39916 virtual)
2025-12-23 09:07:02,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,661 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,734 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,781 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,805 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:02,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:02,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,090 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:04,121 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 41393 virtual documents
2025-12-23 09:07:04,265 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:04,353 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:07:04,354 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:07:04.354012', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:04,355 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:06,848 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:07:06,851 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:07:06,853 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:07:06,855 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:07:06,857 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:07:06,859 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:07:06,861 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:07:06,862 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:07:06,864 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:07:06,866 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:07:06,868 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:07:06,870 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:07:06,871 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:07:06,873 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:07:06,875 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:07:06,877 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:07:06,879 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:07:06,881 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:07:06,882 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:07:06,885 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:07:06,887 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:07:06,888 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:07:06,890 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:07:06,891 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:07:06,893 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:07:06,895 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:07:06,897 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:07:06,899 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (139284 virtual)
2025-12-23 09:07:06,901 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (143030 virtual)
2025-12-23 09:07:06,902 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (143809 virtual)
2025-12-23 09:07:06,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:06,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:06,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:07,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:07,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,991 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:09,021 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 143811 virtual documents
2025-12-23 09:07:09,127 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:09,215 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:07:09,215 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:07:09.215220', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:09,226 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:28,487 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:30,137 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:30,227 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:07:30,227 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:07:30.227771', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:30,229 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:33,101 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:07:33,110 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:07:33,113 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:07:33,118 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:07:33,129 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:07:33,131 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-39916 virtual)
2025-12-23 09:07:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,788 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:33,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:35,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:35,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:35,851 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:35,885 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 41393 virtual documents
2025-12-23 09:07:36,036 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:36,124 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:07:36,124 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:07:36.124628', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:36,126 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:38,487 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:07:38,490 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:07:38,492 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:07:38,494 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:07:38,496 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:07:38,498 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:07:38,500 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:07:38,501 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:07:38,503 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:07:38,505 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:07:38,507 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:07:38,509 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:07:38,510 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:07:38,512 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:07:38,513 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:07:38,516 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:07:38,518 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:07:38,520 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:07:38,522 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:07:38,524 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:07:38,527 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:07:38,528 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:07:38,530 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:07:38,531 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:07:38,533 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:07:38,535 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:07:38,538 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:07:38,540 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (139284 virtual)
2025-12-23 09:07:38,542 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (143030 virtual)
2025-12-23 09:07:38,543 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (143809 virtual)
2025-12-23 09:07:38,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:38,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:38,991 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,144 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,345 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,401 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,421 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:39,440 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,441 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:39,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:40,599 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:40,649 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 143811 virtual documents
2025-12-23 09:07:40,761 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:40,849 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:07:40,849 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:07:40.849697', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:40,860 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:00,157 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 41.34it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 40.08it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 40.57it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 42.07it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 43.75it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 42.41it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 44.48it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 43.24it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 43.04it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 44.09it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 42.42it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 43.76it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 41.70it/s]Training CobwebTree:  56%|    | 70/125 [00:01<00:01, 40.35it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:01, 41.63it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:01, 41.31it/s]Training CobwebTree:  68%|   | 85/125 [00:02<00:00, 42.27it/s]Training CobwebTree:  72%|  | 90/125 [00:02<00:00, 43.73it/s]Training CobwebTree:  76%|  | 95/125 [00:02<00:00, 44.61it/s]Training CobwebTree:  80%|  | 100/125 [00:02<00:00, 45.49it/s]Training CobwebTree:  84%| | 105/125 [00:02<00:00, 44.13it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 43.24it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 42.50it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 40.45it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 41.03it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 42.45it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:04,880 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:04,970 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:08:04,970 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:08:04.970914', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:04,972 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:07,450 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:08:07,459 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:08:07,461 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:08:07,467 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:08:07,478 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:08:07,481 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-39916 virtual)
2025-12-23 09:08:07,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,621 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,812 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,812 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,941 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:07,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:07,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,138 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,394 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,394 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:09,580 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:09,673 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 41393 virtual documents
2025-12-23 09:08:09,923 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:10,011 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:08:10,011 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:08:10.011900', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:10,014 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:12,525 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:08:12,528 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:08:12,530 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:08:12,532 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:08:12,534 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:08:12,536 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:08:12,537 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:08:12,539 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:08:12,541 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:08:12,543 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:08:12,545 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:08:12,547 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:08:12,548 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:08:12,550 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:08:12,552 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:08:12,554 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:08:12,557 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:08:12,559 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:08:12,576 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:08:12,579 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:08:12,581 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:08:12,582 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:08:12,583 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:08:12,584 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:08:12,586 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:08:12,588 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:08:12,590 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:08:12,605 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (139284 virtual)
2025-12-23 09:08:12,607 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (143030 virtual)
2025-12-23 09:08:12,608 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (143809 virtual)
2025-12-23 09:08:12,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,213 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,329 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,337 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,424 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,501 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:13,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:14,803 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:14,851 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 143811 virtual documents
2025-12-23 09:08:15,033 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:15,120 INFO gensim.corpora.dictionary: built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)
2025-12-23 09:08:15,120 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14580 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 1875 documents (total 160684 corpus positions)", 'datetime': '2025-12-23T09:08:15.120572', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:15,133 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:34,424 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:36,647 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:36,741 INFO gensim.corpora.dictionary: built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)
2025-12-23 09:08:36,741 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)", 'datetime': '2025-12-23T09:08:36.741755', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:36,743 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:39,568 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:08:39,577 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:08:39,580 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:08:39,585 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:08:39,596 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:08:39,598 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-39916 virtual)
2025-12-23 09:08:39,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,779 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,797 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,812 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:39,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:39,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,124 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,198 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:40,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:40,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:41,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:41,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:42,213 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:42,244 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 42069 virtual documents
2025-12-23 09:08:42,386 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:42,478 INFO gensim.corpora.dictionary: built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)
2025-12-23 09:08:42,478 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)", 'datetime': '2025-12-23T09:08:42.478685', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:42,480 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:44,846 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (5556 virtual)
2025-12-23 09:08:44,849 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (10971 virtual)
2025-12-23 09:08:44,851 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (14698 virtual)
2025-12-23 09:08:44,853 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (18499 virtual)
2025-12-23 09:08:44,854 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (22872 virtual)
2025-12-23 09:08:44,855 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (27204 virtual)
2025-12-23 09:08:44,857 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (31765 virtual)
2025-12-23 09:08:44,859 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (35619 virtual)
2025-12-23 09:08:44,860 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (39618 virtual)
2025-12-23 09:08:44,862 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (46536 virtual)
2025-12-23 09:08:44,864 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (51793 virtual)
2025-12-23 09:08:44,866 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (55663 virtual)
2025-12-23 09:08:44,868 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (59576 virtual)
2025-12-23 09:08:44,869 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (63650 virtual)
2025-12-23 09:08:44,871 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (67606 virtual)
2025-12-23 09:08:44,873 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (74513 virtual)
2025-12-23 09:08:44,876 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (81709 virtual)
2025-12-23 09:08:44,878 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (86813 virtual)
2025-12-23 09:08:44,879 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (90000 virtual)
2025-12-23 09:08:44,881 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (97609 virtual)
2025-12-23 09:08:44,883 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (103934 virtual)
2025-12-23 09:08:44,884 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (107748 virtual)
2025-12-23 09:08:44,886 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (111880 virtual)
2025-12-23 09:08:44,887 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (115260 virtual)
2025-12-23 09:08:44,889 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (119303 virtual)
2025-12-23 09:08:44,890 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (124697 virtual)
2025-12-23 09:08:44,893 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (131764 virtual)
2025-12-23 09:08:44,895 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (139284 virtual)
2025-12-23 09:08:44,897 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (143030 virtual)
2025-12-23 09:08:44,898 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (145948 virtual)
2025-12-23 09:08:44,916 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (149037 virtual)
2025-12-23 09:08:44,917 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (149707 virtual)
2025-12-23 09:08:44,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:44,982 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,994 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:44,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,117 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,593 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:45,832 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:45,853 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:46,915 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:46,945 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 149709 virtual documents
2025-12-23 09:08:47,065 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:47,157 INFO gensim.corpora.dictionary: built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)
2025-12-23 09:08:47,157 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)", 'datetime': '2025-12-23T09:08:47.157661', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:47,168 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:47,177 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:09:07,739 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:09:09,167 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:09:09,261 INFO gensim.corpora.dictionary: built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)
2025-12-23 09:09:09,261 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)", 'datetime': '2025-12-23T09:09:09.261908', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:09:09,263 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:09:11,656 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (-17464 virtual)
2025-12-23 09:09:11,665 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (-27887 virtual)
2025-12-23 09:09:11,668 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (-27091 virtual)
2025-12-23 09:09:11,674 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (-30391 virtual)
2025-12-23 09:09:11,685 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (-41036 virtual)
2025-12-23 09:09:11,687 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (-39916 virtual)
2025-12-23 09:09:11,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,896 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,899 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,938 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:11,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:11,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,002 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,109 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,236 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,345 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,365 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:09:12,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:12,494 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:09:13,667 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:09:13,719 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 42069 virtual documents
2025-12-23 09:09:13,881 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:09:13,973 INFO gensim.corpora.dictionary: built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)
2025-12-23 09:09:13,973 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<14846 unique tokens: ['acquired', 'acrylic', 'affiliate', 'allow', 'arco']...> from 2000 documents (total 167707 corpus positions)", 'datetime': '2025-12-23T09:09:13.973690', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:09:13,975 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
