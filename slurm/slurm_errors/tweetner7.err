2025-12-23 08:53:45,115 INFO __main__: Starting incremental benchmark for dataset=tweetner7
2025-12-23 08:53:48,019 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:53:48,083 INFO gensim.corpora.dictionary: built Dictionary<18595 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 5000 documents (total 81653 corpus positions)
2025-12-23 08:53:48,086 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<18595 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 5000 documents (total 81653 corpus positions)", 'datetime': '2025-12-23T08:53:48.084086', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:53:49,393 INFO sentence_transformers.SentenceTransformer: Use pytorch device_name: cuda:0
2025-12-23 08:53:49,393 INFO sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: all-roberta-large-v1
2025-12-23 08:53:55,634 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:54:09,033 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:09,040 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:09,040 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:09.040725', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:09,041 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:10,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,730 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,741 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,748 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,750 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,752 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:10,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,777 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,777 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,780 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,781 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,782 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,782 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,785 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,785 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,792 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:10,800 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:11,592 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:11,643 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 500 virtual documents
2025-12-23 08:54:11,693 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:11,700 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:11,700 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:11.700372', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:11,701 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:13,476 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:54:13,477 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:54:13,478 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:54:13,478 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:54:13,479 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:54:13,479 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:54:13,480 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:54:13,480 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3923 virtual)
2025-12-23 08:54:13,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,504 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,509 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:13,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,517 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,532 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,532 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,537 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,544 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,550 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,557 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,557 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:13,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:14,381 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:14,439 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4066 virtual documents
2025-12-23 08:54:14,492 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:14,499 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:14,499 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:14.499098', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:15,947 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
2025-12-23 08:54:17,646 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:17,653 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:17,654 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:17.653998', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:17,654 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:19,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,814 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,817 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,818 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,824 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,832 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,836 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,840 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:19,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,849 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,850 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,853 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,854 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,854 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,860 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,860 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,861 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,864 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,868 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,868 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,872 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,872 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,872 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,878 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,881 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,881 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,885 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,885 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,888 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:19,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:20,912 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:20,917 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:20,941 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 500 virtual documents
2025-12-23 08:54:21,058 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:21,065 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:21,065 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:21.065731', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:21,066 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:22,882 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:54:22,883 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:54:22,883 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:54:22,884 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:54:22,885 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:54:22,885 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:54:22,886 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:54:22,886 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3923 virtual)
2025-12-23 08:54:22,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,906 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,916 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,922 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,924 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,925 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:22,925 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,928 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,929 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,929 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,930 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,932 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,933 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,934 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,938 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,938 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,938 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,944 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,944 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,946 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,948 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,948 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,949 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,952 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,953 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,954 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,957 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,958 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,961 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,961 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,965 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,968 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,976 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,980 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,980 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:22,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:23,026 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:23,858 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:23,891 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4066 virtual documents
2025-12-23 08:54:23,993 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:24,000 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:24,000 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:24.000361', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:25,457 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 0 (500 docs)
Training CobwebTree:   0%|          | 0/500 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 17/500 [00:00<00:03, 156.90it/s]Training CobwebTree:   7%|         | 33/500 [00:00<00:04, 116.60it/s]Training CobwebTree:   9%|         | 46/500 [00:00<00:04, 106.54it/s]Training CobwebTree:  11%|        | 57/500 [00:00<00:04, 98.85it/s] Training CobwebTree:  14%|        | 68/500 [00:00<00:04, 92.88it/s]Training CobwebTree:  16%|        | 78/500 [00:00<00:04, 91.21it/s]Training CobwebTree:  18%|        | 88/500 [00:00<00:04, 85.75it/s]Training CobwebTree:  19%|        | 97/500 [00:01<00:05, 75.61it/s]Training CobwebTree:  21%|        | 105/500 [00:01<00:05, 76.09it/s]Training CobwebTree:  23%|       | 113/500 [00:01<00:05, 74.98it/s]Training CobwebTree:  24%|       | 121/500 [00:01<00:05, 75.58it/s]Training CobwebTree:  26%|       | 130/500 [00:01<00:04, 77.70it/s]Training CobwebTree:  28%|       | 138/500 [00:01<00:04, 74.67it/s]Training CobwebTree:  29%|       | 147/500 [00:01<00:04, 76.74it/s]Training CobwebTree:  31%|       | 155/500 [00:01<00:04, 72.49it/s]Training CobwebTree:  33%|      | 163/500 [00:01<00:04, 70.58it/s]Training CobwebTree:  34%|      | 171/500 [00:02<00:04, 72.78it/s]Training CobwebTree:  36%|      | 179/500 [00:02<00:04, 72.71it/s]Training CobwebTree:  37%|      | 187/500 [00:02<00:04, 72.54it/s]Training CobwebTree:  39%|      | 195/500 [00:02<00:04, 70.00it/s]Training CobwebTree:  41%|      | 203/500 [00:02<00:04, 69.05it/s]Training CobwebTree:  42%|     | 210/500 [00:02<00:04, 66.55it/s]Training CobwebTree:  43%|     | 217/500 [00:02<00:04, 66.36it/s]Training CobwebTree:  45%|     | 224/500 [00:02<00:04, 67.00it/s]Training CobwebTree:  46%|     | 231/500 [00:02<00:04, 64.98it/s]Training CobwebTree:  48%|     | 239/500 [00:03<00:03, 67.21it/s]Training CobwebTree:  49%|     | 246/500 [00:03<00:03, 65.62it/s]Training CobwebTree:  51%|     | 253/500 [00:03<00:03, 64.83it/s]Training CobwebTree:  52%|    | 260/500 [00:03<00:03, 63.47it/s]Training CobwebTree:  53%|    | 267/500 [00:03<00:03, 61.89it/s]Training CobwebTree:  55%|    | 274/500 [00:03<00:03, 60.31it/s]Training CobwebTree:  56%|    | 281/500 [00:03<00:03, 58.94it/s]Training CobwebTree:  57%|    | 287/500 [00:03<00:03, 57.50it/s]Training CobwebTree:  59%|    | 293/500 [00:04<00:03, 56.32it/s]Training CobwebTree:  60%|    | 299/500 [00:04<00:03, 56.30it/s]Training CobwebTree:  61%|    | 306/500 [00:04<00:03, 57.59it/s]Training CobwebTree:  63%|   | 313/500 [00:04<00:03, 58.84it/s]Training CobwebTree:  64%|   | 319/500 [00:04<00:03, 58.88it/s]Training CobwebTree:  65%|   | 326/500 [00:04<00:02, 59.79it/s]Training CobwebTree:  67%|   | 333/500 [00:04<00:02, 60.55it/s]Training CobwebTree:  68%|   | 340/500 [00:04<00:02, 59.75it/s]Training CobwebTree:  69%|   | 347/500 [00:04<00:02, 61.33it/s]Training CobwebTree:  71%|   | 354/500 [00:05<00:02, 61.82it/s]Training CobwebTree:  72%|  | 361/500 [00:05<00:02, 61.85it/s]Training CobwebTree:  74%|  | 368/500 [00:05<00:02, 59.38it/s]Training CobwebTree:  75%|  | 375/500 [00:05<00:02, 59.60it/s]Training CobwebTree:  76%|  | 381/500 [00:05<00:02, 57.73it/s]Training CobwebTree:  77%|  | 387/500 [00:05<00:01, 57.52it/s]Training CobwebTree:  79%|  | 394/500 [00:05<00:01, 58.53it/s]Training CobwebTree:  80%|  | 400/500 [00:05<00:01, 56.33it/s]Training CobwebTree:  81%|  | 406/500 [00:05<00:01, 55.88it/s]Training CobwebTree:  82%| | 412/500 [00:06<00:01, 54.04it/s]Training CobwebTree:  84%| | 418/500 [00:06<00:01, 55.07it/s]Training CobwebTree:  85%| | 425/500 [00:06<00:01, 56.68it/s]Training CobwebTree:  86%| | 431/500 [00:06<00:01, 55.04it/s]Training CobwebTree:  88%| | 438/500 [00:06<00:01, 56.37it/s]Training CobwebTree:  89%| | 444/500 [00:06<00:00, 56.35it/s]Training CobwebTree:  90%| | 450/500 [00:06<00:00, 55.48it/s]Training CobwebTree:  91%| | 456/500 [00:06<00:00, 53.63it/s]Training CobwebTree:  92%|| 462/500 [00:06<00:00, 54.28it/s]Training CobwebTree:  94%|| 468/500 [00:07<00:00, 52.84it/s]Training CobwebTree:  95%|| 474/500 [00:07<00:00, 51.48it/s]Training CobwebTree:  96%|| 480/500 [00:07<00:00, 52.24it/s]Training CobwebTree:  97%|| 486/500 [00:07<00:00, 51.66it/s]Training CobwebTree:  98%|| 492/500 [00:07<00:00, 52.56it/s]Training CobwebTree: 100%|| 498/500 [00:07<00:00, 52.16it/s]Training CobwebTree: 100%|| 500/500 [00:07<00:00, 64.94it/s]
2025-12-23 08:54:35,056 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:35,063 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:35,063 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:35.063610', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:35,066 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:36,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,953 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,953 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,959 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,964 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,966 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,968 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:36,969 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,973 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,974 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,974 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,996 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:36,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,001 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,018 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,032 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:37,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:38,202 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:38,313 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 500 virtual documents
2025-12-23 08:54:38,879 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:38,886 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:38,886 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:38.886183', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:38,889 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:40,772 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:54:40,773 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:54:40,774 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:54:40,775 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:54:40,776 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:54:40,777 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:54:40,777 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:54:40,778 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3923 virtual)
2025-12-23 08:54:40,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,821 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,852 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,853 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,868 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:40,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:40,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:41,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:42,122 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:42,220 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4066 virtual documents
2025-12-23 08:54:42,552 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:42,559 INFO gensim.corpora.dictionary: built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)
2025-12-23 08:54:42,559 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<3900 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 500 documents (total 8423 corpus positions)", 'datetime': '2025-12-23T08:54:42.559787', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:44,046 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:54:47,887 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:47,901 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:54:47,901 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:54:47.901170', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:47,901 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:49,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,790 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,792 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,794 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,796 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,800 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,800 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,808 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,810 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,811 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:49,813 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,813 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,824 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,830 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,830 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,838 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,845 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,850 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,852 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,876 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:49,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:50,709 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:50,788 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 625 virtual documents
2025-12-23 08:54:50,869 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:50,878 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:54:50,878 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:54:50.878277', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:50,879 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:52,818 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:54:52,819 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:54:52,820 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:54:52,820 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:54:52,821 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:54:52,821 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:54:52,822 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:54:52,823 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:54:52,823 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:54:52,824 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4772 virtual)
2025-12-23 08:54:52,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,862 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,875 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,876 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:52,876 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,876 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,877 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,878 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,884 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,886 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,888 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,894 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,894 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,894 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,897 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,898 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,898 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,900 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,900 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,901 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,901 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,901 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,905 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,909 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:52,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:53,813 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:54:53,856 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4970 virtual documents
2025-12-23 08:54:53,925 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:53,934 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:54:53,934 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:54:53.934368', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:56,810 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:54:57,589 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:54:57,598 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:54:57,598 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:54:57.598764', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:54:57,599 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:54:59,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,544 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:54:59,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,586 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,586 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,589 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,612 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:54:59,613 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:00,489 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:00,561 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 625 virtual documents
2025-12-23 08:55:00,695 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:00,703 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:55:00,704 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:55:00.703975', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:00,705 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:02,609 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:55:02,610 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:55:02,611 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:55:02,612 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:55:02,612 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:55:02,613 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:55:02,613 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:55:02,614 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:55:02,615 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:55:02,615 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4772 virtual)
2025-12-23 08:55:02,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,646 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,650 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,653 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,653 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:02,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,672 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,676 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,681 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,685 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,685 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,705 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,705 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,709 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,717 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:02,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:03,662 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:03,712 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4970 virtual documents
2025-12-23 08:55:03,839 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:03,848 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:55:03,848 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:55:03.848599', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:06,734 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 57.33it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:01, 58.58it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:01, 56.35it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:01, 57.07it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:01, 53.39it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 53.79it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 53.43it/s]Training CobwebTree:  39%|      | 49/125 [00:00<00:01, 53.21it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 54.02it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 52.77it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 54.06it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 51.35it/s]Training CobwebTree:  63%|   | 79/125 [00:01<00:00, 52.63it/s]Training CobwebTree:  68%|   | 85/125 [00:01<00:00, 53.94it/s]Training CobwebTree:  73%|  | 91/125 [00:01<00:00, 54.56it/s]Training CobwebTree:  78%|  | 97/125 [00:01<00:00, 55.62it/s]Training CobwebTree:  82%| | 103/125 [00:01<00:00, 54.36it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 55.47it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 54.78it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 58.65it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 54.88it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:09,965 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:09,973 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:55:09,973 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:55:09.973935', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:09,975 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:12,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,281 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:12,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,316 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,368 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,368 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,381 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:12,381 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:13,294 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:13,360 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 625 virtual documents
2025-12-23 08:55:13,625 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:13,634 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:55:13,634 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:55:13.634284', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:13,636 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:15,571 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:55:15,572 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:55:15,573 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:55:15,574 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:55:15,575 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:55:15,575 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:55:15,576 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:55:15,577 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:55:15,577 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:55:15,578 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4772 virtual)
2025-12-23 08:55:15,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,602 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,618 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,626 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,644 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,646 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,646 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,650 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,680 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,692 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:15,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:15,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:16,658 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:16,732 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 4970 virtual documents
2025-12-23 08:55:16,918 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:16,926 INFO gensim.corpora.dictionary: built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)
2025-12-23 08:55:16,926 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<4504 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 625 documents (total 10397 corpus positions)", 'datetime': '2025-12-23T08:55:16.926894', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:19,898 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:21,348 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:21,358 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:21,358 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:21.358897', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:21,359 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:23,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,241 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,241 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,246 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,237 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,254 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,254 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,258 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,258 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:23,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,300 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,309 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,321 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,325 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:23,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:24,233 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:24,267 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 750 virtual documents
2025-12-23 08:55:24,398 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:24,408 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:24,408 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:24.408757', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:24,409 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:26,315 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:55:26,316 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:55:26,316 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:55:26,317 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:55:26,318 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:55:26,318 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:55:26,319 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:55:26,320 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:55:26,320 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:55:26,321 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:55:26,322 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:55:26,322 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5727 virtual)
2025-12-23 08:55:26,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,348 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,350 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,350 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,368 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,372 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,377 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,377 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:26,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,393 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,398 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,402 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:26,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:27,377 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:27,420 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 5969 virtual documents
2025-12-23 08:55:27,496 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:27,507 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:27,507 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:27.507190', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:30,973 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:31,853 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:31,863 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:31,863 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:31.863952', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:31,864 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:34,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,252 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,253 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,256 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,261 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,266 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:34,272 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,277 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,282 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,285 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,285 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,285 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,286 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,290 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,304 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,309 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,309 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:34,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:35,277 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:35,331 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 750 virtual documents
2025-12-23 08:55:35,474 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:35,484 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:35,485 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:35.484981', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:35,486 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:37,369 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:55:37,370 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:55:37,371 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:55:37,372 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:55:37,373 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:55:37,373 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:55:37,374 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:55:37,375 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:55:37,375 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:55:37,376 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:55:37,377 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:55:37,377 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5727 virtual)
2025-12-23 08:55:37,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,395 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,397 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,398 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,429 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,488 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,492 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:37,501 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:37,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:38,430 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:38,476 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 5969 virtual documents
2025-12-23 08:55:38,574 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:38,584 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:38,584 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:38.584640', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:42,099 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:01, 59.83it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:01, 58.52it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:01, 56.33it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:01, 54.87it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 53.49it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 55.00it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 56.31it/s]Training CobwebTree:  39%|      | 49/125 [00:00<00:01, 55.28it/s]Training CobwebTree:  44%|     | 55/125 [00:00<00:01, 55.25it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 54.40it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 55.16it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:00, 54.84it/s]Training CobwebTree:  63%|   | 79/125 [00:01<00:00, 54.07it/s]Training CobwebTree:  68%|   | 85/125 [00:01<00:00, 54.44it/s]Training CobwebTree:  73%|  | 91/125 [00:01<00:00, 54.47it/s]Training CobwebTree:  78%|  | 97/125 [00:01<00:00, 51.85it/s]Training CobwebTree:  83%| | 104/125 [00:01<00:00, 54.38it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 52.49it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 51.26it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 52.59it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 54.30it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:45,446 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:45,456 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:45,456 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:45.456916', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:45,458 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:47,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,429 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,438 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,443 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,446 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:47,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,453 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,458 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,472 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,473 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,506 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:47,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:48,430 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:48,521 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 750 virtual documents
2025-12-23 08:55:48,829 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:48,839 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:48,840 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:48.840010', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:48,842 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:50,858 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:55:50,874 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:55:50,874 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:55:50,875 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:55:50,876 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:55:50,877 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:55:50,878 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:55:50,878 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:55:50,879 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:55:50,880 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:55:50,881 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:55:50,881 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5727 virtual)
2025-12-23 08:55:50,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,912 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,917 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,917 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,921 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,922 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,922 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,924 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,942 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,946 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,948 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,952 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,953 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:50,958 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,970 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,976 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,982 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,993 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:51,004 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:50,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:51,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:51,032 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:51,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:51,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:52,234 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:55:52,348 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 5969 virtual documents
2025-12-23 08:55:52,535 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:52,545 INFO gensim.corpora.dictionary: built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)
2025-12-23 08:55:52,545 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 750 documents (total 12477 corpus positions)", 'datetime': '2025-12-23T08:55:52.545841', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:56,090 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:55:57,497 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:55:57,509 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:55:57,509 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:55:57.509590', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:55:57,510 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:55:59,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,412 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:55:59,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,421 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,430 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,436 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,441 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,442 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,445 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,446 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,446 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,469 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:55:59,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:00,398 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:00,452 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 875 virtual documents
2025-12-23 08:56:00,532 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:00,545 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:00,545 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:00.545110', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:00,546 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:02,475 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:56:02,476 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:56:02,476 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:56:02,477 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:56:02,477 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:56:02,478 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:56:02,479 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:56:02,479 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:56:02,480 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:56:02,481 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:56:02,481 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:56:02,482 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:56:02,483 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:56:02,483 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6620 virtual)
2025-12-23 08:56:02,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,513 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,520 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,548 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,549 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,549 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,553 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:02,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,564 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,573 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,574 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,574 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,589 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,593 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:02,600 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:03,503 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:03,565 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 6906 virtual documents
2025-12-23 08:56:03,633 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:03,646 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:03,646 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:03.646171', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:07,730 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:08,615 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:08,627 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:08,627 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:08.627928', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:08,628 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:10,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:10,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,550 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,550 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,550 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,560 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,573 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,576 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:10,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:11,563 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:11,638 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 875 virtual documents
2025-12-23 08:56:11,771 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:11,787 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:11,787 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:11.787542', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:11,788 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:13,678 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:56:13,680 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:56:13,680 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:56:13,681 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:56:13,681 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:56:13,682 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:56:13,683 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:56:13,683 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:56:13,684 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:56:13,685 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:56:13,686 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:56:13,686 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:56:13,687 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:56:13,687 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6620 virtual)
2025-12-23 08:56:13,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,730 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,730 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:13,748 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,764 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,773 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,785 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,789 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,790 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:13,820 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:14,726 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:14,786 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 6906 virtual documents
2025-12-23 08:56:14,902 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:14,914 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:14,914 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:14.914747', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:19,015 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 750 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 58.34it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 56.36it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:01, 54.32it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:01, 52.17it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 51.86it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 55.23it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 54.98it/s]Training CobwebTree:  40%|      | 50/125 [00:00<00:01, 56.94it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 55.23it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 56.48it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 55.89it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:00, 56.66it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:00, 55.97it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 55.84it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 55.37it/s]Training CobwebTree:  78%|  | 98/125 [00:01<00:00, 55.01it/s]Training CobwebTree:  83%| | 104/125 [00:01<00:00, 52.01it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 50.34it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 49.07it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 50.38it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 53.69it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:22,421 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:22,433 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:22,433 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:22.433763', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:22,435 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:24,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,493 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,501 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,505 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,508 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,513 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,513 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:24,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,561 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:24,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:25,875 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:25,988 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 875 virtual documents
2025-12-23 08:56:26,326 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:26,338 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:26,338 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:26.338676', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:26,341 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:28,281 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:56:28,282 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:56:28,283 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:56:28,284 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:56:28,284 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:56:28,285 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:56:28,286 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:56:28,287 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:56:28,287 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:56:28,288 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:56:28,289 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:56:28,289 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:56:28,290 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:56:28,291 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6620 virtual)
2025-12-23 08:56:28,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,321 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,324 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,325 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,329 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,335 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,341 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,347 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,356 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,356 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,362 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:28,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:28,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:29,439 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:29,485 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 6906 virtual documents
2025-12-23 08:56:29,713 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:29,725 INFO gensim.corpora.dictionary: built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)
2025-12-23 08:56:29,725 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<5834 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 875 documents (total 14495 corpus positions)", 'datetime': '2025-12-23T08:56:29.725397', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:33,900 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:35,361 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:35,375 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:35,375 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:35.375261', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:35,376 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:37,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,362 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,363 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,367 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,368 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,369 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,372 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,372 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,373 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,374 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,375 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,376 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,377 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,377 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,377 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,379 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,380 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:37,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,412 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,413 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:37,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:38,394 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:38,441 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1000 virtual documents
2025-12-23 08:56:38,552 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:38,566 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:38,566 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:38.566327', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:38,567 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:40,566 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:56:40,567 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:56:40,568 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:56:40,569 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:56:40,569 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:56:40,570 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:56:40,570 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:56:40,571 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:56:40,572 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:56:40,572 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:56:40,573 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:56:40,574 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:56:40,574 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:56:40,575 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:56:40,576 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:56:40,576 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7407 virtual)
2025-12-23 08:56:40,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,668 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,668 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,668 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,673 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,673 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:40,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:40,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:41,651 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:41,692 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 7740 virtual documents
2025-12-23 08:56:41,767 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:41,781 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:41,781 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:41.781815', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:41,785 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:56:46,576 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:56:47,484 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:47,498 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:47,498 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:47.498126', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:47,499 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:49,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,500 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,504 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,505 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:49,508 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,508 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,561 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,565 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:49,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:50,578 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:50,909 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1000 virtual documents
2025-12-23 08:56:51,040 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:51,053 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:51,054 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:51.054011', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:51,055 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:56:52,969 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:56:52,970 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:56:52,971 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:56:52,972 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:56:52,972 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:56:52,973 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:56:52,973 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:56:52,974 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:56:52,975 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:56:52,975 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:56:52,976 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:56:52,977 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:56:52,977 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:56:52,978 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:56:52,979 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:56:52,979 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7407 virtual)
2025-12-23 08:56:53,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,011 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,011 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,011 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,014 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,016 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,022 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,029 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,029 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,036 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,036 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:56:53,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,062 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,072 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:53,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:56:54,087 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:56:54,119 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 7740 virtual documents
2025-12-23 08:56:54,234 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:56:54,252 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:56:54,252 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:56:54.252366', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:56:54,256 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:56:58,976 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 875 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 55.55it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 49.95it/s]Training CobwebTree:  14%|        | 18/125 [00:00<00:02, 52.13it/s]Training CobwebTree:  19%|        | 24/125 [00:00<00:01, 51.79it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:01, 51.07it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 53.50it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 53.12it/s]Training CobwebTree:  38%|      | 48/125 [00:00<00:01, 52.51it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 51.80it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 51.24it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 49.08it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 48.89it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 48.22it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 48.32it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 48.51it/s]Training CobwebTree:  73%|  | 91/125 [00:01<00:00, 46.75it/s]Training CobwebTree:  77%|  | 96/125 [00:01<00:00, 46.19it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 46.27it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 46.60it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 48.40it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 46.97it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 47.28it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 49.20it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:02,600 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:02,620 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:57:02,620 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:57:02.620514', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:02,622 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,654 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:04,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,676 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,677 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,681 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,681 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,718 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,718 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,729 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,734 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:04,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:05,759 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:05,819 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1000 virtual documents
2025-12-23 08:57:06,073 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:06,086 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:57:06,086 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:57:06.086821', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:06,089 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:08,023 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:57:08,025 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:57:08,025 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:57:08,026 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:57:08,027 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:57:08,028 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:57:08,028 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:57:08,029 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:57:08,030 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:57:08,030 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:57:08,031 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:57:08,032 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:57:08,033 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:57:08,033 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:57:08,034 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:57:08,035 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7407 virtual)
2025-12-23 08:57:08,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,067 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,069 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,073 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,076 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,085 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,086 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,088 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,092 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,106 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,109 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,117 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:08,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:08,220 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:09,211 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:09,248 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 7740 virtual documents
2025-12-23 08:57:09,424 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:09,438 INFO gensim.corpora.dictionary: built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)
2025-12-23 08:57:09,438 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6301 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1000 documents (total 16407 corpus positions)", 'datetime': '2025-12-23T08:57:09.438301', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:09,443 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:57:14,156 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:15,614 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:15,629 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:15,629 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:15.629447', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:15,630 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:17,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,900 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,900 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,905 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,908 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,909 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,910 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,912 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,920 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,920 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,923 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:17,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,928 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,932 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,933 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,937 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,946 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,949 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,949 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,954 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,957 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,958 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,976 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,982 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,982 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,982 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:17,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:19,062 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:19,124 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1125 virtual documents
2025-12-23 08:57:19,229 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:19,244 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:19,244 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:19.244729', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:19,245 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:21,248 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:57:21,249 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:57:21,250 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:57:21,251 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:57:21,252 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:57:21,252 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:57:21,253 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:57:21,253 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:57:21,254 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:57:21,255 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:57:21,256 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:57:21,256 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:57:21,257 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:57:21,258 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:57:21,258 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:57:21,259 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:57:21,260 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:57:21,260 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8179 virtual)
2025-12-23 08:57:21,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,306 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,308 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,313 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,313 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:21,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,324 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,330 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,348 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,352 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:21,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:22,476 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:22,504 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 8563 virtual documents
2025-12-23 08:57:22,590 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:22,605 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:22,605 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:22.605491', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:22,609 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:57:27,914 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:28,743 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:28,758 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:28,758 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:28.758440', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:28,759 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:30,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,675 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,676 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,677 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,678 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,682 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,683 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,684 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,685 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,686 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,688 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,689 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,690 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,691 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:30,692 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,692 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,717 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,737 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,764 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,764 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:30,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:31,811 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:31,842 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1125 virtual documents
2025-12-23 08:57:31,954 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:31,970 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:31,970 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:31.970540', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:31,971 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:33,960 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:57:33,962 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:57:33,963 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:57:33,963 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:57:33,964 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:57:33,964 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:57:33,965 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:57:33,966 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:57:33,967 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:57:33,968 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:57:33,968 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:57:33,969 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:57:33,970 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:57:33,970 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:57:33,971 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:57:33,971 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:57:33,972 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:57:33,973 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8179 virtual)
2025-12-23 08:57:34,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,016 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,017 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,019 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,021 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,025 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,036 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:34,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,042 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,050 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,074 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,076 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,081 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:34,093 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:35,115 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:35,156 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 8563 virtual documents
2025-12-23 08:57:35,241 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:35,256 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:35,256 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:35.256262', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:35,260 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:57:40,574 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1000 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 48.03it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 47.84it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 51.34it/s]Training CobwebTree:  18%|        | 22/125 [00:00<00:02, 47.91it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:02, 48.24it/s]Training CobwebTree:  26%|       | 33/125 [00:00<00:01, 50.57it/s]Training CobwebTree:  31%|       | 39/125 [00:00<00:01, 49.33it/s]Training CobwebTree:  36%|      | 45/125 [00:00<00:01, 50.53it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 52.97it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 52.94it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 52.67it/s]Training CobwebTree:  55%|    | 69/125 [00:01<00:01, 52.45it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:00, 50.61it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 50.35it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 46.46it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 45.62it/s]Training CobwebTree:  78%|  | 97/125 [00:01<00:00, 45.34it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 45.42it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 46.42it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 44.79it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 45.15it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 45.86it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 48.29it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:44,154 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:44,169 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:44,169 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:44.169761', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:44,171 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:46,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,189 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,189 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,194 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,202 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,217 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:46,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,233 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,233 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,245 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:46,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:47,340 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:47,391 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1125 virtual documents
2025-12-23 08:57:47,608 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:47,623 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:47,624 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:47.623969', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:47,625 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:57:49,853 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:57:49,855 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:57:49,856 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:57:49,856 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:57:49,857 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:57:49,858 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:57:49,859 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:57:49,859 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:57:49,860 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:57:49,861 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:57:49,861 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:57:49,862 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:57:49,863 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:57:49,864 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:57:49,864 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:57:49,865 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:57:49,866 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:57:49,866 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8179 virtual)
2025-12-23 08:57:49,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,905 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,906 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,912 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,913 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,914 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,915 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,916 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,917 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,918 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,918 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,919 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,926 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,927 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,929 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,930 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,931 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,932 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,934 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,935 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,936 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,945 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,956 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,962 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,989 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,990 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:49,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:50,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:50,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:50,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:50,010 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:50,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:57:50,058 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:57:51,139 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:57:51,195 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 8563 virtual documents
2025-12-23 08:57:51,347 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:51,362 INFO gensim.corpora.dictionary: built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)
2025-12-23 08:57:51,362 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<6778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1125 documents (total 18304 corpus positions)", 'datetime': '2025-12-23T08:57:51.362639', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:51,367 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:57:56,664 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:57:58,115 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:57:58,132 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:57:58,132 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:57:58.132482', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:57:58,133 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:00,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,157 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,161 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,173 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,173 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:00,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,180 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,181 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,186 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,189 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,209 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,214 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,217 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,249 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:00,257 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:01,256 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:01,286 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1250 virtual documents
2025-12-23 08:58:01,382 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:01,399 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:01,399 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:01.399405', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:01,400 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:03,373 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:58:03,374 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:58:03,375 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:58:03,376 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:58:03,376 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:58:03,377 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:58:03,378 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:58:03,378 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:58:03,379 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:58:03,380 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:58:03,381 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:58:03,381 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:58:03,382 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:58:03,383 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:58:03,383 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:58:03,384 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:58:03,385 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:58:03,386 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:58:03,386 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:58:03,387 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8803 virtual)
2025-12-23 08:58:03,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,445 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,448 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,448 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,453 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,453 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,457 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,480 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,486 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,500 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,505 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,508 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:03,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:03,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:04,512 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:04,539 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9282 virtual documents
2025-12-23 08:58:04,642 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:04,659 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:04,659 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:04.659372', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:04,663 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:10,534 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:11,334 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:11,351 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:11,351 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:11.351259', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:11,352 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:13,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,297 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,310 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,312 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:13,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,318 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,330 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,349 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,358 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,366 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,366 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,369 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:13,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:14,395 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:14,439 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1250 virtual documents
2025-12-23 08:58:14,574 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:14,591 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:14,591 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:14.591511', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:14,592 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:16,582 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:58:16,583 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:58:16,584 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:58:16,585 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:58:16,585 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:58:16,586 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:58:16,587 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:58:16,587 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:58:16,588 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:58:16,589 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:58:16,590 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:58:16,590 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:58:16,591 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:58:16,592 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:58:16,592 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:58:16,593 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:58:16,594 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:58:16,594 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:58:16,595 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:58:16,596 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8803 virtual)
2025-12-23 08:58:16,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,640 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,648 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,653 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,653 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,672 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,672 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,677 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,732 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,756 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:16,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:16,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:17,741 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:17,784 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9282 virtual documents
2025-12-23 08:58:17,879 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:17,895 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:17,895 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:17.895779', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:17,899 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:23,818 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1125 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:03, 39.15it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 43.01it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 45.47it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 46.67it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 45.89it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 45.23it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 46.91it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 47.71it/s]Training CobwebTree:  38%|      | 47/125 [00:01<00:01, 46.17it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 45.33it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 46.09it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 48.28it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 48.08it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 47.35it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:01, 46.99it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 45.21it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 45.97it/s]Training CobwebTree:  74%|  | 93/125 [00:02<00:00, 46.70it/s]Training CobwebTree:  78%|  | 98/125 [00:02<00:00, 46.33it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 46.25it/s]Training CobwebTree:  86%| | 108/125 [00:02<00:00, 43.61it/s]Training CobwebTree:  90%| | 113/125 [00:02<00:00, 41.44it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 44.69it/s]Training CobwebTree:  99%|| 124/125 [00:02<00:00, 45.44it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 45.86it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:27,522 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:27,539 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:27,539 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:27.539804', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:27,541 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:29,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,505 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,518 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,520 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,520 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,526 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:29,532 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,546 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,561 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:29,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:30,899 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:30,959 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1250 virtual documents
2025-12-23 08:58:31,184 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:31,201 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:31,201 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:31.201256', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:31,203 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:33,157 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:58:33,158 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:58:33,159 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:58:33,160 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:58:33,161 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:58:33,161 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:58:33,162 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:58:33,163 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:58:33,163 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:58:33,164 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:58:33,165 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:58:33,166 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:58:33,166 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:58:33,167 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:58:33,168 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:58:33,169 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:58:33,169 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:58:33,170 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:58:33,171 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:58:33,171 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8803 virtual)
2025-12-23 08:58:33,211 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,217 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,225 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,229 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,230 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,231 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,232 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,233 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,234 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,236 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,236 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,236 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,238 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,240 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,238 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,241 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,254 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,257 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,286 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,286 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,289 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:33,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:33,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:34,351 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:34,401 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9282 virtual documents
2025-12-23 08:58:34,574 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:34,590 INFO gensim.corpora.dictionary: built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)
2025-12-23 08:58:34,590 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7195 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1250 documents (total 20053 corpus positions)", 'datetime': '2025-12-23T08:58:34.590790', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:34,595 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:40,436 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:41,783 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:41,802 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:58:41,802 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:58:41.802342', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:41,803 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:43,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,864 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,870 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:43,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,874 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,884 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,884 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,885 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,914 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,920 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:43,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:44,926 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:44,976 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1375 virtual documents
2025-12-23 08:58:45,081 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:45,099 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:58:45,099 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:58:45.099703', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:45,100 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:47,058 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:58:47,060 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:58:47,060 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:58:47,061 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:58:47,062 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:58:47,062 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:58:47,063 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:58:47,064 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:58:47,064 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:58:47,065 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:58:47,066 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:58:47,067 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:58:47,068 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:58:47,068 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:58:47,069 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:58:47,070 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:58:47,071 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:58:47,071 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:58:47,072 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:58:47,072 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 08:58:47,073 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 08:58:47,073 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9379 virtual)
2025-12-23 08:58:47,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,121 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,124 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,127 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,128 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,129 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,134 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:47,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,140 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,140 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,145 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,146 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,146 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,153 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,197 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:47,221 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:48,213 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:48,240 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9933 virtual documents
2025-12-23 08:58:48,322 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:48,345 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:58:48,345 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:58:48.345083', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:48,349 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:58:54,652 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:58:55,407 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:55,429 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:58:55,429 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:58:55.429830', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:55,430 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:58:57,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,437 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,442 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,442 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,444 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,445 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,445 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,445 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,452 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:58:57,458 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,458 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,473 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,486 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:57,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:58:58,550 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:58:58,584 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1375 virtual documents
2025-12-23 08:58:58,725 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:58:58,743 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:58:58,744 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:58:58.744050', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:58:58,745 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:00,776 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:59:00,777 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:59:00,777 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:59:00,778 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:59:00,779 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:59:00,780 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:59:00,780 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:59:00,781 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:59:00,782 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:59:00,783 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:59:00,783 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:59:00,784 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:59:00,785 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:59:00,786 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:59:00,786 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:59:00,787 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:59:00,788 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:59:00,789 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:59:00,789 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:59:00,790 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 08:59:00,790 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 08:59:00,791 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9379 virtual)
2025-12-23 08:59:00,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,849 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,856 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,861 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,886 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,888 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,910 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,928 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,932 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:00,941 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:00,957 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:02,183 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:02,264 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9933 virtual documents
2025-12-23 08:59:02,384 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:02,402 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:59:02,403 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:59:02.403002', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:02,406 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:08,762 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1250 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 43.27it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 39.70it/s]Training CobwebTree:  11%|         | 14/125 [00:00<00:02, 38.59it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 42.93it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 43.77it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 38.09it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 39.63it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:02, 40.57it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 40.88it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 41.34it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 42.53it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 43.80it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 43.59it/s]Training CobwebTree:  56%|    | 70/125 [00:01<00:01, 42.40it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 44.87it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 44.86it/s]Training CobwebTree:  69%|   | 86/125 [00:02<00:00, 42.97it/s]Training CobwebTree:  73%|  | 91/125 [00:02<00:00, 43.86it/s]Training CobwebTree:  77%|  | 96/125 [00:02<00:00, 42.30it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 42.75it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 43.95it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 45.32it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 47.86it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 49.72it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 43.66it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:12,560 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:12,578 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:59:12,578 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:59:12.578125', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:12,579 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:14,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,548 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,549 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,550 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,551 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,552 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,553 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,554 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,555 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:14,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,565 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,589 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,593 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,593 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,626 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:14,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:15,664 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:15,707 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1375 virtual documents
2025-12-23 08:59:15,924 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:15,942 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:59:15,942 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:59:15.942365', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:15,944 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:17,901 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:59:17,903 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:59:17,903 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:59:17,904 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:59:17,905 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:59:17,905 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:59:17,906 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:59:17,907 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:59:17,907 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:59:17,908 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:59:17,909 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:59:17,910 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:59:17,910 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:59:17,911 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:59:17,912 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:59:17,913 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:59:17,913 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:59:17,914 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:59:17,915 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:59:17,916 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 08:59:17,916 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 08:59:17,917 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9379 virtual)
2025-12-23 08:59:17,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,969 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,969 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,970 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,973 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,977 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,978 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,979 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,981 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,986 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,987 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,987 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,987 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,988 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,988 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,988 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,988 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,992 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,993 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,994 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,994 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,994 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,995 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,996 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,997 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,997 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:17,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:17,999 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,001 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,008 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,008 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,008 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,008 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,021 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,022 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,026 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,045 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,046 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,046 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,046 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,046 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,069 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:18,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:18,108 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:19,116 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:19,155 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 9933 virtual documents
2025-12-23 08:59:19,297 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:19,315 INFO gensim.corpora.dictionary: built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)
2025-12-23 08:59:19,315 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7501 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1375 documents (total 21754 corpus positions)", 'datetime': '2025-12-23T08:59:19.315816', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:19,320 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:25,626 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:27,032 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:27,052 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:27,052 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:27.052715', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:27,053 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:29,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,164 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,168 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,170 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,174 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,177 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:29,193 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,194 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,209 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,213 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,214 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,233 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:29,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:30,244 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:30,293 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1500 virtual documents
2025-12-23 08:59:30,383 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:30,403 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:30,403 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:30.403089', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:30,404 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:32,326 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:59:32,328 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:59:32,328 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:59:32,329 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:59:32,330 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:59:32,330 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:59:32,331 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:59:32,332 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:59:32,332 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:59:32,333 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:59:32,334 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:59:32,335 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:59:32,335 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:59:32,336 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:59:32,337 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:59:32,338 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:59:32,338 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:59:32,339 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:59:32,340 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:59:32,340 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 08:59:32,341 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 08:59:32,341 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 08:59:32,342 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 08:59:32,342 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10322 virtual)
2025-12-23 08:59:32,384 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,385 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,386 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,387 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,388 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,390 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,391 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,399 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,400 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,400 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,401 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,402 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,414 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,416 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,416 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:32,421 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,426 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,437 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,438 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,450 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,456 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,457 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,473 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:32,496 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:33,521 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:33,562 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 10903 virtual documents
2025-12-23 08:59:33,627 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:33,647 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:33,647 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:33.647217', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:33,650 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:40,538 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:41,396 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:41,416 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:41,416 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:41.416450', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:41,417 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:43,403 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,404 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,405 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,406 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,407 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,408 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,409 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,410 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,411 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,412 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,413 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,414 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,415 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,416 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,417 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,418 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,419 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,421 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,422 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,422 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:43,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,423 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,425 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,427 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,431 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,486 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,494 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,509 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:43,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:44,531 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:44,588 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1500 virtual documents
2025-12-23 08:59:44,717 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:44,736 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:44,736 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:44.736877', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:44,738 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 08:59:46,764 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 08:59:46,765 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 08:59:46,766 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 08:59:46,767 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 08:59:46,767 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 08:59:46,768 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 08:59:46,769 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 08:59:46,770 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 08:59:46,770 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 08:59:46,771 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 08:59:46,772 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 08:59:46,773 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 08:59:46,773 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 08:59:46,774 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 08:59:46,775 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 08:59:46,776 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 08:59:46,776 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 08:59:46,777 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 08:59:46,778 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 08:59:46,778 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 08:59:46,779 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 08:59:46,780 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 08:59:46,780 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 08:59:46,781 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10322 virtual)
2025-12-23 08:59:46,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,832 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,837 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,844 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,843 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,845 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,846 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,884 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,890 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,893 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,897 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,904 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,910 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,930 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 08:59:46,933 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:46,954 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 08:59:48,255 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 08:59:48,287 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 10903 virtual documents
2025-12-23 08:59:48,395 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:48,414 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:48,414 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:48.414601', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:48,418 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 08:59:55,361 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1375 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 40.74it/s]Training CobwebTree:   9%|         | 11/125 [00:00<00:02, 49.54it/s]Training CobwebTree:  14%|        | 17/125 [00:00<00:02, 49.09it/s]Training CobwebTree:  18%|        | 22/125 [00:00<00:02, 47.85it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:02, 47.78it/s]Training CobwebTree:  26%|       | 32/125 [00:00<00:01, 47.65it/s]Training CobwebTree:  30%|       | 38/125 [00:00<00:01, 49.15it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 48.10it/s]Training CobwebTree:  39%|      | 49/125 [00:01<00:01, 49.55it/s]Training CobwebTree:  43%|     | 54/125 [00:01<00:01, 49.48it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 51.53it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 49.24it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 48.08it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:00, 48.23it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 47.47it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 47.93it/s]Training CobwebTree:  74%|  | 92/125 [00:01<00:00, 46.12it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 45.22it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 44.82it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 44.83it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 44.26it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 44.29it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 43.45it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 46.73it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 08:59:59,081 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 08:59:59,101 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 08:59:59,101 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T08:59:59.101183', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 08:59:59,102 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:01,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,096 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,096 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,101 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:01,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,114 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,114 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,125 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,125 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:01,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:02,204 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:02,261 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1500 virtual documents
2025-12-23 09:00:02,483 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:02,502 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 09:00:02,502 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T09:00:02.502661', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:02,504 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:04,434 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:00:04,436 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:00:04,437 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:00:04,438 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:00:04,438 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:00:04,439 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:00:04,441 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:00:04,441 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:00:04,442 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:00:04,443 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:00:04,444 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:00:04,445 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:00:04,445 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:00:04,446 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:00:04,447 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:00:04,448 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:00:04,448 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:00:04,449 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:00:04,449 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:00:04,450 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:00:04,450 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:00:04,451 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:00:04,452 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:00:04,453 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10322 virtual)
2025-12-23 09:00:04,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,490 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,505 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,507 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,519 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,530 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,537 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,552 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:04,646 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:04,664 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:05,637 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:05,705 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 10903 virtual documents
2025-12-23 09:00:05,864 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:05,884 INFO gensim.corpora.dictionary: built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)
2025-12-23 09:00:05,884 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<7984 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1500 documents (total 23822 corpus positions)", 'datetime': '2025-12-23T09:00:05.884285', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:05,889 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:12,727 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:14,207 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:14,229 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:14,229 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:14.229530', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:14,230 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:16,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,281 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,282 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,283 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,284 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,284 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,285 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,286 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,287 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,288 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,289 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,293 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,294 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,296 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,297 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,298 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:16,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,316 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,316 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,322 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,322 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,338 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,346 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:16,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:17,387 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:17,465 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1625 virtual documents
2025-12-23 09:00:17,583 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:17,604 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:17,604 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:17.604323', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:17,605 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:19,547 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:00:19,548 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:00:19,549 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:00:19,550 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:00:19,550 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:00:19,551 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:00:19,552 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:00:19,552 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:00:19,553 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:00:19,554 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:00:19,555 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:00:19,556 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:00:19,557 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:00:19,557 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:00:19,558 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:00:19,559 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:00:19,559 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:00:19,560 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:00:19,561 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:00:19,562 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:00:19,562 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:00:19,563 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:00:19,564 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:00:19,564 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:00:19,565 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:00:19,565 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11237 virtual)
2025-12-23 09:00:19,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,624 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,640 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:19,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,650 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,652 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,652 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,657 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,662 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,681 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,682 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,697 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:19,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:21,100 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:21,155 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 11850 virtual documents
2025-12-23 09:00:21,243 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:21,264 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:21,265 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:21.265041', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:21,268 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:28,794 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:29,648 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:29,670 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:29,670 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:29.670665', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:29,671 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:31,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,745 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,749 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:31,750 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,777 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,785 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,790 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,793 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,798 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:31,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:32,840 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:32,929 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1625 virtual documents
2025-12-23 09:00:33,066 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:33,087 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:33,087 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:33.087747', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:33,089 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:35,119 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:00:35,121 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:00:35,122 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:00:35,123 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:00:35,123 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:00:35,124 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:00:35,125 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:00:35,126 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:00:35,127 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:00:35,127 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:00:35,128 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:00:35,129 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:00:35,130 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:00:35,130 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:00:35,131 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:00:35,132 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:00:35,133 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:00:35,133 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:00:35,134 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:00:35,135 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:00:35,135 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:00:35,136 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:00:35,137 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:00:35,137 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:00:35,138 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:00:35,138 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11237 virtual)
2025-12-23 09:00:35,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,191 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,192 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,205 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,208 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,208 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,210 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,214 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,214 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,238 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,238 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,238 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,250 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,270 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:35,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:35,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:36,329 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:36,373 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 11850 virtual documents
2025-12-23 09:00:36,479 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:36,500 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:36,500 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:36.500861', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:36,505 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:00:44,143 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 44.18it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 45.72it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 44.24it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:02, 47.47it/s]Training CobwebTree:  21%|        | 26/125 [00:00<00:02, 47.80it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:02, 46.04it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:02, 43.56it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 44.88it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:01, 44.94it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 47.23it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 43.73it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 44.02it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 44.52it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 44.34it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 43.10it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:01, 42.15it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 42.43it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 42.92it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 43.36it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 44.58it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 43.63it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 44.83it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 45.18it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 45.63it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 44.61it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:00:48,005 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:48,027 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:48,027 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:48.027228', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:48,028 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:50,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,056 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,057 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,058 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,054 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,061 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,062 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,062 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,062 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,063 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,064 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,065 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,066 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,068 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,069 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,070 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,071 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,073 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,074 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,076 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,082 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,094 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,098 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,112 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:50,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,116 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,116 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:50,162 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:51,200 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:51,266 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1625 virtual documents
2025-12-23 09:00:51,509 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:51,530 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:51,530 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:51.530488', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:51,532 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:00:53,532 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:00:53,533 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:00:53,538 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:00:53,539 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:00:53,540 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:00:53,541 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:00:53,541 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:00:53,542 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:00:53,543 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:00:53,544 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:00:53,545 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:00:53,545 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:00:53,546 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:00:53,547 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:00:53,548 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:00:53,548 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:00:53,549 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:00:53,550 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:00:53,551 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:00:53,551 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:00:53,552 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:00:53,553 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:00:53,553 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:00:53,554 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:00:53,555 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:00:53,555 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11237 virtual)
2025-12-23 09:00:53,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,600 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,617 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,617 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,650 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:00:53,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:53,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:00:55,127 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:00:55,189 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 11850 virtual documents
2025-12-23 09:00:55,360 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:00:55,381 INFO gensim.corpora.dictionary: built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)
2025-12-23 09:00:55,381 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8422 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1625 documents (total 25862 corpus positions)", 'datetime': '2025-12-23T09:00:55.381507', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:00:55,386 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:02,899 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:04,429 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:04,452 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:04,452 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:04.452293', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:04,453 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:06,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,479 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,480 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,482 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,481 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,482 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,484 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,486 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,488 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,490 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,491 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,492 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,495 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,496 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,498 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:06,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,514 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,537 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,542 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:06,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:07,645 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:07,672 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1750 virtual documents
2025-12-23 09:01:07,798 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:07,821 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:07,821 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:07.821587', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:07,822 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:09,784 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:01:09,785 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:01:09,786 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:01:09,788 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:01:09,788 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:01:09,789 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:01:09,789 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:01:09,790 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:01:09,791 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:01:09,792 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:01:09,793 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:01:09,794 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:01:09,794 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:01:09,795 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:01:09,796 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:01:09,797 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:01:09,797 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:01:09,798 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:01:09,798 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:01:09,799 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:01:09,799 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:01:09,800 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:01:09,800 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:01:09,800 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:01:09,801 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:01:09,801 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:01:09,802 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:01:09,802 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12213 virtual)
2025-12-23 09:01:09,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,858 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,859 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,873 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,880 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,901 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,908 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,908 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,908 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,920 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,957 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:09,983 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:09,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:11,044 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:11,073 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12852 virtual documents
2025-12-23 09:01:11,165 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:11,188 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:11,188 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:11.188412', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:11,192 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:19,193 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:20,038 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:20,061 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:20,061 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:20.061795', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:20,062 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:22,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,103 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,104 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,105 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:22,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,112 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,113 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,118 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,122 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,129 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,133 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,149 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,154 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,169 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,174 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,186 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:22,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:23,211 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:23,265 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1750 virtual documents
2025-12-23 09:01:23,419 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:23,442 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:23,442 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:23.442282', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:23,443 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:25,475 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:01:25,477 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:01:25,478 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:01:25,478 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:01:25,479 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:01:25,479 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:01:25,480 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:01:25,481 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:01:25,482 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:01:25,483 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:01:25,483 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:01:25,484 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:01:25,485 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:01:25,485 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:01:25,486 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:01:25,487 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:01:25,487 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:01:25,488 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:01:25,489 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:01:25,490 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:01:25,490 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:01:25,491 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:01:25,492 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:01:25,492 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:01:25,493 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:01:25,494 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:01:25,494 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:01:25,495 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12213 virtual)
2025-12-23 09:01:25,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,557 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,558 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,564 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,577 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,580 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:25,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,602 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:25,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:26,687 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:26,749 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12852 virtual documents
2025-12-23 09:01:26,860 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:26,883 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:26,883 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:26.883152', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:26,887 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:34,970 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1625 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 42.37it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 42.21it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 41.35it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 41.25it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 41.90it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 44.00it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 44.21it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 43.69it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:01, 44.26it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 42.40it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 42.25it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 43.42it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 44.97it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 46.10it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 45.05it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:00, 46.08it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 45.42it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 46.74it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 46.15it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 47.86it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 49.09it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 48.96it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 49.73it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 45.50it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:38,789 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:38,812 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:38,812 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:38.812284', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:38,813 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:40,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,823 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,828 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,829 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,830 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,830 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,839 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,841 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,842 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,844 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:40,844 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,846 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,866 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,900 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,901 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:40,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:42,285 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:42,331 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1750 virtual documents
2025-12-23 09:01:42,590 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:42,613 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:42,613 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:42.613088', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:42,615 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:44,556 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:01:44,557 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:01:44,558 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:01:44,559 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:01:44,560 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:01:44,560 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:01:44,561 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:01:44,562 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:01:44,562 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:01:44,563 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:01:44,564 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:01:44,565 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:01:44,565 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:01:44,566 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:01:44,567 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:01:44,568 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:01:44,568 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:01:44,569 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:01:44,570 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:01:44,571 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:01:44,571 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:01:44,572 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:01:44,573 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:01:44,573 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:01:44,574 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:01:44,575 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:01:44,575 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:01:44,576 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12213 virtual)
2025-12-23 09:01:44,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,665 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,679 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,680 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,686 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,687 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:44,777 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:44,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:45,787 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:45,867 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 12852 virtual documents
2025-12-23 09:01:46,033 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:46,056 INFO gensim.corpora.dictionary: built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)
2025-12-23 09:01:46,057 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<8925 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1750 documents (total 27963 corpus positions)", 'datetime': '2025-12-23T09:01:46.057035', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:46,061 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:01:54,048 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:01:55,574 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:55,603 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:01:55,603 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:01:55.603939', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:55,605 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:01:57,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,718 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,719 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,720 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,722 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,722 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,723 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,724 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,725 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,726 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,727 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,728 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,730 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,731 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,733 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,734 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,735 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:01:57,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,762 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,773 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,773 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:57,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:01:58,932 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:01:58,959 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1875 virtual documents
2025-12-23 09:01:59,070 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:01:59,095 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:01:59,095 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:01:59.095531', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:01:59,096 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:01,081 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:02:01,082 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:02:01,083 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:02:01,084 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:02:01,084 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:02:01,085 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:02:01,086 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:02:01,086 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:02:01,087 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:02:01,092 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:02:01,093 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:02:01,093 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:02:01,094 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:02:01,095 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:02:01,096 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:02:01,096 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:02:01,097 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:02:01,097 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:02:01,098 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:02:01,099 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:02:01,100 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:02:01,101 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:02:01,101 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:02:01,102 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:02:01,102 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:02:01,103 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:02:01,103 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:02:01,104 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:02:01,105 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:02:01,105 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13006 virtual)
2025-12-23 09:02:01,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,171 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,177 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,177 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,177 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,180 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,181 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,189 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,193 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,199 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,200 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,222 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,222 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,226 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,226 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,236 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:01,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,254 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,262 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,301 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:01,302 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:02,343 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:02,417 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 13697 virtual documents
2025-12-23 09:02:02,519 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:02,543 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:02,543 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:02.543481', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:02,547 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:11,217 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:12,025 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:12,049 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:12,049 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:12.049802', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:12,050 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:14,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,072 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,073 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,074 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,076 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,078 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,079 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,080 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,081 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,082 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,083 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,084 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,088 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,093 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:14,093 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,096 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,105 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,126 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,134 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:14,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:15,229 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:15,290 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1875 virtual documents
2025-12-23 09:02:15,429 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:15,453 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:15,453 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:15.453788', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:15,455 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:17,498 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:02:17,500 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:02:17,501 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:02:17,502 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:02:17,502 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:02:17,503 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:02:17,504 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:02:17,505 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:02:17,506 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:02:17,507 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:02:17,508 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:02:17,508 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:02:17,509 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:02:17,510 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:02:17,511 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:02:17,511 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:02:17,512 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:02:17,513 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:02:17,514 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:02:17,514 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:02:17,515 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:02:17,516 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:02:17,516 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:02:17,517 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:02:17,517 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:02:17,518 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:02:17,519 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:02:17,519 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:02:17,520 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:02:17,520 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13006 virtual)
2025-12-23 09:02:17,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,577 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,580 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,582 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,583 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,584 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,604 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,617 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,636 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,641 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:17,681 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:17,714 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:18,748 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:18,796 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 13697 virtual documents
2025-12-23 09:02:18,905 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:18,930 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:18,930 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:18.930428', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:18,934 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:27,643 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1750 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   5%|         | 6/125 [00:00<00:02, 49.87it/s]Training CobwebTree:  10%|         | 12/125 [00:00<00:02, 49.24it/s]Training CobwebTree:  14%|        | 17/125 [00:00<00:02, 48.48it/s]Training CobwebTree:  18%|        | 22/125 [00:00<00:02, 46.65it/s]Training CobwebTree:  22%|       | 27/125 [00:00<00:02, 44.84it/s]Training CobwebTree:  26%|       | 33/125 [00:00<00:02, 45.76it/s]Training CobwebTree:  30%|       | 38/125 [00:00<00:01, 45.36it/s]Training CobwebTree:  34%|      | 43/125 [00:00<00:01, 44.81it/s]Training CobwebTree:  38%|      | 48/125 [00:01<00:01, 44.59it/s]Training CobwebTree:  42%|     | 53/125 [00:01<00:01, 44.66it/s]Training CobwebTree:  46%|     | 58/125 [00:01<00:01, 43.24it/s]Training CobwebTree:  50%|     | 63/125 [00:01<00:01, 43.04it/s]Training CobwebTree:  54%|    | 68/125 [00:01<00:01, 44.39it/s]Training CobwebTree:  58%|    | 73/125 [00:01<00:01, 45.19it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:01, 43.89it/s]Training CobwebTree:  66%|   | 83/125 [00:01<00:00, 42.91it/s]Training CobwebTree:  70%|   | 88/125 [00:01<00:00, 43.12it/s]Training CobwebTree:  74%|  | 93/125 [00:02<00:00, 43.15it/s]Training CobwebTree:  78%|  | 98/125 [00:02<00:00, 41.83it/s]Training CobwebTree:  83%| | 104/125 [00:02<00:00, 44.10it/s]Training CobwebTree:  87%| | 109/125 [00:02<00:00, 44.68it/s]Training CobwebTree:  91%| | 114/125 [00:02<00:00, 44.71it/s]Training CobwebTree:  95%|| 119/125 [00:02<00:00, 44.61it/s]Training CobwebTree:  99%|| 124/125 [00:02<00:00, 45.79it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 44.81it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:31,435 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:31,460 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:31,460 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:31.460463', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:31,462 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:33,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,847 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,848 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,849 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,852 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,853 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,854 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,855 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,856 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,857 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,860 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,861 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,862 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,863 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,864 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,865 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,866 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,867 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,868 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,869 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,871 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,872 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:33,873 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,882 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,897 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,932 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:33,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:35,047 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:35,108 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 1875 virtual documents
2025-12-23 09:02:35,367 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:35,391 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:35,391 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:35.391610', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:35,393 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:37,363 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:02:37,365 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:02:37,366 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:02:37,367 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:02:37,368 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:02:37,369 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:02:37,370 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:02:37,371 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:02:37,371 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:02:37,372 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:02:37,373 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:02:37,374 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:02:37,374 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:02:37,375 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:02:37,376 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:02:37,377 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:02:37,377 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:02:37,378 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:02:37,379 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:02:37,383 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:02:37,384 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:02:37,384 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:02:37,385 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:02:37,386 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:02:37,386 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:02:37,387 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:02:37,387 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:02:37,388 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:02:37,389 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:02:37,389 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13006 virtual)
2025-12-23 09:02:37,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,465 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,468 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,475 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,476 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,478 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,483 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,493 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,497 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,499 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,521 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,522 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,536 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,540 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,545 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,564 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,570 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,574 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,586 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,612 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:37,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:37,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:38,698 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:38,755 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 13697 virtual documents
2025-12-23 09:02:38,930 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:38,954 INFO gensim.corpora.dictionary: built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)
2025-12-23 09:02:38,954 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9272 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 1875 documents (total 29881 corpus positions)", 'datetime': '2025-12-23T09:02:38.954362', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:38,959 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:47,587 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:02:49,185 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:49,211 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:02:49,211 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:02:49.211701', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:49,212 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:51,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,309 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,310 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,311 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,317 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,321 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,323 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:51,325 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,326 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,336 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,357 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,359 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,362 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,363 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:51,400 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:52,485 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:52,577 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2000 virtual documents
2025-12-23 09:02:52,691 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:52,724 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:02:52,724 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:02:52.724505', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:52,725 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:02:54,709 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:02:54,711 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:02:54,712 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:02:54,713 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:02:54,713 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:02:54,715 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:02:54,715 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:02:54,716 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:02:54,717 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:02:54,718 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:02:54,719 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:02:54,719 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:02:54,720 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:02:54,721 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:02:54,721 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:02:54,722 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:02:54,723 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:02:54,723 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:02:54,724 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:02:54,725 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:02:54,725 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:02:54,726 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:02:54,727 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:02:54,727 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:02:54,728 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:02:54,729 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:02:54,729 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:02:54,730 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:02:54,730 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:02:54,731 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:02:54,732 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:02:54,732 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (13942 virtual)
2025-12-23 09:02:54,793 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,794 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,797 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,800 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,800 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,802 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,809 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,816 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,818 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,819 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,820 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,821 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,822 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,822 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,824 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,825 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,830 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,832 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,834 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,841 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,842 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,850 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,859 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,869 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,874 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:02:54,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,883 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,887 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,891 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,899 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,913 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,918 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:54,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:02:56,001 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:02:56,038 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 14663 virtual documents
2025-12-23 09:02:56,130 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:02:56,156 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:02:56,157 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:02:56.157025', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:02:56,160 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:02:56,163 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:03:05,312 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1875 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:06,126 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:06,153 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:06,153 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:06.153401', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:06,154 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:08,521 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,522 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,529 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,538 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:08,541 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,586 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,601 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,606 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:08,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:09,688 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:09,720 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2000 virtual documents
2025-12-23 09:03:09,868 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:09,894 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:09,894 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:09.894923', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:09,896 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:11,930 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:03:11,932 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:03:11,932 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:03:11,933 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:03:11,933 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:03:11,934 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:03:11,935 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:03:11,936 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:03:11,936 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:03:11,937 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:03:11,938 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:03:11,939 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:03:11,940 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:03:11,941 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:03:11,941 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:03:11,942 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:03:11,942 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:03:11,943 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:03:11,944 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:03:11,945 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:03:11,945 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:03:11,946 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:03:11,946 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:03:11,947 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:03:11,948 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:03:11,948 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:03:11,949 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:03:11,949 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:03:11,950 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:03:11,951 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:03:11,951 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:03:11,952 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (13942 virtual)
2025-12-23 09:03:12,000 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,001 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,002 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,002 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,003 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,004 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,005 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,006 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,007 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,008 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,009 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,010 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,012 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,013 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,015 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,016 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,018 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,033 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,033 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,045 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,046 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,047 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,049 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,049 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,052 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,053 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,064 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,064 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,064 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,065 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,070 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,072 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:12,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:12,168 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:13,204 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:13,240 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 14663 virtual documents
2025-12-23 09:03:13,343 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:13,369 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:13,369 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:13.369643', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:13,373 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:13,376 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:03:22,563 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 1875 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 45.37it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 45.85it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 43.12it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 44.27it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 45.87it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 46.65it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 42.18it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:02, 42.03it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 41.30it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 41.14it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 42.09it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 42.14it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 43.03it/s]Training CobwebTree:  56%|    | 70/125 [00:01<00:01, 44.38it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:01, 44.61it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:00, 45.23it/s]Training CobwebTree:  68%|   | 85/125 [00:01<00:00, 45.37it/s]Training CobwebTree:  72%|  | 90/125 [00:02<00:00, 44.51it/s]Training CobwebTree:  76%|  | 95/125 [00:02<00:00, 45.20it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 46.78it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 42.52it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 43.11it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 44.29it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 43.20it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 43.80it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:26,427 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:26,454 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:26,454 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:26.454195', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:26,455 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:28,509 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,511 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,512 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,513 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,514 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,515 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,516 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,516 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,517 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,517 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,518 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,523 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,524 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,525 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:28,534 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,554 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,581 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,582 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:28,589 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:29,674 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:29,722 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2000 virtual documents
2025-12-23 09:03:29,976 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:30,003 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:30,003 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:30.003174', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:30,005 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:32,044 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:03:32,045 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:03:32,046 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:03:32,047 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:03:32,048 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:03:32,048 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:03:32,049 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:03:32,050 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:03:32,050 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:03:32,051 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:03:32,052 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:03:32,053 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:03:32,054 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:03:32,054 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:03:32,055 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:03:32,056 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:03:32,056 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:03:32,057 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:03:32,058 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:03:32,059 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:03:32,059 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:03:32,060 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:03:32,061 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:03:32,061 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:03:32,062 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:03:32,062 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:03:32,063 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:03:32,063 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:03:32,064 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:03:32,065 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:03:32,065 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:03:32,066 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (13942 virtual)
2025-12-23 09:03:32,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,156 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,158 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,165 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,166 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,166 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,167 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,168 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,169 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,170 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,172 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,173 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,175 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,176 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,176 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,178 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,178 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,213 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,213 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,218 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:32,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:33,623 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:33,688 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 14663 virtual documents
2025-12-23 09:03:33,863 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:33,889 INFO gensim.corpora.dictionary: built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)
2025-12-23 09:03:33,889 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<9703 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2000 documents (total 31942 corpus positions)", 'datetime': '2025-12-23T09:03:33.889845', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:33,895 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:33,898 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:03:43,010 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:03:44,509 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:44,536 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:03:44,536 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:03:44.536963', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:44,537 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:46,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,700 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,700 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,713 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,714 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:46,716 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,716 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,721 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,748 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,758 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,765 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,768 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:46,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:47,892 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:47,936 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2125 virtual documents
2025-12-23 09:03:48,035 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:48,083 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:03:48,083 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:03:48.083296', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:48,084 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:03:50,107 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:03:50,109 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:03:50,110 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:03:50,111 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:03:50,111 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:03:50,112 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:03:50,113 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:03:50,114 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:03:50,114 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:03:50,115 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:03:50,116 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:03:50,117 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:03:50,117 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:03:50,118 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:03:50,119 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:03:50,119 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:03:50,120 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:03:50,121 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:03:50,122 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:03:50,122 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:03:50,123 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:03:50,124 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:03:50,124 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:03:50,125 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:03:50,125 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:03:50,126 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:03:50,127 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:03:50,127 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:03:50,128 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:03:50,128 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:03:50,129 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:03:50,130 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:03:50,131 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:03:50,131 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (14754 virtual)
2025-12-23 09:03:50,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,179 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,183 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,184 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,185 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,186 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,187 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,188 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,188 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,190 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,182 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,195 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,196 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,197 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,197 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,201 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,202 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,203 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,204 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,204 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,205 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,206 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,206 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,207 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,209 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,212 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,214 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,198 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,217 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,228 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,229 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,291 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:03:50,330 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:50,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:03:51,360 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:03:51,403 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15522 virtual documents
2025-12-23 09:03:51,485 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:03:51,513 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:03:51,513 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:03:51.513154', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:03:51,516 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:03:51,519 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:04:01,183 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2000 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:01,969 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:01,996 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:01,997 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:01.997019', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:01,998 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:04,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,117 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,118 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,119 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,120 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,120 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,121 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,121 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,122 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,123 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,124 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,124 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,125 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,125 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,126 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,130 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,130 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,131 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,132 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,132 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,133 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,134 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,135 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,136 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,136 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,137 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,138 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,139 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,140 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,141 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:04,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,152 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,152 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,172 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,182 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:04,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:05,310 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:05,343 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2125 virtual documents
2025-12-23 09:04:05,478 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:05,506 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:05,506 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:05.506965', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:05,508 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:07,553 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:04:07,554 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:04:07,555 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:04:07,556 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:04:07,556 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:04:07,557 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:04:07,558 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:04:07,559 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:04:07,560 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:04:07,561 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:04:07,562 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:04:07,562 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:04:07,563 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:04:07,564 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:04:07,564 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:04:07,565 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:04:07,566 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:04:07,566 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:04:07,567 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:04:07,568 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:04:07,568 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:04:07,569 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:04:07,570 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:04:07,570 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:04:07,571 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:04:07,572 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:04:07,573 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:04:07,573 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:04:07,574 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:04:07,574 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:04:07,575 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:04:07,576 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:04:07,576 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:04:07,577 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (14754 virtual)
2025-12-23 09:04:07,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,649 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,650 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,651 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,652 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,672 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,673 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,674 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:07,781 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:07,805 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:08,828 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:08,885 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15522 virtual documents
2025-12-23 09:04:09,000 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:09,028 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:09,028 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:09.028356', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:09,032 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:09,035 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:04:18,814 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2000 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 41.16it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 45.56it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 43.80it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 42.20it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 41.86it/s]Training CobwebTree:  25%|       | 31/125 [00:00<00:02, 45.48it/s]Training CobwebTree:  29%|       | 36/125 [00:00<00:01, 45.22it/s]Training CobwebTree:  33%|      | 41/125 [00:00<00:01, 45.38it/s]Training CobwebTree:  37%|      | 46/125 [00:01<00:01, 45.73it/s]Training CobwebTree:  41%|      | 51/125 [00:01<00:01, 46.78it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 46.21it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 44.79it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 43.78it/s]Training CobwebTree:  57%|    | 71/125 [00:01<00:01, 43.01it/s]Training CobwebTree:  61%|    | 76/125 [00:01<00:01, 43.22it/s]Training CobwebTree:  65%|   | 81/125 [00:01<00:01, 43.21it/s]Training CobwebTree:  69%|   | 86/125 [00:01<00:00, 44.45it/s]Training CobwebTree:  73%|  | 91/125 [00:02<00:00, 45.73it/s]Training CobwebTree:  77%|  | 96/125 [00:02<00:00, 46.10it/s]Training CobwebTree:  81%|  | 101/125 [00:02<00:00, 44.92it/s]Training CobwebTree:  85%| | 106/125 [00:02<00:00, 41.53it/s]Training CobwebTree:  89%| | 111/125 [00:02<00:00, 40.86it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 42.61it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 43.22it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 44.00it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:22,632 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:22,661 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:22,661 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:22.661132', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:22,662 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:24,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,761 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,765 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,766 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:24,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,825 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,826 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,826 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,830 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,833 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:24,851 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:26,233 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:26,282 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2125 virtual documents
2025-12-23 09:04:26,547 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:26,575 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:26,575 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:26.575504', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:26,577 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:28,617 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:04:28,619 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:04:28,621 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:04:28,622 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:04:28,622 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:04:28,623 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:04:28,624 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:04:28,625 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:04:28,626 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:04:28,626 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:04:28,627 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:04:28,628 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:04:28,629 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:04:28,629 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:04:28,630 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:04:28,631 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:04:28,632 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:04:28,632 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:04:28,633 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:04:28,634 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:04:28,634 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:04:28,635 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:04:28,635 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:04:28,636 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:04:28,637 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:04:28,638 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:04:28,638 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:04:28,639 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:04:28,639 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:04:28,640 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:04:28,641 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:04:28,642 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:04:28,642 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:04:28,643 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (14754 virtual)
2025-12-23 09:04:28,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,732 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,737 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,738 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,739 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,740 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,741 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,742 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,743 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,736 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,744 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,745 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,746 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,747 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:28,757 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,777 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,778 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,782 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,797 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,802 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,810 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:28,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:29,980 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:30,030 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 15522 virtual documents
2025-12-23 09:04:30,205 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:30,233 INFO gensim.corpora.dictionary: built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)
2025-12-23 09:04:30,233 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10085 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2125 documents (total 33879 corpus positions)", 'datetime': '2025-12-23T09:04:30.233517', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:30,238 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:30,241 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:04:39,974 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:41,517 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:41,546 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:04:41,547 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:04:41.547007', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:41,548 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:43,695 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,696 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,696 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,697 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,698 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,700 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,699 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,700 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,701 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,702 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,703 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,704 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,705 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,705 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,706 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,707 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,708 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,709 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,710 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,711 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,712 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,715 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,717 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:43,718 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,725 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,742 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,747 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,749 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,751 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,754 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,754 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,755 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,759 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,767 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,774 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,775 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:43,787 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:44,904 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:44,943 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2250 virtual documents
2025-12-23 09:04:45,062 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:45,091 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:04:45,091 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:04:45.091644', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:45,092 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:04:47,227 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:04:47,228 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:04:47,229 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:04:47,230 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:04:47,230 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:04:47,231 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:04:47,232 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:04:47,232 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:04:47,233 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:04:47,234 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:04:47,235 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:04:47,236 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:04:47,236 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:04:47,237 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:04:47,238 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:04:47,239 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:04:47,239 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:04:47,240 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:04:47,241 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:04:47,241 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:04:47,242 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:04:47,242 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:04:47,242 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:04:47,243 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:04:47,243 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:04:47,244 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:04:47,244 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:04:47,245 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:04:47,246 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:04:47,246 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:04:47,247 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:04:47,247 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:04:47,248 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:04:47,249 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:04:47,249 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:04:47,250 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (15641 virtual)
2025-12-23 09:04:47,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,302 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,305 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,307 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,308 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,312 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,313 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,328 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,330 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,331 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,301 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,333 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,336 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,340 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,360 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,360 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,361 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,367 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,371 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,372 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,382 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,384 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,385 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,386 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,389 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,397 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,397 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:47,489 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:04:47,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:04:48,545 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:04:48,581 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 16464 virtual documents
2025-12-23 09:04:48,661 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:48,690 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:04:48,690 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:04:48.690462', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:48,694 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:04:48,696 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:04:59,006 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2125 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:04:59,867 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:04:59,898 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:04:59,898 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:04:59.898329', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:04:59,899 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:02,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,030 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,032 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,036 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,036 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,039 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,040 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,042 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,043 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,044 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,045 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:02,045 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,045 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,052 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,087 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,091 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,098 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:02,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:03,237 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:03,274 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2250 virtual documents
2025-12-23 09:05:03,421 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:03,451 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:05:03,451 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:05:03.451357', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:03,452 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:05,490 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:05:05,492 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:05:05,493 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:05:05,494 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:05:05,494 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:05:05,495 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:05:05,496 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:05:05,497 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:05:05,498 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:05:05,499 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:05:05,499 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:05:05,500 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:05:05,501 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:05:05,502 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:05:05,502 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:05:05,503 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:05:05,504 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:05:05,505 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:05:05,505 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:05:05,506 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:05:05,506 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:05:05,507 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:05:05,508 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:05:05,508 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:05:05,509 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:05:05,510 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:05:05,510 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:05:05,511 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:05:05,512 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:05:05,512 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:05:05,513 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:05:05,514 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:05:05,514 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:05:05,515 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:05:05,516 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:05:05,516 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (15641 virtual)
2025-12-23 09:05:05,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,587 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,590 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,590 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,594 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,595 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,597 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,598 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,601 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,619 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,620 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,621 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,638 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,656 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,656 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,656 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,678 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,716 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,721 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,733 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:05,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:05,776 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:06,813 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:06,851 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 16464 virtual documents
2025-12-23 09:05:06,959 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:06,989 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:05:06,989 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:05:06.989231', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:06,993 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:06,996 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:05:17,385 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2125 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 49.17it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 46.84it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 46.76it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 46.25it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 46.64it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 42.55it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 44.00it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:01, 44.34it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 41.83it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 41.25it/s]Training CobwebTree:  45%|     | 56/125 [00:01<00:01, 43.61it/s]Training CobwebTree:  49%|     | 61/125 [00:01<00:01, 43.04it/s]Training CobwebTree:  53%|    | 66/125 [00:01<00:01, 43.15it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 45.09it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 43.46it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:00, 44.43it/s]Training CobwebTree:  70%|   | 87/125 [00:01<00:00, 43.65it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 43.54it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 43.11it/s]Training CobwebTree:  82%| | 103/125 [00:02<00:00, 45.75it/s]Training CobwebTree:  86%| | 108/125 [00:02<00:00, 45.82it/s]Training CobwebTree:  90%| | 113/125 [00:02<00:00, 44.13it/s]Training CobwebTree:  94%|| 118/125 [00:02<00:00, 44.71it/s]Training CobwebTree:  98%|| 123/125 [00:02<00:00, 41.93it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 43.73it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:21,292 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:21,322 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:05:21,322 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:05:21.322245', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:21,324 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:23,749 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,751 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,752 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,753 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,754 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,755 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,756 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,757 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,757 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,758 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,759 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,760 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,761 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,762 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,763 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,763 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,764 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,767 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,768 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,769 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,769 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,770 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,771 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,771 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,772 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,772 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,773 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,773 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,774 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,775 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,779 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,780 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,782 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,783 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,784 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,785 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:23,788 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,788 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,791 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,799 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,807 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,811 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,819 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:23,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:24,921 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:25,018 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2250 virtual documents
2025-12-23 09:05:25,312 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:25,341 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:05:25,341 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:05:25.341676', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:25,344 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:27,388 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:05:27,390 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:05:27,392 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:05:27,393 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:05:27,394 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:05:27,395 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:05:27,395 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:05:27,396 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:05:27,397 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:05:27,398 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:05:27,399 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:05:27,399 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:05:27,400 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:05:27,401 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:05:27,401 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:05:27,402 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:05:27,403 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:05:27,404 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:05:27,405 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:05:27,405 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:05:27,406 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:05:27,406 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:05:27,407 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:05:27,408 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:05:27,408 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:05:27,409 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:05:27,409 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:05:27,410 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:05:27,411 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:05:27,411 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:05:27,412 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:05:27,413 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:05:27,413 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:05:27,414 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:05:27,415 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:05:27,415 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (15641 virtual)
2025-12-23 09:05:27,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,526 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,528 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,527 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,528 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,529 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,530 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,531 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,533 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,532 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,533 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,534 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,535 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,536 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,537 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:27,544 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,544 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,547 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,555 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,559 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,594 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,597 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,612 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,614 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:27,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:28,771 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:28,828 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 16464 virtual documents
2025-12-23 09:05:29,011 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:29,041 INFO gensim.corpora.dictionary: built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)
2025-12-23 09:05:29,041 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10525 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2250 documents (total 35891 corpus positions)", 'datetime': '2025-12-23T09:05:29.041181', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:29,046 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:29,049 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:05:39,379 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:40,946 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:40,978 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:05:40,978 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:05:40.978809', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:40,979 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:43,146 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,147 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,148 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,148 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,149 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,150 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,150 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,151 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,152 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,153 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,154 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,156 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,157 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,158 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,159 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,160 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,161 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,162 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,163 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,164 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,164 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:43,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,171 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,175 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,179 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,180 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,181 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,183 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,186 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,186 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,187 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,191 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,195 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,199 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,203 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,207 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,211 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,215 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,219 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,223 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,227 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,234 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:43,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:44,389 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:44,448 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2375 virtual documents
2025-12-23 09:05:44,550 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:44,587 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:05:44,587 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:05:44.587931', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:44,589 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:05:46,697 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:05:46,699 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:05:46,700 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:05:46,701 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:05:46,702 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:05:46,702 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:05:46,703 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:05:46,704 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:05:46,705 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:05:46,705 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:05:46,706 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:05:46,707 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:05:46,708 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:05:46,708 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:05:46,709 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:05:46,710 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:05:46,710 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:05:46,711 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:05:46,712 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:05:46,713 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:05:46,713 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:05:46,714 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:05:46,715 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:05:46,715 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:05:46,716 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:05:46,717 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:05:46,717 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:05:46,718 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:05:46,718 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:05:46,719 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:05:46,720 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:05:46,720 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:05:46,721 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:05:46,722 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:05:46,722 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:05:46,723 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:05:46,724 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:05:46,724 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (16605 virtual)
2025-12-23 09:05:46,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,783 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,786 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,787 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,788 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,789 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,790 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,791 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,795 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,795 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,796 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,798 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,799 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,801 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,803 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,803 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,804 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,805 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,806 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,807 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,808 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,812 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,812 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,815 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,815 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,816 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,818 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,818 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,823 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,826 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,827 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,827 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,828 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,829 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,831 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,831 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,833 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,834 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,835 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,835 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,836 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,837 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,838 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,839 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,840 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,840 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,841 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,841 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,843 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,847 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,848 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,849 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,849 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,851 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,855 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,857 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,858 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,863 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,865 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,867 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,870 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,871 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,875 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,879 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,885 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,894 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:46,911 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:05:46,934 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:05:47,970 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:05:48,015 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17453 virtual documents
2025-12-23 09:05:48,146 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:48,177 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:05:48,177 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:05:48.177954', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:48,182 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:05:48,184 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:05:59,069 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2250 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:05:59,918 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:05:59,949 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:05:59,949 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:05:59.949692', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:05:59,950 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:02,085 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,086 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,087 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,088 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,089 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,090 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,091 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,092 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,093 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,094 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,095 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,096 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,097 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,098 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,099 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,100 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,102 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,103 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,106 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,107 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,108 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:02,108 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,110 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,127 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,131 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,135 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,139 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,143 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,147 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,151 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,155 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,159 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,163 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:02,167 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:03,629 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:03,667 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2375 virtual documents
2025-12-23 09:06:03,816 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:03,847 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:06:03,847 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:06:03.847695', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:03,849 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:05,915 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:06:05,917 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:06:05,918 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:06:05,919 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:06:05,920 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:06:05,920 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:06:05,921 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:06:05,922 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:06:05,923 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:06:05,924 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:06:05,925 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:06:05,925 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:06:05,926 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:06:05,927 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:06:05,928 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:06:05,928 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:06:05,929 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:06:05,930 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:06:05,931 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:06:05,931 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:06:05,932 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:06:05,932 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:06:05,933 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:06:05,934 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:06:05,935 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:06:05,935 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:06:05,936 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:06:05,936 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:06:05,937 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:06:05,938 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:06:05,938 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:06:05,939 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:06:05,940 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:06:05,940 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:06:05,941 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:06:05,942 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:06:05,943 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:06:05,943 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (16605 virtual)
2025-12-23 09:06:06,020 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,021 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,022 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,023 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,024 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,025 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,026 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,027 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,028 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,029 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,030 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,031 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,032 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,032 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,033 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,034 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,035 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,037 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,038 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,039 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,041 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,042 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,043 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,047 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,048 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,051 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,054 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,055 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,055 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,056 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,058 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,059 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,060 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,060 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,061 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,063 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,067 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,071 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,075 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,077 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,079 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,081 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,083 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,086 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,090 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,095 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,097 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,099 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,101 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,101 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,102 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,107 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,111 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,115 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,119 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,123 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,137 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:06,155 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:06,201 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:07,278 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:07,310 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17453 virtual documents
2025-12-23 09:06:07,422 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:07,454 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:06:07,454 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:06:07.454169', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:07,458 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:07,461 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:06:18,446 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2250 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:02, 46.85it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 41.54it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 43.80it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 41.82it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 42.04it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 41.48it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 39.99it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:02, 41.61it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 41.39it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 40.34it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 41.03it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 41.93it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 41.41it/s]Training CobwebTree:  56%|    | 70/125 [00:01<00:01, 43.44it/s]Training CobwebTree:  60%|    | 75/125 [00:01<00:01, 45.17it/s]Training CobwebTree:  64%|   | 80/125 [00:01<00:01, 44.53it/s]Training CobwebTree:  68%|   | 85/125 [00:01<00:00, 44.50it/s]Training CobwebTree:  72%|  | 90/125 [00:02<00:00, 43.33it/s]Training CobwebTree:  76%|  | 95/125 [00:02<00:00, 42.08it/s]Training CobwebTree:  80%|  | 100/125 [00:02<00:00, 43.09it/s]Training CobwebTree:  84%| | 105/125 [00:02<00:00, 42.51it/s]Training CobwebTree:  88%| | 110/125 [00:02<00:00, 42.65it/s]Training CobwebTree:  92%|| 115/125 [00:02<00:00, 42.96it/s]Training CobwebTree:  96%|| 120/125 [00:02<00:00, 44.10it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 39.67it/s]Training CobwebTree: 100%|| 125/125 [00:02<00:00, 42.11it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:22,449 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:22,480 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:06:22,481 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:06:22.481030', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:22,482 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:24,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,572 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,573 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,574 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,575 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,576 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,577 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,578 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,579 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,581 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,585 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,586 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,588 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,589 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,591 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,592 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,593 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,593 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,596 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,599 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,600 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,620 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:24,729 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:24,740 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:25,781 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:25,888 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2375 virtual documents
2025-12-23 09:06:26,137 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:26,168 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:06:26,169 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:06:26.168982', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:26,171 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:28,214 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:06:28,216 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:06:28,217 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:06:28,218 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:06:28,219 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:06:28,220 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:06:28,220 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:06:28,221 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:06:28,222 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:06:28,222 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:06:28,223 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:06:28,224 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:06:28,225 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:06:28,226 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:06:28,226 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:06:28,227 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:06:28,228 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:06:28,229 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:06:28,230 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:06:28,230 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:06:28,231 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:06:28,232 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:06:28,232 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:06:28,233 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:06:28,234 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:06:28,235 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:06:28,235 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:06:28,236 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:06:28,236 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:06:28,237 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:06:28,237 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:06:28,238 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:06:28,239 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:06:28,239 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:06:28,240 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:06:28,241 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:06:28,242 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:06:28,242 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (16605 virtual)
2025-12-23 09:06:28,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,315 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,316 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,314 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,317 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,318 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,319 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,320 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,322 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,327 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,337 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,338 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,339 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,341 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,342 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,343 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,351 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,353 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,354 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,354 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,355 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,357 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,359 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,360 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,361 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,365 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,370 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,374 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,374 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,378 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,380 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,380 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,380 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,391 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,399 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,404 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,411 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,419 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,428 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,435 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,366 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,477 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,487 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:28,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,506 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:28,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:29,601 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:29,681 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 17453 virtual documents
2025-12-23 09:06:29,868 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:29,900 INFO gensim.corpora.dictionary: built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)
2025-12-23 09:06:29,900 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<10931 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2375 documents (total 37980 corpus positions)", 'datetime': '2025-12-23T09:06:29.900294', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:29,905 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:29,908 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:06:40,818 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:06:42,462 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:42,495 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:06:42,495 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:06:42.495693', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:42,496 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:44,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,660 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,661 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,667 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,668 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,669 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,670 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,671 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:44,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,706 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,731 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:44,796 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:45,896 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:45,937 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2500 virtual documents
2025-12-23 09:06:46,055 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:46,088 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:06:46,088 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:06:46.088139', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:46,089 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:06:48,485 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:06:48,486 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:06:48,487 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:06:48,488 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:06:48,488 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:06:48,489 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:06:48,490 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:06:48,490 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:06:48,491 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:06:48,492 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:06:48,493 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:06:48,493 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:06:48,494 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:06:48,495 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:06:48,495 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:06:48,496 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:06:48,497 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:06:48,498 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:06:48,498 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:06:48,499 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:06:48,500 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:06:48,500 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:06:48,501 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:06:48,501 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:06:48,502 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:06:48,502 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:06:48,503 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:06:48,503 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:06:48,504 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:06:48,505 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:06:48,505 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:06:48,506 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:06:48,507 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:06:48,507 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:06:48,508 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:06:48,509 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:06:48,509 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:06:48,510 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:06:48,511 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:06:48,511 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (17612 virtual)
2025-12-23 09:06:48,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,602 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,603 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,604 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,605 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,606 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,607 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,608 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,609 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,609 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,610 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,611 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,612 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,613 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,614 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,615 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,616 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,617 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,618 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,618 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,632 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,634 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,643 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,688 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:48,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:48,743 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,299 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:06:49,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:06:49,946 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:06:49,995 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 18506 virtual documents
2025-12-23 09:06:50,081 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:06:50,114 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:06:50,114 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:06:50.114722', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:06:50,118 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:06:50,121 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:07:01,598 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2375 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:02,477 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:02,510 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:02,510 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:02.510592', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:02,511 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:04,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,635 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,637 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,640 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,643 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,644 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,645 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,645 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,646 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,647 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,648 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,653 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,653 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,654 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,655 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,656 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,657 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,658 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,659 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,660 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,661 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,662 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,663 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,664 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,665 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,666 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:04,666 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,693 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,698 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,702 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,711 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,713 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,719 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,723 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,727 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,735 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:04,739 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:05,874 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:05,906 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2500 virtual documents
2025-12-23 09:07:06,047 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:06,080 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:06,081 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:06.080966', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:06,082 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:08,127 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:07:08,129 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:07:08,130 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:07:08,131 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:07:08,131 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:07:08,132 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:07:08,133 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:07:08,134 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:07:08,135 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:07:08,135 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:07:08,136 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:07:08,137 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:07:08,138 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:07:08,139 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:07:08,140 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:07:08,140 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:07:08,141 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:07:08,142 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:07:08,142 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:07:08,143 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:07:08,144 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:07:08,144 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:07:08,145 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:07:08,146 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:07:08,146 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:07:08,147 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:07:08,147 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:07:08,148 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:07:08,149 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:07:08,149 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:07:08,150 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:07:08,151 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:07:08,156 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:07:08,157 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:07:08,158 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:07:08,158 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:07:08,159 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:07:08,160 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:07:08,160 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:07:08,160 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (17612 virtual)
2025-12-23 09:07:08,215 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,216 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,218 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,219 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,220 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,221 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,222 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,223 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,224 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,225 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,226 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,227 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,228 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,231 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,235 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,235 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,239 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,243 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,247 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,253 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,255 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,259 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,260 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,269 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,274 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,276 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,276 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,276 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,280 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,292 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,292 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,292 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,292 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,326 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,360 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,364 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,370 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,378 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,309 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:08,394 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,407 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:08,409 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:09,474 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:09,503 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 18506 virtual documents
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning:

Mean of empty slice.

/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/numpy/_core/_methods.py:144: RuntimeWarning:

invalid value encountered in scalar divide

2025-12-23 09:07:09,622 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:09,654 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:09,655 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:09.655051', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:09,659 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:09,662 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:07:21,283 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2375 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   4%|         | 5/125 [00:00<00:03, 38.40it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 42.40it/s]Training CobwebTree:  12%|        | 15/125 [00:00<00:02, 39.39it/s]Training CobwebTree:  16%|        | 20/125 [00:00<00:02, 42.50it/s]Training CobwebTree:  20%|        | 25/125 [00:00<00:02, 44.12it/s]Training CobwebTree:  24%|       | 30/125 [00:00<00:02, 45.03it/s]Training CobwebTree:  28%|       | 35/125 [00:00<00:02, 42.19it/s]Training CobwebTree:  32%|      | 40/125 [00:00<00:02, 41.34it/s]Training CobwebTree:  36%|      | 45/125 [00:01<00:01, 40.71it/s]Training CobwebTree:  40%|      | 50/125 [00:01<00:01, 41.11it/s]Training CobwebTree:  44%|     | 55/125 [00:01<00:01, 40.37it/s]Training CobwebTree:  48%|     | 60/125 [00:01<00:01, 40.41it/s]Training CobwebTree:  52%|    | 65/125 [00:01<00:01, 38.86it/s]Training CobwebTree:  55%|    | 69/125 [00:01<00:01, 36.77it/s]Training CobwebTree:  59%|    | 74/125 [00:01<00:01, 38.72it/s]Training CobwebTree:  62%|   | 78/125 [00:01<00:01, 38.69it/s]Training CobwebTree:  66%|   | 82/125 [00:02<00:01, 37.96it/s]Training CobwebTree:  70%|   | 87/125 [00:02<00:00, 39.45it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 40.81it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 40.69it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 40.79it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 41.12it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 41.79it/s]Training CobwebTree:  94%|| 117/125 [00:02<00:00, 43.09it/s]Training CobwebTree:  98%|| 122/125 [00:02<00:00, 43.24it/s]Training CobwebTree: 100%|| 125/125 [00:03<00:00, 41.03it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:25,439 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:25,473 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:25,473 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:25.473485', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:25,475 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:27,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,556 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,557 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,558 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,559 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,560 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,560 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,561 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,562 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,563 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,564 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,565 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,566 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,567 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,568 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,569 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,569 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,570 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,571 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,575 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,579 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,598 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,605 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,607 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,610 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,611 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,613 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,613 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,615 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,618 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,619 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,623 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,626 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,630 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,639 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:27,649 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:28,793 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:28,845 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2500 virtual documents
2025-12-23 09:07:29,097 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:29,129 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:29,129 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:29.129910', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:29,132 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:31,160 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:07:31,161 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:07:31,163 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:07:31,164 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:07:31,165 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:07:31,166 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:07:31,166 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:07:31,167 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:07:31,168 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:07:31,169 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:07:31,169 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:07:31,170 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:07:31,171 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:07:31,172 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:07:31,172 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:07:31,173 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:07:31,174 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:07:31,175 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:07:31,176 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:07:31,176 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:07:31,177 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:07:31,177 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:07:31,178 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:07:31,179 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:07:31,179 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:07:31,180 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:07:31,180 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:07:31,181 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:07:31,182 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:07:31,182 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:07:31,183 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:07:31,184 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:07:31,184 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:07:31,185 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:07:31,186 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:07:31,186 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:07:31,187 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:07:31,188 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:07:31,189 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:07:31,189 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (17612 virtual)
2025-12-23 09:07:31,254 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,255 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,258 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,277 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,278 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,290 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,292 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,293 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,294 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,295 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,300 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,303 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,304 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,305 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,306 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,334 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,341 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,346 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,349 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,351 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,352 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,355 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,365 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,371 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,374 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,375 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,379 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,383 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,387 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,389 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,390 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,395 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,396 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,396 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,403 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,415 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,417 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,418 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,420 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,420 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:31,446 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,449 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:31,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:32,868 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:32,914 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 18506 virtual documents
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning:

Mean of empty slice.

/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/numpy/_core/_methods.py:144: RuntimeWarning:

invalid value encountered in scalar divide

2025-12-23 09:07:33,083 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:33,116 INFO gensim.corpora.dictionary: built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)
2025-12-23 09:07:33,116 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11342 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2500 documents (total 40112 corpus positions)", 'datetime': '2025-12-23T09:07:33.116690', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:33,121 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:33,124 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:07:44,701 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:07:46,455 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:46,491 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:07:46,491 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:07:46.491402', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:46,492 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:48,625 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,626 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,627 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,627 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,628 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,629 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,630 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,631 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,631 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,632 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,633 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,633 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,634 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,635 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,636 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,637 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,638 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,639 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,640 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,641 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,642 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,642 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,647 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,650 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,651 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,655 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,658 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,659 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,663 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,667 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,669 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,671 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,674 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,675 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,677 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,679 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,683 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,687 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,689 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,691 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,692 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,694 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,695 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,699 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,703 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,707 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,710 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,710 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,715 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:48,746 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:49,884 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:49,924 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2625 virtual documents
2025-12-23 09:07:50,032 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:50,067 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:07:50,067 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:07:50.067266', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:50,068 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:07:52,135 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:07:52,137 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:07:52,138 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:07:52,139 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:07:52,140 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:07:52,140 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:07:52,141 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:07:52,142 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:07:52,143 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:07:52,143 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:07:52,144 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:07:52,145 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:07:52,146 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:07:52,146 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:07:52,147 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:07:52,148 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:07:52,149 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:07:52,149 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:07:52,150 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:07:52,150 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:07:52,151 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:07:52,151 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:07:52,152 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:07:52,153 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:07:52,153 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:07:52,154 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:07:52,154 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:07:52,155 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:07:52,156 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:07:52,156 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:07:52,157 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:07:52,158 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:07:52,159 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:07:52,159 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:07:52,160 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:07:52,160 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:07:52,161 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:07:52,162 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:07:52,162 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:07:52,163 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (18088 virtual)
2025-12-23 09:07:52,164 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (18634 virtual)
2025-12-23 09:07:52,164 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (18643 virtual)
2025-12-23 09:07:52,239 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,240 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,241 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,242 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,242 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,243 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,244 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,244 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,245 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,246 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,247 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,248 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,249 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,250 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,251 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,252 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,256 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,257 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,261 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,265 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,265 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,268 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,278 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,280 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:07:52,281 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,295 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,299 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,314 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,324 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,324 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:52,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:07:53,529 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:07:53,555 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19557 virtual documents
2025-12-23 09:07:53,634 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:07:53,669 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:07:53,669 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:07:53.669252', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:07:53,673 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:07:53,676 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:08:05,887 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2500 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:06,746 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:06,781 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:06,781 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:06.781154', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:06,782 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:08,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,877 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,878 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,879 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,880 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,881 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,882 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,883 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,884 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,885 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,886 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,887 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,888 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,888 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,889 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,890 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,891 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,892 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,893 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,893 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,894 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,895 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,895 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,897 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,898 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,898 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,901 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,902 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,902 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,903 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,903 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,904 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,905 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,907 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:08,907 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,911 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,915 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,919 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,923 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,925 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,927 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,930 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,931 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,935 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,939 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,942 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,943 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,947 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,951 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,955 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,959 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:08,966 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:10,057 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:10,100 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2625 virtual documents
2025-12-23 09:08:10,258 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:10,293 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:10,293 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:10.293101', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:10,294 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:12,337 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:08:12,338 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:08:12,338 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:08:12,339 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:08:12,340 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:08:12,341 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:08:12,341 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:08:12,342 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:08:12,343 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:08:12,343 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:08:12,344 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:08:12,345 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:08:12,346 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:08:12,346 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:08:12,347 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:08:12,348 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:08:12,349 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:08:12,349 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:08:12,350 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:08:12,351 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:08:12,351 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:08:12,352 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:08:12,353 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:08:12,353 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:08:12,354 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:08:12,354 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:08:12,355 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:08:12,356 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:08:12,356 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:08:12,357 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:08:12,357 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:08:12,358 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:08:12,359 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:08:12,360 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:08:12,360 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:08:12,361 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:08:12,361 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:08:12,362 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:08:12,363 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:08:12,364 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (18088 virtual)
2025-12-23 09:08:12,364 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (18634 virtual)
2025-12-23 09:08:12,364 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (18643 virtual)
2025-12-23 09:08:12,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,423 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,424 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,425 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,426 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,428 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,436 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,443 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,446 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,453 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,463 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,466 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,468 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,470 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,471 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,473 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,473 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,476 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,485 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,494 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,497 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,500 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,501 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,502 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,503 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,504 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,506 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,508 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,510 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,512 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,524 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,474 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,535 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,539 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,543 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,551 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,599 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:12,538 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:12,629 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:13,726 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:13,756 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19557 virtual documents
2025-12-23 09:08:13,859 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:13,894 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:13,894 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:13.894582', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:13,898 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:13,901 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:08:26,166 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2500 (125 docs)
Training CobwebTree:   0%|          | 0/125 [00:00<?, ?it/s]Training CobwebTree:   3%|         | 4/125 [00:00<00:03, 39.28it/s]Training CobwebTree:   8%|         | 10/125 [00:00<00:02, 46.66it/s]Training CobwebTree:  13%|        | 16/125 [00:00<00:02, 46.38it/s]Training CobwebTree:  17%|        | 21/125 [00:00<00:02, 42.85it/s]Training CobwebTree:  21%|        | 26/125 [00:00<00:02, 41.48it/s]Training CobwebTree:  26%|       | 32/125 [00:00<00:02, 44.69it/s]Training CobwebTree:  30%|       | 37/125 [00:00<00:01, 45.79it/s]Training CobwebTree:  34%|      | 42/125 [00:00<00:01, 45.09it/s]Training CobwebTree:  38%|      | 47/125 [00:01<00:01, 44.19it/s]Training CobwebTree:  42%|     | 52/125 [00:01<00:01, 45.17it/s]Training CobwebTree:  46%|     | 57/125 [00:01<00:01, 44.72it/s]Training CobwebTree:  50%|     | 62/125 [00:01<00:01, 41.29it/s]Training CobwebTree:  54%|    | 67/125 [00:01<00:01, 41.04it/s]Training CobwebTree:  58%|    | 72/125 [00:01<00:01, 41.92it/s]Training CobwebTree:  62%|   | 77/125 [00:01<00:01, 42.60it/s]Training CobwebTree:  66%|   | 82/125 [00:01<00:01, 40.66it/s]Training CobwebTree:  70%|   | 87/125 [00:02<00:00, 39.36it/s]Training CobwebTree:  74%|  | 92/125 [00:02<00:00, 40.06it/s]Training CobwebTree:  78%|  | 97/125 [00:02<00:00, 40.42it/s]Training CobwebTree:  82%| | 102/125 [00:02<00:00, 37.60it/s]Training CobwebTree:  86%| | 107/125 [00:02<00:00, 37.53it/s]Training CobwebTree:  90%| | 112/125 [00:02<00:00, 38.16it/s]Training CobwebTree:  93%|| 116/125 [00:02<00:00, 37.14it/s]Training CobwebTree:  97%|| 121/125 [00:02<00:00, 39.43it/s]Training CobwebTree: 100%|| 125/125 [00:03<00:00, 41.37it/s]
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:30,239 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:30,274 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:30,274 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:30.274684', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:30,276 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:32,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,435 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,436 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,438 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,438 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,439 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,440 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,441 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,444 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,447 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,449 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,450 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,454 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,455 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,456 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,457 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,463 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,464 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:32,465 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,475 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,478 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,510 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:32,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:33,684 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:33,746 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2625 virtual documents
2025-12-23 09:08:33,955 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:33,990 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:33,990 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:33.990570', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:33,992 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:36,318 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:08:36,320 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:08:36,321 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:08:36,322 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:08:36,322 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:08:36,323 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:08:36,324 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:08:36,325 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:08:36,325 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:08:36,326 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:08:36,327 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:08:36,327 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:08:36,328 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:08:36,329 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:08:36,330 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:08:36,331 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:08:36,332 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:08:36,332 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:08:36,333 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:08:36,334 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:08:36,335 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:08:36,335 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:08:36,336 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:08:36,337 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:08:36,337 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:08:36,338 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:08:36,339 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:08:36,339 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:08:36,340 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:08:36,340 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:08:36,341 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:08:36,342 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:08:36,342 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:08:36,343 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:08:36,344 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:08:36,344 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:08:36,345 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:08:36,346 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:08:36,347 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:08:36,347 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (18088 virtual)
2025-12-23 09:08:36,348 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (18634 virtual)
2025-12-23 09:08:36,348 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (18643 virtual)
2025-12-23 09:08:36,427 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,429 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,430 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,431 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,432 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,434 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,433 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,434 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,439 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,447 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,448 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,451 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,452 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,452 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,453 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,454 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,455 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,458 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,459 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,459 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,460 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,461 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,462 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,462 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,467 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,471 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,474 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,479 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,483 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,487 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,491 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,495 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,499 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,502 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,503 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,507 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,511 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,515 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,519 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,523 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,527 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,531 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,539 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,540 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,541 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,542 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,543 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,544 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,545 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,546 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,547 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:36,563 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,566 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,567 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,571 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,577 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,578 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,583 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,587 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,591 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,595 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,597 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:36,603 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:37,981 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:38,018 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 19557 virtual documents
2025-12-23 09:08:38,168 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:38,202 INFO gensim.corpora.dictionary: built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)
2025-12-23 09:08:38,202 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<11778 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2625 documents (total 42268 corpus positions)", 'datetime': '2025-12-23T09:08:38.202469', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:38,207 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:38,210 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:08:50,426 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:08:52,106 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:52,157 INFO gensim.corpora.dictionary: built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)
2025-12-23 09:08:52,157 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)", 'datetime': '2025-12-23T09:08:52.157650', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:52,158 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:54,259 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,260 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,261 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,262 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,263 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,263 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,264 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,265 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,266 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,267 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,268 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,268 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,269 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,269 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,270 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,271 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,272 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,273 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,273 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,274 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,275 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,275 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,276 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,279 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:54,279 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,283 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,287 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,291 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,296 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,298 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,303 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,305 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,307 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,311 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,315 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,319 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,323 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,327 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,331 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,333 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,335 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,339 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,342 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,343 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:54,347 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:55,501 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:55,528 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 2750 virtual documents
2025-12-23 09:08:55,635 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:55,676 INFO gensim.corpora.dictionary: built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)
2025-12-23 09:08:55,676 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)", 'datetime': '2025-12-23T09:08:55.676465', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:55,677 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-23 09:08:57,834 INFO gensim.topic_coherence.text_analysis: 1 batches submitted to accumulate stats from 64 documents (387 virtual)
2025-12-23 09:08:57,835 INFO gensim.topic_coherence.text_analysis: 2 batches submitted to accumulate stats from 128 documents (938 virtual)
2025-12-23 09:08:57,836 INFO gensim.topic_coherence.text_analysis: 3 batches submitted to accumulate stats from 192 documents (1479 virtual)
2025-12-23 09:08:57,837 INFO gensim.topic_coherence.text_analysis: 4 batches submitted to accumulate stats from 256 documents (1967 virtual)
2025-12-23 09:08:57,837 INFO gensim.topic_coherence.text_analysis: 5 batches submitted to accumulate stats from 320 documents (2473 virtual)
2025-12-23 09:08:57,838 INFO gensim.topic_coherence.text_analysis: 6 batches submitted to accumulate stats from 384 documents (3019 virtual)
2025-12-23 09:08:57,839 INFO gensim.topic_coherence.text_analysis: 7 batches submitted to accumulate stats from 448 documents (3575 virtual)
2025-12-23 09:08:57,840 INFO gensim.topic_coherence.text_analysis: 8 batches submitted to accumulate stats from 512 documents (3986 virtual)
2025-12-23 09:08:57,841 INFO gensim.topic_coherence.text_analysis: 9 batches submitted to accumulate stats from 576 documents (4412 virtual)
2025-12-23 09:08:57,841 INFO gensim.topic_coherence.text_analysis: 10 batches submitted to accumulate stats from 640 documents (4895 virtual)
2025-12-23 09:08:57,843 INFO gensim.topic_coherence.text_analysis: 11 batches submitted to accumulate stats from 704 documents (5387 virtual)
2025-12-23 09:08:57,843 INFO gensim.topic_coherence.text_analysis: 12 batches submitted to accumulate stats from 768 documents (5869 virtual)
2025-12-23 09:08:57,844 INFO gensim.topic_coherence.text_analysis: 13 batches submitted to accumulate stats from 832 documents (6315 virtual)
2025-12-23 09:08:57,845 INFO gensim.topic_coherence.text_analysis: 14 batches submitted to accumulate stats from 896 documents (6736 virtual)
2025-12-23 09:08:57,846 INFO gensim.topic_coherence.text_analysis: 15 batches submitted to accumulate stats from 960 documents (7165 virtual)
2025-12-23 09:08:57,846 INFO gensim.topic_coherence.text_analysis: 16 batches submitted to accumulate stats from 1024 documents (7484 virtual)
2025-12-23 09:08:57,847 INFO gensim.topic_coherence.text_analysis: 17 batches submitted to accumulate stats from 1088 documents (7898 virtual)
2025-12-23 09:08:57,848 INFO gensim.topic_coherence.text_analysis: 18 batches submitted to accumulate stats from 1152 documents (8338 virtual)
2025-12-23 09:08:57,848 INFO gensim.topic_coherence.text_analysis: 19 batches submitted to accumulate stats from 1216 documents (8692 virtual)
2025-12-23 09:08:57,849 INFO gensim.topic_coherence.text_analysis: 20 batches submitted to accumulate stats from 1280 documents (8916 virtual)
2025-12-23 09:08:57,849 INFO gensim.topic_coherence.text_analysis: 21 batches submitted to accumulate stats from 1344 documents (9216 virtual)
2025-12-23 09:08:57,849 INFO gensim.topic_coherence.text_analysis: 22 batches submitted to accumulate stats from 1408 documents (9565 virtual)
2025-12-23 09:08:57,850 INFO gensim.topic_coherence.text_analysis: 23 batches submitted to accumulate stats from 1472 documents (10088 virtual)
2025-12-23 09:08:57,850 INFO gensim.topic_coherence.text_analysis: 24 batches submitted to accumulate stats from 1536 documents (10558 virtual)
2025-12-23 09:08:57,851 INFO gensim.topic_coherence.text_analysis: 25 batches submitted to accumulate stats from 1600 documents (11067 virtual)
2025-12-23 09:08:57,851 INFO gensim.topic_coherence.text_analysis: 26 batches submitted to accumulate stats from 1664 documents (11557 virtual)
2025-12-23 09:08:57,852 INFO gensim.topic_coherence.text_analysis: 27 batches submitted to accumulate stats from 1728 documents (12045 virtual)
2025-12-23 09:08:57,852 INFO gensim.topic_coherence.text_analysis: 28 batches submitted to accumulate stats from 1792 documents (12422 virtual)
2025-12-23 09:08:57,853 INFO gensim.topic_coherence.text_analysis: 29 batches submitted to accumulate stats from 1856 documents (12803 virtual)
2025-12-23 09:08:57,854 INFO gensim.topic_coherence.text_analysis: 30 batches submitted to accumulate stats from 1920 documents (13322 virtual)
2025-12-23 09:08:57,854 INFO gensim.topic_coherence.text_analysis: 31 batches submitted to accumulate stats from 1984 documents (13774 virtual)
2025-12-23 09:08:57,855 INFO gensim.topic_coherence.text_analysis: 32 batches submitted to accumulate stats from 2048 documents (14265 virtual)
2025-12-23 09:08:57,856 INFO gensim.topic_coherence.text_analysis: 33 batches submitted to accumulate stats from 2112 documents (14670 virtual)
2025-12-23 09:08:57,856 INFO gensim.topic_coherence.text_analysis: 34 batches submitted to accumulate stats from 2176 documents (15182 virtual)
2025-12-23 09:08:57,857 INFO gensim.topic_coherence.text_analysis: 35 batches submitted to accumulate stats from 2240 documents (15557 virtual)
2025-12-23 09:08:57,858 INFO gensim.topic_coherence.text_analysis: 36 batches submitted to accumulate stats from 2304 documents (16065 virtual)
2025-12-23 09:08:57,858 INFO gensim.topic_coherence.text_analysis: 37 batches submitted to accumulate stats from 2368 documents (16555 virtual)
2025-12-23 09:08:57,859 INFO gensim.topic_coherence.text_analysis: 38 batches submitted to accumulate stats from 2432 documents (17010 virtual)
2025-12-23 09:08:57,860 INFO gensim.topic_coherence.text_analysis: 39 batches submitted to accumulate stats from 2496 documents (17571 virtual)
2025-12-23 09:08:57,860 INFO gensim.topic_coherence.text_analysis: 40 batches submitted to accumulate stats from 2560 documents (18088 virtual)
2025-12-23 09:08:57,861 INFO gensim.topic_coherence.text_analysis: 41 batches submitted to accumulate stats from 2624 documents (18634 virtual)
2025-12-23 09:08:57,862 INFO gensim.topic_coherence.text_analysis: 42 batches submitted to accumulate stats from 2688 documents (19078 virtual)
2025-12-23 09:08:57,862 INFO gensim.topic_coherence.text_analysis: 43 batches submitted to accumulate stats from 2752 documents (19499 virtual)
2025-12-23 09:08:57,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,943 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,944 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,944 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,945 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,945 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,946 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,947 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,948 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,949 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,951 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,952 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,954 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,955 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,956 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,957 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,958 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,960 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,961 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,962 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,963 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,963 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,964 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,965 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,965 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,967 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,967 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,971 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,971 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,972 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,974 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,975 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,975 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,976 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,977 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,979 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,980 INFO gensim.topic_coherence.text_analysis: serializing accumulator to return to master...
2025-12-23 09:08:57,981 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,983 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,987 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,991 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,995 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:57,998 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,003 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,007 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,011 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,014 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,015 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,019 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,021 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,023 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,024 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,027 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,031 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,035 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:58,059 INFO gensim.topic_coherence.text_analysis: accumulator serialized
2025-12-23 09:08:59,218 INFO gensim.topic_coherence.text_analysis: 63 accumulators retrieved from output queue
2025-12-23 09:08:59,244 INFO gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 20463 virtual documents
2025-12-23 09:08:59,332 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:08:59,368 INFO gensim.corpora.dictionary: built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)
2025-12-23 09:08:59,368 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)", 'datetime': '2025-12-23T09:08:59.368143', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:08:59,372 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 1000 documents
2025-12-23 09:08:59,374 INFO gensim.topic_coherence.text_analysis: CorpusAccumulator accumulated stats from 2000 documents
2025-12-23 09:09:12,058 INFO src.utils.bertopic_utils: Partial fitting model BERTopic on batch starting 2625 (125 docs)
/nethome/ksingara3/flash/miniconda3/envs/rag-cobweb/lib/python3.11/site-packages/bertopic/vectorizers/_ctfidf.py:82: RuntimeWarning:

divide by zero encountered in divide

2025-12-23 09:09:12,950 INFO gensim.corpora.dictionary: adding document #0 to Dictionary<0 unique tokens: []>
2025-12-23 09:09:12,987 INFO gensim.corpora.dictionary: built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)
2025-12-23 09:09:12,987 INFO gensim.utils: Dictionary lifecycle event {'msg': "built Dictionary<12174 unique tokens: ['100', 'final', 'floorball', 'game', 'nations']...> from 2750 documents (total 44249 corpus positions)", 'datetime': '2025-12-23T09:09:12.987331', 'gensim': '4.4.0', 'python': '3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]', 'platform': 'Linux-5.4.0-187-generic-x86_64-with-glibc2.31', 'event': 'created'}
2025-12-23 09:09:12,988 INFO gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator<processes=63, batch_size=64> to estimate probabilities from sliding windows
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
